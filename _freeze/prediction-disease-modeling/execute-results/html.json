{
  "hash": "1f56f58ca013f3f95ddec39276265b44",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Disease modeling\"\nbibliography: references.bib\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n\n## Introduction\n\nAs seen in the previous chapter, plant disease modeling is a crucial tool for predicting disease dynamics and informing management decisions when integrated into decision support systems. By leveraging models, researchers and practitioners can anticipate disease outbreaks, assess potential risks, and implement timely interventions to mitigate losses [@savary2018; @rossi2010a].\n\nMathematical modeling involves representing empirical phenomena and experimental outcomes using mathematical functions. The data used for these models may be collected specifically for modeling purposes or drawn from existing experiments and observations originally conducted to address different research questions, with such data often found in the literature [@hau1990].\n\nMathematical models integrating plant, disease, and environmental - in most cases weather-based variables - factors have been developed since the mid-1900s (See recent review by @gonz√°lez-dom√≠nguez2023 ). Dynamic modeling of disease epidemics gained traction in the early 1960s with foundational work by Vanderplank and Zadoks, setting the stage for future advancements. Since then, researchers have contributed extensively to model development, mainly focusing on the plant disease cycle which outline pathogen development stages, such as dormancy, reproduction, dispersal, and pathogenesis, driven by interactions among host, pathogen, and environmental factors [@dewolf2007].\n\nA systematic map by @fedele2022a identified over 750 papers on plant disease models, primarily aimed at understanding system interactions (n = 680). This map revealed that while most models focus on system understanding, fewer are devoted to tactical management (n = 40), strategic planning (n = 38), or scenario analysis (n = 9).\n\nIn terms of model development, we can classify the models into two main groups based on the approach taken [@gonz√°lez-dom√≠nguez2023]: Empirical or mechanistic approaches, which differ fundamentally in their basis, complexity and application ([@fig-approaches_modeling]).\n\n![Steps of model development from data collection to modeling based on statistical relationships (data-driven) between data collected from field or controlled environment to mechanistic approach based on the elements of the disease cycles (concept-driven).](imgs/modeling-fig1.png){#fig-approaches_modeling fig-align=\"center\" width=\"614\"}\n\n**Empirical models**, which emerged in the mid-20th century, rely on data-driven statistical relationships between variables collected under varying field or controlled environments. These models often lack cause-effect understanding, making them less robust and requiring rigorous validation and calibration when applied in diverse environments, especially in regions that did not provide data for model construction. The parameters of the model change every time new data are incorporated during model development.\n\nIn contrast, **mechanistic models**, developed from a deep understanding of biological and epidemiological processes, explain disease dynamics based on known system behaviors in response to external variables---a concept-driven approach. These dynamic models quantitatively characterize the state of the pathosystem over time, offering generally more robust predictions by utilizing mathematical equations to describe how epidemics evolve under varying environmental conditions.\n\nBoth empirical and mechanistic approaches are valid methodologies extensively used in plant pathology research. The choice between these approaches depends on several factors, including data availability, urgency in model development, and, frequently, the researcher's experience or preference. Empirical models focus on statistical relationships derived directly from data, whereas mechanistic models aim to represent the biological processes of disease progression through linked mathematical equations.\n\nIn mechanistic modeling, the equations used to predict specific disease components---such as infection frequency or the latency period---are often empirically derived from controlled experiments. For example, an infection frequency equation is typically based on data collected under specific environmental conditions, with models fitted to accurately describe observed patterns. These process-based models are then built by integrating empirically-derived equations or rules, which collectively simulate the disease cycle. Data and equations are sourced from published studies or generated from new experiments conducted by researchers.\n\nBeyond their practical predictive value, mechanistic models are valuable tools for organizing existing knowledge about a particular disease, helping to identify gaps and guide future research efforts. An example of such work is the extensive collection of comprehensive mechanistic models developed for various plant diseases by the research group led by Prof. Vittorio Rossi in Italy [@rossi2008; @rossi2014; @salotti2023; @salotti2022].\n\nThis chapter focuses mainly on empirical modeling. We begin by examining the types of data utilized in model development, focusing on those collected under controlled conditions, such as replicated laboratory or growth chamber experiments, as well as field data collected from several locations and years. We will also analyze real-world case studies, drawing on examples from the literature to replicate and understand model applications. Through these examples, we aim to illustrate the process of fitting models to data and underscore the role of modeling in advancing plant disease management practices.\n\n## Controlled environment\n\nIn this section, we will demonstrate, using examples from the literature, how statistical models can be fitted to data that represent various stages of the disease cycle.\n\nResearch on disease-environment interactions under controlled conditions - such as laboratory or growth chamber studies - lays the groundwork for building foundational models, including infection-based models and sub-models for specific processes like dormancy, dispersal, infection, and latency [@krause1975; @magarey2005; @dewolf2007].\n\nGrowth chambers and phytotrons are essential for testing the effects of individual variables, though these controlled results may not fully replicate field conditions. Anyway, laboratory experiments help clarify specific questions by isolating interactions, unlike complex field trials where host, pathogen, and environment factors interact. Polycyclic or \"mini epidemic\" experiments enable observation of disease dynamics under targeted conditions [@hau1990; @rotem1988].\n\nOnce developed, these sub-models can be incorporated into larger mechanistic models that simulate the entire disease cycle, thereby mimicking disease progression over time [@rossi2008; @salotti2023]. Alternatively, sub-models can also be used in stand-alone predictive systems where the process being modeled - such as infection - is the key factor in determining disease occurrence [@machardy1989; @magarey2007]. For example, infection sub-models can be integrated into prediction systems that help schedule crop protection measures by forecasting when infection risk is highest.\n\n### Infection-based models\n\nTo model infection potential based on environmental factors, simple rules can be used with daily weather data, such as temperature and rainfall thresholds [@magarey2002]. Simple decision aids, such as charts and graphs, also exist to help model infection potential by using combinations of daily average temperature and hours of wetness. These tools offer a straightforward approach to evaluate infection risks based on readily available weather data, supporting decision-making without complex modeling [@seem1984]. However, for many pathogens, hourly data is needed, requiring complex models that track favorable conditions hour by hour. These models start with specific triggers and can reset due to conditions like dryness or low humidity, simulating a biological clock for infection risk assessment [@magarey2007].\n\nModeling approaches vary based on available data and model goals. A common method is the matrix approach, like the Wallin potato late blight model, which uses rows for temperature and columns for moisture duration to estimate disease severity [@krause1975] (see previous chapter on [warning systems](https://r4pde.net/prediction-warning-systems)). Bailey enhanced this with an interactive matrix that combines temperature, relative humidity, and duration to assess infection risk across pathogens, making it versatile for various modeling needs [@bailey1999].\n\nWhen infection responses are measured at various temperature and wetness combinations, regression models can be developed to predict infection rates. These models often use polynomial, logistic, or complex three-dimensional response surface equations to represent the relationship between environmental conditions and infection potential. In an excellent review title \"*How to create and deploy infection models for plant pathogen*s\" @magarey2007 discusses that many modeling approaches lack biological foundations and are not generic, making them unsuitable for developing a unified set of disease forecast models. While three-dimensional response surfaces, such as those created with sufficient temperature-moisture observations, offer detailed infection responses, they are often too complex and data-intensive for widespread use (seeTable 1 adapted from @magarey2007).\n\n| Approach                                                               | Strengths                                                                                                          | Weaknesses                                                                               |\n|-------------------|------------------------------|-----------------------|\n| Matrix [@krause1975; @mills1944; @windels1998]                         | Easy; converts moisture/temperature combinations into severity values or risk categories. Tried and true approach. | Data to populate matrix may not be readily available.                                    |\n| Regression:<br>-- Polynomial [@evans1992]<br>-- Logistic [@bulger1987] | Widely used in plant pathology. Available for many economically important pathogens.                               | Parameters not biologically based. Requires dataset for development.                     |\n| Three-dimensional response surface [@duthie1997]                       | Describes infection response in detail.                                                                            | Parameters not biologically based. Complex, requires extensive data and processing time. |\n| Degree wet hours [@pfender2003]                                        | Simple; based on degree hours, commonly used in entomology. Requires only Tmin and Tmax                            | Recently developed; assumes linear thermal response.                                     |\n| Temperature-moisture response function [@magarey2005]                  | Simple; based on crop modeling functions, requires only Tmin, Topt and Tmax                                        | Recently developed.                                                                      |\n\n: Comparison of different infection modeling approaches. Source: @magarey2007\n\nIn the following sections, I will demonstrate how various biologically meaningful models fit infection data, using temperature, wetness duration, or a combination of both as predictors.\n\n#### Temperature effects\n\n##### Generalized beta-function\n\nAmong several non-linear models that can be fitted to infection responses to temperature, the generalized beta-function is an interesting alternative [@hau1990]. This is a nonlinear model with five parameters. Two of them, namely $b$ and $c$ , have a biological meaning because they are estimates of the minimum and maximum temperature of the biological process under consideration.\n\nWe will use a subset of the data obtained from a study conducted under controlled conditions that aimed to assess the influence of temperature on the symptom development of citrus canker in sweet orange [@dallapria2006]. The data used here is only for severity on the cultivar Hamlin (plot a in @fig-temperature). The data was extracted using the R package {digitize} as shown [here on this tweet](https://twitter.com/edelponte/status/1580320409794539520?s=20&t=KqjJPmwzFVKm8Gu7Ss-P6A).\n\n![Effect of temperature (12, 15, 20, 25, 30, 35 or 40¬∞C) on disease severity of citrus canker on sweet orange cvs Hamlin (a), Natal (b), Pera (c) and Valencia (d) with a leaf wetness duration of 24 h. Each point represents the mean of three repetitions. Vertical bars represent standard errors. Lines show the generalized beta function fitted to data. Source: @dallapria2006](imgs/modeling-fig_temperature.gif){#fig-temperature fig-align=\"center\" width=\"441\"}\n\nLet's enter the data manually. Where $t$ is the temperature and $y$ is the severity on leaves.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp <- tibble::tribble(\n  ~t, ~y,\n12.0, 0.00,\n15.0, 0.1,\n20.0, 0.5,\n25.0, 1.2,\n30.0, 1.5,\n35.0, 1.2,\n40.0, 0.1\n)\n```\n:::\n\n\n\n\n\nFit the generalized beta-function [@hau1990]. The model can be written as:\n\n$$\ny = a*((t - b )^d)*((c - t)^e)\n$$\n\nwhere $b$ and $c$ represent minimum and maximum temperatures, respectively, for the development of the disease, $a$, $d$ and $e$ are parameters to be estimated, $t$ is the temperature and $y$ is disease severity. We need the {minpack.lm} library to avoid parameterization issues.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(minpack.lm)\nfit_temp <- nlsLM(\n  y ~ a * ((t - b) ^ d) * ((c - t) ^ e),\n  start = list(\n    a = 0,\n    b = 10,\n    c = 40,\n    d = 1.5,\n    e = 1\n  ),\n  algorithm = \"port\",\n  data = temp\n)\nsummary(fit_temp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: y ~ a * ((t - b)^d) * ((c - t)^e)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na  0.001303   0.006295   0.207    0.855    \nb 11.999999   4.875414   2.461    0.133    \nc 40.137236   0.346763 115.748 7.46e-05 ***\nd  1.760101   1.193017   1.475    0.278    \ne  0.830868   0.445213   1.866    0.203    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1121 on 2 degrees of freedom\n\nAlgorithm \"port\", convergence message: Relative error between `par' and the solution is at most `ptol'.\n```\n\n\n:::\n\n```{.r .cell-code}\nmodelr::rsquare(fit_temp, temp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9898275\n```\n\n\n:::\n:::\n\n\n\n\n\nStore the model parameters in objects.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_temp$m$getAllPars()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          a           b           c           d           e \n 0.00130259 11.99999931 40.13723602  1.76010097  0.83086798 \n```\n\n\n:::\n\n```{.r .cell-code}\na <- fit_temp$m$getAllPars()[1]\nb <- fit_temp$m$getAllPars()[2]\nc <- fit_temp$m$getAllPars()[3]\nd <- fit_temp$m$getAllPars()[4]\ne <- fit_temp$m$getAllPars()[5]\n```\n:::\n\n\n\n\n\nCreate a data frame for predictions at each temperature unit from 10 to 45 degree Celsius.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- seq(10, 45, 0.1)\ny <- a * ((t - b) ^ d) * ((c - t) ^ e)\ndat <- data.frame(t, y)\n```\n:::\n\n\n\n\n\nPlot the observed and predicted data using {ggplot2} package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(r4pde)\ndat |>\n  ggplot(aes(t, y)) +\n  geom_line() +\n  geom_point(data = temp, aes(t, y)) +\n  theme_r4pde(font_size = 16) +\n  labs(x = \"Temperature\", y = \"Severity\",\n       title = \"Generalized beta-function\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\n##### Analytis beta function\n\n@ji2023a tested and compared various mathematical equations to describe the response of mycelial growth to temperature for several fungi associated with Grapevine trunk diseases. The authors found that the beta equation [@analytis1977] provided the best fit and, therefore, was considered the most suitable for all fungi.\n\nThe model equation for re-scaled severity (0 to 1) as a function of temperature is given by:\n\n$Y = \\left( a \\cdot T_{eq}^b \\cdot (1 - T_{eq}) \\right)^c \\quad ; \\quad \\text{if } Y > 1, \\text{ then } Y = 1$\n\nwhere\n\n$T_{eq} = \\frac{T - T_{\\text{min}}}{T_{\\text{max}} - T_{\\text{min}}}$\n\n$T$ is the temperature in degrees Celsius. $T_{\\text{min}}$ is the minimum temperature, $T_{\\text{max}}$ is the maximum temperature for severity. The $a$ , $b$ , and $c$ are parameters that define the top, symmetry, and size of the unimodal curve.\n\nLet's rescale (0 to 1) the data on the citrus canker using the function rescale of the {scales} package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'scales'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:purrr':\n\n    discard\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n\n\n:::\n\n```{.r .cell-code}\ntemp$yscaled <- rescale(temp$y)\ntemp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 √ó 3\n      t     y yscaled\n  <dbl> <dbl>   <dbl>\n1    12   0    0     \n2    15   0.1  0.0667\n3    20   0.5  0.333 \n4    25   1.2  0.8   \n5    30   1.5  1     \n6    35   1.2  0.8   \n7    40   0.1  0.0667\n```\n\n\n:::\n:::\n\n\n\n\n\nNow we can fit the model using the same `nlsLM` function.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the minimum and maximum temperatures\nTmin <- 12\nTmax <- 40\n\nlibrary(minpack.lm)\nfit_temp2 <- nlsLM(\n  yscaled ~ (a * ((t - Tmin) / (Tmax - Tmin))^b * (1 - ((t - Tmin) / (Tmax - Tmin))))^c,\n  data = temp,\n  start = list(a = 1, b = 2, c = 3), # Initial guesses for parameters\n  algorithm = \"port\" \n)\n\nsummary(fit_temp2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: yscaled ~ (a * ((t - Tmin)/(Tmax - Tmin))^b * (1 - ((t - Tmin)/(Tmax - \n    Tmin))))^c\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \na   6.7625     0.3218  21.013 3.03e-05 ***\nb   1.9648     0.1030  19.072 4.45e-05 ***\nc   1.1607     0.1507   7.701  0.00153 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03955 on 4 degrees of freedom\n\nAlgorithm \"port\", convergence message: Relative error in the sum of squares is at most `ftol'.\n```\n\n\n:::\n\n```{.r .cell-code}\nmodelr::rsquare(fit_temp2, temp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9948325\n```\n\n\n:::\n:::\n\n\n\n\n\nLets's store the model parameters in objects.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_temp2$m$getAllPars()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       a        b        c \n6.762509 1.964817 1.160702 \n```\n\n\n:::\n\n```{.r .cell-code}\na <- fit_temp2$m$getAllPars()[1]\nb <- fit_temp2$m$getAllPars()[2]\nc <- fit_temp2$m$getAllPars()[3]\n```\n:::\n\n\n\n\n\nAgain, we create a data frame for predictions at each temperature unit from 10 to 45 degree Celsius.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTmin <- 12\nTmax <- 40\nt <- seq(10, 45, 0.1)\ny <- (a * ((t - Tmin) / (Tmax - Tmin))^b * (1 - ((t - Tmin) / (Tmax - Tmin))))^c\ndat2 <- data.frame(t, y)\n```\n:::\n\n\n\n\n\nAnd now we can plot the observed and predicted data using {ggplot2} package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(r4pde)\ndat2 |>\n  ggplot(aes(t, y)) +\n  geom_line() +\n  geom_point(data = temp, aes(t, yscaled)) +\n  theme_r4pde(font_size = 16) +\n  labs(x = \"Temperature\", y = \"Scaled severity\", \n       title = \"Analytis beta function\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n#### Moisture effects\n\n##### Monomolecular function\n\nFor this example, we will use a subset of the data obtained from a study conducted under controlled conditions that aimed to assess the effects of moisture duration on the symptom development of citrus canker in sweet orange [@dallapria2006]. As in the previous example for temperature effects, the data used here is only for severity on the cultivar Hamlin (plot a in @fig-moisture). The data was also extracted using the R package digitize.\n\nLet's look at the original data and the predictions by the model fitted in the paper.\n\n![Effect of leaf wetness duration (0, 4, 8, 12, 16, 20 or 24 h) on disease severity of citrus canker on sweet orange cvs Hamlin (a), Natal (b), Pera (c) and Valencia (d) at 30¬∞C. Each point represents the mean of three repetitions. Vertical bars represent standard errors. Lines show the monomolecular model fitted to data. Source: @dallapria2006](imgs/modeling-fig2.gif){#fig-moisture fig-align=\"center\" width=\"516\"}\n\nFor this pattern in the data, we will fit a three-parameter asymptotic regression model. These models describe a limited growth, where y approaches an horizontal asymptote as x tends to infinity. This equation is also known as Monomolecular Growth, Mitscherlich law or von Bertalanffy law. See [this tutorial](https://www.statforbiology.com/nonlinearregression/usefulequations) for comprehensive information about fitting several non-linear regression models in R.\n\nAgain, we enter the data manually. The ùë•x is wetness duration in hours and ùë¶y is severity.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwet <- tibble::tribble(~ x, ~ y,\n                       0 ,  0,\n                       4 ,  0.50,\n                       8 ,  0.81,\n                       12,  1.50,\n                       16,  1.26,\n                       20,  2.10,\n                       24,  1.45)\n```\n:::\n\n\n\n\n\nThe model can be written as:\n\n$y = c1 + (d1-c1)*(1-exp(-x/e1))$\n\nwhere $c$ is the lower limit (at $x = 0$), the parameter $d$ is the upper limit and the parameter $e$ (greater than 0) is determining the steepness of the increase as $x$.\n\nWe will solve the model again using the `nlsLM` function. We should provide initial values for the three parameters.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_wet <- nlsLM(y ~ c1 + (d1 - c1) * (1 - exp(-x / e1)),\n                 start = list(c1 = 0.5,\n                              d1 = 3,\n                              e1 = 1),\n                 data = wet)\n\nsummary(fit_wet)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: y ~ c1 + (d1 - c1) * (1 - exp(-x/e1))\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)  \nc1 -0.04898    0.31182  -0.157   0.8828  \nd1  2.00746    0.70594   2.844   0.0467 *\ne1 11.63694    9.33183   1.247   0.2804  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3296 on 4 degrees of freedom\n\nNumber of iterations to convergence: 7 \nAchieved convergence tolerance: 1.49e-08\n```\n\n\n:::\n\n```{.r .cell-code}\nmodelr::rsquare(fit_wet, wet)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8532282\n```\n\n\n:::\n:::\n\n\n\n\n\nStore the value of the parameters in the respective object.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHW <- seq(0, 24, 0.1)\nc1 <-  fit_wet$m$getAllPars()[1]\nd1 <- fit_wet$m$getAllPars()[2]\ne1 <- fit_wet$m$getAllPars()[3]\ny <-  (c1 + (d1 - c1) * (1 - exp(-HW / e1)))\ndat2 <- data.frame(HW, y)\n```\n:::\n\n\n\n\n\nNow we can plot the predictions and the original data.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 |>\n  ggplot(aes(HW, y)) +\n  geom_line() +\n  geom_point(data = wet, aes(x, y)) +\n  theme_r4pde(font_size = 16) +\n  labs(x = \"Wetness duration\", y = \"Severity\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n\n##### Weibull function\n\nIn the study by [@ji2021; @ji2023a], a Weibull model was fitted to the re-scaled data (0 to 1) on the effect of moisture duration on spore germination or infection. Let's keep working with the re-scaled data on the citrus canker.\n\nThe model is given by:\n\n$y = 1 - \\exp(-(a \\cdot x)^b)$\n\nwhere $y$ is the response variable, $x$ is the moist duration, $a$ is the scale parameter influencing the rate of infection and $b$ is the shape parameter affecting the curve's shape and acceleration\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwet$yscaled <- rescale(wet$y) \nwet\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 √ó 3\n      x     y yscaled\n  <dbl> <dbl>   <dbl>\n1     0  0      0    \n2     4  0.5    0.238\n3     8  0.81   0.386\n4    12  1.5    0.714\n5    16  1.26   0.6  \n6    20  2.1    1    \n7    24  1.45   0.690\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_wet2 <- nlsLM(\n  yscaled ~ 1 - exp(-(a * x)^b),\n  data = wet,\n  start = list(a = 1, b = 2),  # Initial guesses for parameters a and b\n  )\nsummary(fit_wet2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: yscaled ~ 1 - exp(-(a * x)^b)\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)   \na  0.07684    0.01296    5.93  0.00195 **\nb  1.07610    0.37103    2.90  0.03378 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1404 on 5 degrees of freedom\n\nNumber of iterations to convergence: 26 \nAchieved convergence tolerance: 1.49e-08\n```\n\n\n:::\n\n```{.r .cell-code}\nmodelr::rsquare(fit_wet2, wet)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8534077\n```\n\n\n:::\n:::\n\n\n\n\n\nSet the value of the parameters in the respective objects\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- seq(0, 24, 0.1)\na <-  fit_wet2$m$getAllPars()[1]\nb <- fit_wet2$m$getAllPars()[2]\ny <-  1 - exp(-(a * x)^b)\ndat3 <- data.frame(x, y)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3 |>\n  ggplot(aes(x, y)) +\n  geom_line() +\n  geom_point(data = wet, aes(x, yscaled)) +\n  theme_r4pde(font_size = 16) +\n  labs(x = \"Wetness duration\", y = \"Scaled severity\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n\n\n#### Integrating temperature and wetness effects\n\nThe equations developed for the separate effects can be integrated to create a surface response curve or a simple contour plot. Let's first integrate the generalized beta and the monomolecular models for the original severity data for the citrus canker experiment.\n\nFirst, we need a data frame for the interaction between temperature $t$ and hours of wetness $hw$. Then, we obtain the disease value for each combination of $t$ and $hw$.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- rep(1:40, 40)\nhw <- rep(1:40, each = 40)\n\n# let's fit the two models again and store the parameters in objects\n# Temperature effects\nfit_temp <- nlsLM(\n  y ~ a * ((t - b) ^ d) * ((c - t) ^ e),\n  start = list(\n    a = 0,\n    b = 10,\n    c = 40,\n    d = 1.5,\n    e = 1\n  ),\n  algorithm = \"port\",\n  data = temp\n)\nfit_temp$m$getAllPars()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          a           b           c           d           e \n 0.00130259 11.99999931 40.13723602  1.76010097  0.83086798 \n```\n\n\n:::\n\n```{.r .cell-code}\na <- fit_temp$m$getAllPars()[1]\nb <- fit_temp$m$getAllPars()[2]\nc <- fit_temp$m$getAllPars()[3]\nd <- fit_temp$m$getAllPars()[4]\ne <- fit_temp$m$getAllPars()[5]\n\n## Moist duration effects\nfit_wet <- nlsLM(y ~ c1 + (d1 - c1) * (1 - exp(-x / e1)),\n                 start = list(c1 = 0.5,\n                              d1 = 3,\n                              e1 = 1),\n                 data = wet)\n\nc1 <-  fit_wet$m$getAllPars()[1]\nd1 <- fit_wet$m$getAllPars()[2]\ne1 <- fit_wet$m$getAllPars()[3]\n\ndis <-\n  (a * (t - b) ^ d) * ((c - t) ^ e) * (c1 + (d1 - c1) * (1 - exp(- hw / e1)))\nvalidation <- data.frame(t, hw, dis)\n```\n:::\n\n\n\n\n\nNow the contour plot can be visualized using {ggplot2} and {geomtextpath} packages.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(geomtextpath)\nggplot(validation, aes(t, hw, z = dis)) +\n  geom_contour_filled(bins = 8, alpha = 0.7) +\n  geom_textcontour(bins = 8,\n                   size = 2.5,\n                   padding = unit(0.05, \"in\")) +\n  theme_light(base_size = 10) +\n  theme(legend.position = \"right\") +\n  ylim(0, 40) +\n  labs(y = \"Wetness duration (hours)\",\n       fill = \"Severity\",\n       x = \"Temperature (Celcius)\",\n       title = \"Integrating generalized beta and monomolecular\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n\n\n\nIn the second example, let's integrate the Analytis beta and the Weibull model:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_temp2 <- nlsLM(\n  yscaled ~ (a * ((t - Tmin) / (Tmax - Tmin))^b * (1 - ((t - Tmin) / (Tmax - Tmin))))^c,\n  data = temp,\n  start = list(a = 1, b = 2, c = 3), # Initial guesses for parameters\n  algorithm = \"port\" \n)\n\nfit_temp2$m$getAllPars()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       a        b        c \n6.762509 1.964817 1.160702 \n```\n\n\n:::\n\n```{.r .cell-code}\na2 <- fit_temp2$m$getAllPars()[1]\nb2 <- fit_temp2$m$getAllPars()[2]\nc2 <- fit_temp2$m$getAllPars()[3]\n\n\nfit_wet2 <- nlsLM(\n  yscaled ~ 1 - exp(-(d * x)^e),\n  data = wet,\n  start = list(d = 1, e = 2),  # Initial guesses for parameters a and b\n  )\n\nd2 <-  fit_wet2$m$getAllPars()[1]\ne2 <- fit_wet2$m$getAllPars()[2]\n\nTmin <- 12\nTmax <- 40\ndis2 <-  (a2 * ((t - Tmin) / (Tmax - Tmin))^b2 * (1 - ((t - Tmin) / (Tmax - Tmin))))^c2 * 1 - exp(-(d2 * hw)^e2)\n\nt <- rep(1:40, 40)\nhw <- rep(1:40, each = 40)\nvalidation2 <- data.frame(t, hw, dis2)\n\nvalidation2 <- validation2 |> \n  filter(dis2 != \"NaN\") |> \n  mutate(dis2 = case_when(dis2 < 0 ~ 0,\n                          TRUE ~ dis2))\n```\n:::\n\n\n\n\n\nNow the plot.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(validation2, aes(t, hw, z = dis2)) +\n  geom_contour_filled(bins = 7, alpha = 0.7) +\n  geom_textcontour(bins = 7,\n                   size = 2.5,\n                   padding = unit(0.05, \"in\")) +\n  theme_light(base_size = 10) +\n  theme(legend.position = \"right\") +\n  ylim(0, 40) +\n  labs(y = \"Wetness duration (hours)\",\n       fill = \"Severity\",\n       x = \"Temperature (Celcius)\",\n       title = \"Integrating generalized beta and monomolecular\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\n\nWe can create a 3D surface plot to visualize the predictions, as [it was used in the original paper](https://bsppjournals.onlinelibrary.wiley.com/cms/asset/0acf45ce-bad8-4a49-9a17-181836aa9876/ppa_1393_f3.gif). Note that In `plot_ly`, a 3D surface plot requires a matrix or grid format for the `z` values, with corresponding vectors for `x` and `y` values that define the axes. If the data frame (`validation2`) has three columns (`t`, `hw`, and `dis2`), we'll need to convert `dis2` into a matrix format that `plot_ly` can interpret for a surface plot.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plotly)\nlibrary(reshape2)  \nz_matrix <- acast(validation2, hw ~ t, value.var = \"dis2\")\nx_vals <- sort(unique(validation2$t))  \ny_vals <- sort(unique(validation2$hw)) \n\nplot_ly(x = ~x_vals, y = ~y_vals, z = ~z_matrix, type = \"surface\") |> \n    config(displayModeBar = FALSE) |> \n  layout(\n    scene = list(\n      xaxis = list(title = \"Temperature (¬∞C)\", nticks = 10),\n      yaxis = list(title = \"Wetness Duration (hours)\", range = c(0, 40)),\n      zaxis = list(title = \"Severity\"),\n      aspectratio = list(x = 1, y = 1, z = 1)  \n    ),\n    title = \"Integrating Generalized Beta and Monomolecular\"\n  )\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-3054de54d5d469964b09\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3054de54d5d469964b09\">{\"x\":{\"visdat\":{\"f32dc26a478\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"f32dc26a478\",\"attrs\":{\"f32dc26a478\":{\"x\":{},\"y\":{},\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"surface\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"Temperature (¬∞C)\",\"nticks\":10},\"yaxis\":{\"title\":\"Wetness Duration (hours)\",\"range\":[0,40]},\"zaxis\":{\"title\":\"Severity\"},\"aspectratio\":{\"x\":1,\"y\":1,\"z\":1}},\"title\":\"Integrating Generalized Beta and Monomolecular\",\"hovermode\":\"closest\",\"showlegend\":false,\"legend\":{\"yanchor\":\"top\",\"y\":0.5}},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false,\"displayModeBar\":false},\"data\":[{\"colorbar\":{\"title\":\"z_matrix\",\"ticklen\":2,\"len\":0.5,\"lenmode\":\"fraction\",\"y\":1,\"yanchor\":\"top\"},\"colorscale\":[[\"0\",\"rgba(68,1,84,1)\"],[\"0.0416666666666667\",\"rgba(70,19,97,1)\"],[\"0.0833333333333333\",\"rgba(72,32,111,1)\"],[\"0.125\",\"rgba(71,45,122,1)\"],[\"0.166666666666667\",\"rgba(68,58,128,1)\"],[\"0.208333333333333\",\"rgba(64,70,135,1)\"],[\"0.25\",\"rgba(60,82,138,1)\"],[\"0.291666666666667\",\"rgba(56,93,140,1)\"],[\"0.333333333333333\",\"rgba(49,104,142,1)\"],[\"0.375\",\"rgba(46,114,142,1)\"],[\"0.416666666666667\",\"rgba(42,123,142,1)\"],[\"0.458333333333333\",\"rgba(38,133,141,1)\"],[\"0.5\",\"rgba(37,144,140,1)\"],[\"0.541666666666667\",\"rgba(33,154,138,1)\"],[\"0.583333333333333\",\"rgba(39,164,133,1)\"],[\"0.625\",\"rgba(47,174,127,1)\"],[\"0.666666666666667\",\"rgba(53,183,121,1)\"],[\"0.708333333333333\",\"rgba(79,191,110,1)\"],[\"0.75\",\"rgba(98,199,98,1)\"],[\"0.791666666666667\",\"rgba(119,207,85,1)\"],[\"0.833333333333333\",\"rgba(147,214,70,1)\"],[\"0.875\",\"rgba(172,220,52,1)\"],[\"0.916666666666667\",\"rgba(199,225,42,1)\"],[\"0.958333333333333\",\"rgba(226,228,40,1)\"],[\"1\",\"rgba(253,231,37,1)\"]],\"showscale\":true,\"x\":[12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"y\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40],\"z\":[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.02094769419669118,0.057384573392527005,0.077230207094710956,0.07825867633143424,0.058386691236345878,0.015730531737265907,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.033762750183378376,0.084465106104958942,0.12090198530079477,0.14074761900297872,0.141776088239702,0.12190410314461364,0.079247943645533669,0.012203730301255322,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.032721049345398212,0.095297112936580941,0.14599946885816151,0.18243634805399733,0.20228198175618128,0.20331045099290457,0.18343846589781621,0.14078230639873623,0.073738093054457887,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0.019351164493891182,0.091371292937351245,0.15394735652853397,0.20464971245011454,0.24108659164595037,0.26093222534813432,0.2619606945848576,0.24208870948976924,0.19943254999068927,0.13238833664641092,0.039753055455259867,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0.074790334464367558,0.14681046290782762,0.20938652649901035,0.26008888242059092,0.29652576161642674,0.31637139531861069,0.31739986455533398,0.29752787946024561,0.25487171996116564,0.1878275066168873,0.095192225425736243,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0.047900348408809412,0.12692154040745374,0.1989416688509138,0.26151773244209653,0.3122200883636771,0.34865696755951292,0.36850260126169687,0.36953107049842016,0.34965908540333179,0.30700292590425182,0.23995871255997347,0.14732343136882242,0.02849331986577186,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0.013153337835403289,0.096741647036678424,0.17576283903532275,0.24778296747878281,0.31035903106996554,0.36106138699154611,0.39749826618738193,0.41734389988956588,0.41837236912628917,0.3985003840312008,0.35584422453212083,0.28880001118784249,0.19616472999669143,0.077334618493640872,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0.058786208227948555,0.14237451742922369,0.22139570942786801,0.29341583787132808,0.35599190146251081,0.40669425738409137,0.4431311365799272,0.46297677028211115,0.46400523951883443,0.44413325442374607,0.4014770949246661,0.33443288158038775,0.2417976003892367,0.12296748888618614,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0.015576471294716288,0.10132851368416285,0.18491682288543798,0.26393801488408231,0.33595814332754237,0.3985342069187251,0.44923656284030566,0.48567344203614149,0.50551907573832544,0.50654754497504872,0.48667555987996036,0.44401940038088039,0.37697518703660204,0.28433990584545099,0.16550979434240043,0.020844086241465498,0,0,0],[0,0,0,0,0,0,0,0,0,0,0.055166793718540497,0.14091883610798706,0.22450714530926219,0.30352833730790652,0.37554846575136658,0.43812452934254931,0.48882688526412987,0.5252637644599657,0.54510939816214965,0.54613786739887293,0.52626588230378457,0.4836097228047046,0.41656550946042625,0.3239302282692752,0.20510011676622464,0.060434408665289707,0,0,0],[0,0,0,0,0,0,0,0,0,0.0063901154447196795,0.091954749465308683,0.17770679185475524,0.26129510105603038,0.3403162930546747,0.41233642149813476,0.47491248508931749,0.52561484101089806,0.56205172020673388,0.58189735390891784,0.58292582314564112,0.56305383805055276,0.52039767855147279,0.45335346520719444,0.36071818401604339,0.24188807251299282,0.097222364412057893,0,0,0],[0,0,0,0,0,0,0,0,0,0.040530108536979637,0.12609474255756864,0.2118467849470152,0.29543509414829033,0.37445628614693466,0.44647641459039472,0.50905247818157751,0.55975483410315796,0.59619171329899379,0.61603734700117774,0.61706581623790102,0.59719383114281266,0.55453767164373269,0.4874934582994544,0.39485817710830334,0.27602806560525278,0.13136235750431785,0,0,0],[0,0,0,0,0,0,0,0,0,0.072177193123197814,0.15774182714378682,0.24349386953323338,0.32708217873450851,0.40610337073315284,0.4781234991766129,0.54069956276779563,0.59140191868937619,0.62783879788521202,0.64768443158739597,0.64871290082411925,0.62884091572903089,0.58618475622995092,0.51914054288567257,0.42650526169452152,0.30767515019147096,0.16300944209053603,0,0,0],[0,0,0,0,0,0,0,0,0.01838298596195681,0.10148429602157627,0.18704893004216527,0.27280097243161183,0.35638928163288697,0.43541047363153129,0.50743060207499135,0.57000666566617408,0.62070902158775465,0.65714590078359048,0.67699153448577443,0.67802000372249771,0.65814801862740935,0.61549185912832938,0.54844764578405103,0.45581236459289998,0.33698225308984942,0.19231654498891448,0.023924353357387018,0,0],[0,0,0,0,0,0,0,0,0.045499040038879945,0.12860035009849941,0.21416498411908841,0.29991702650853497,0.3835053357098101,0.46252652770845443,0.53454665615191455,0.59712271974309727,0.64782507566467773,0.68426195486051355,0.70410758856269751,0.70513605779942079,0.68526407270433243,0.64260791320525246,0.57556369986097411,0.48292841866982311,0.36409830716677255,0.21943259906583762,0.051040407434310153,0,0],[0,0,0,0,0,0,0,0,0.070567745388693814,0.15366905544831327,0.23923368946890228,0.32498573185834884,0.40857404105962397,0.4875952330582683,0.5596153615017283,0.62219142509291103,0.67289378101449171,0.70933066021032753,0.72917629391251149,0.73020476314923477,0.71033277805414641,0.66767661855506644,0.60063240521078809,0.50799712401963704,0.38916701251658642,0.24450130441565149,0.076109112784124022,0,0],[0,0,0,0,0,0,0,0.015263810909302455,0.093726772667315661,0.17682808272693512,0.26239271674752412,0.34814475913697068,0.43173306833824582,0.5107542603368902,0.58277438878035026,0.64535045237153299,0.69605280829311345,0.73248968748894927,0.75233532119113322,0.75336379042785651,0.73349180533276814,0.69083564583368817,0.62379143248940983,0.53115615129825877,0.41232603979520827,0.26766033169427333,0.099268140062745869,0,0],[0,0,0,0,0,0,0,0.036644320947556125,0.11510728270556933,0.19820859276518879,0.28377322678577777,0.36952526917522432,0.45311357837649946,0.53213477037514378,0.60415489881860385,0.66673096240978658,0.71743331833136714,0.75387019752720297,0.77371583122938692,0.7747443004661102,0.75487231537102184,0.71221615587194187,0.64517194252766352,0.55253666133651247,0.43370654983346191,0.28904084173252698,0.12064865010099954,0,0],[0,0,0,0,0,0,0,0.056370712932708872,0.13483367469072208,0.21793498475034154,0.30349961877093057,0.38925166116037713,0.47283997036165226,0.55186116236029659,0.62388129080375665,0.68645735439493938,0.73715971031651994,0.77359658951235577,0.79344222321453972,0.79447069245126301,0.77459870735617464,0.73194254785709467,0.66489833451281632,0.57226305332166527,0.45343294181861471,0.30876723371767978,0.14037504208615229,0,0],[0,0,0,0,0,0,0.00277978758305511,0.074560538647362284,0.15302350040537549,0.23612481046499495,0.32168944448558395,0.40744148687503051,0.49102979607630565,0.57005098807495003,0.64207111651841009,0.70464718010959282,0.75534953603117327,0.7917864152270091,0.81163204892919305,0.81266051816591633,0.79278853307082797,0.750132373571748,0.68308816022746965,0.5904528790363186,0.47162276753326809,0.32695705943233316,0.1585648678008057,0,0],[0,0,0,0,0,0,0.019543786321871592,0.091324537386178767,0.16978749914419197,0.2528888092038114,0.33845344322440041,0.42420548561384697,0.5077937948151221,0.58681498681376643,0.65883511525722649,0.72141117884840922,0.77211353476998978,0.80855041396582561,0.82839604766800956,0.82942451690473284,0.80955253180964448,0.76689637231056451,0.69985215896628616,0.60721687777513511,0.48838676627208455,0.34372105817114962,0.17532886653962218,0,0],[0,0,0,0,0,0,0.03498600704806859,0.10676675811237576,0.18522971987038897,0.26833102993000846,0.35389566395059746,0.43964770634004402,0.52323601554131915,0.60225720753996348,0.67427733598342354,0.73685339957460627,0.78755575549618684,0.82399263469202266,0.84383826839420661,0.8448667376309299,0.82499475253584154,0.78233859303676156,0.71529437969248322,0.62265909850133216,0.5038289869982816,0.35916327889734667,0.19077108726581918,0.0047806809139954998,0],[0,0,0,0,0,0,0.049203992857864254,0.12098474392217143,0.19944770568018463,0.28254901573980407,0.36811364976039307,0.45386569214983963,0.53745400135111476,0.61647519334975909,0.68849532179321915,0.75107138538440188,0.80177374130598245,0.83821062050181827,0.85805625420400222,0.85908472344072551,0.83921273834563714,0.79655657884655717,0.72951236550227883,0.63687708431112777,0.51804697280807721,0.37338126470714228,0.20498907307561484,0.018998666723791163,0],[0,0,0,0,0,0,0.062289008994899864,0.13406976005920704,0.21253272181722024,0.29563403187683968,0.38119866589742868,0.46695070828687524,0.55053901748815037,0.6295602094867947,0.70158033793025476,0.76415640152143749,0.81485875744301806,0.85129563663885388,0.87114127034103783,0.87216973957776112,0.85229775448267275,0.80964159498359278,0.74259738163931444,0.64996210044816338,0.53113198894511282,0.38646628084417789,0.21807408921265045,0.032083682860826773,0],[0,0,0,0,0,0.011102566524349433,0.07432630021057221,0.14610705127487938,0.22457001303289259,0.30767132309251205,0.39323595711310105,0.47898799950254761,0.56257630870382269,0.64159750070246702,0.71361762914592708,0.77619369273710981,0.82689604865869049,0.86333292785452631,0.88317856155671026,0.88420703079343355,0.86433504569834518,0.82167888619926521,0.75463467285498687,0.66199939166383581,0.54316928016078525,0.39850357205985026,0.2301113804283228,0.04412097407649912,0],[0,0,0,0,0,0.022171632985838144,0.085395366672060921,0.15717611773636808,0.23563907949438129,0.31874038955400075,0.40430502357458975,0.49005706596403631,0.57364537516531144,0.65266656716395577,0.72468669560741583,0.78726275919859856,0.83796511512017913,0.87440199431601495,0.8942476280181989,0.89527609725492219,0.87540411215983382,0.83274795266075385,0.76570373931647551,0.67306845812532445,0.55423834662227389,0.40957263852133896,0.2411804468898115,0.055190040537987831,0],[0,0,0,0,0,0.032346516511015541,0.095570250197238318,0.16735100126154551,0.24581396301955871,0.32891527307917817,0.41447990709976718,0.50023194948921368,0.58382025869048881,0.66284145068913314,0.7348615791325932,0.79743764272377593,0.8481399986453565,0.88457687784119232,0.90442251154337627,0.90545098078009956,0.88557899568501119,0.84292283618593122,0.77587862284165288,0.68324334165050182,0.56441323014745126,0.41974752204651639,0.25135533041498892,0.065364924063165228,0],[0,0,0,0,0,0.041696090879320358,0.10491982456554313,0.17670057562985031,0.25516353738786351,0.33826484744748297,0.42382948146807198,0.50958152385751854,0.59316983305879367,0.672191025057438,0.74421115350089806,0.80678721709208079,0.85748957301366135,0.89392645220949718,0.91377208591168113,0.91480055514840442,0.89492857005331605,0.85227241055423608,0.78522819720995773,0.69259291601880668,0.57376280451575612,0.42909709641482119,0.26070490478329372,0.074714498431470044,0],[0,0,0,0,0,0.050284351485636744,0.11350808517185952,0.18528883623616671,0.26375179799417992,0.34685310805379937,0.43241774207438838,0.51816978446383488,0.60175809366511002,0.68077928566375434,0.7527994141072144,0.81537547769839713,0.8660778336199777,0.90251471281581352,0.92236034651799748,0.92338881575472076,0.9035168306596324,0.86086067116055243,0.79381645781627408,0.70118117662512303,0.58235106512207246,0.43768535702113759,0.26929316538961012,0.083302759037786431,0],[0,0,0,0,0.0051589357518163903,0.05817070078167938,0.12139443446790216,0.19317518553220933,0.27163814729022251,0.35473945734984202,0.44030409137043103,0.52605613375987759,0.60964444296115272,0.68866563495979705,0.76068576340325711,0.82326182699443984,0.8739641829160204,0.91040106211185623,0.93024669581404018,0.93127516505076346,0.9114031799556751,0.86874702045659513,0.80170280711231678,0.70906752592116573,0.59023741441811517,0.44557170631718024,0.27717951468565272,0.091189108333829066,0],[0,0,0,0,0.012398461837509894,0.065410226867372884,0.12863396055359566,0.20041471161790284,0.27887767337591607,0.36197898343553547,0.44754361745612448,0.53329565984557104,0.61688396904684617,0.69590516104549049,0.76792528948895056,0.83050135308013329,0.88120370900171385,0.91764058819754968,0.93748622189973363,0.93851469113645691,0.91864270604136855,0.87598654654228858,0.80894233319801023,0.71630705200685918,0.59747694050380862,0.45281123240287369,0.28441904077134628,0.09842863441952257,0],[0,0,0,0,0.019042208283160125,0.072053973313023115,0.13527770699924591,0.20705845806355305,0.28552141982156626,0.36862272988118572,0.45418736390177472,0.53993940629122128,0.62352771549249641,0.70254890749114074,0.7745690359346008,0.83714509952578353,0.8878474554473641,0.92428433464319992,0.94412996834538387,0.94515843758210716,0.9252864524870188,0.88263029298793882,0.81558607964366048,0.72295079845250942,0.60412068694945886,0.45945497884852393,0.29106278721699647,0.1050723808651728,0],[0,0,0,0,0.025137433826495428,0.078149198856358418,0.14137293254258121,0.21315368360688836,0.29161664536490156,0.37471795542452102,0.46028258944511002,0.54603463183455658,0.62962294103583172,0.70864413303447604,0.78066426147793611,0.84324032506911883,0.8939426809906994,0.93037956018653523,0.95022519388871918,0.95125366312544246,0.9313816780303541,0.88872551853127413,0.82168130518699578,0.72904602399584473,0.61021591249279417,0.46555020439185923,0.29715801276033177,0.1111676064085081,0],[0,0,0,0,0.030727861030684547,0.083739626060547537,0.14696335974677033,0.21874411081107747,0.29720707256909068,0.38030838262871014,0.46587301664929914,0.5516250590387457,0.63521336824002084,0.71423456023866516,0.78625468868212522,0.84883075227330795,0.89953310819488852,0.93596998739072435,0.9558156210929083,0.95684409032963158,0.93697210523454322,0.89431594573546325,0.8272717323911849,0.73463645120003385,0.61580633969698328,0.47114063159604835,0.30274843996452089,0.11675803361269722,0],[0,0,0,0,0.035853913336002567,0.088865678365865564,0.15208941205208834,0.22387016311639552,0.30233312487440872,0.38543443493402818,0.47099906895461718,0.55675111134406374,0.64033942054533888,0.7193606125439832,0.79138074098744327,0.85395680457862599,0.90465916050020656,0.94109603969604239,0.96094167339822634,0.96197014263494962,0.94209815753986126,0.89944199804078129,0.83239778469650294,0.73976250350535189,0.62093239200230133,0.47626668390136639,0.30787449226983893,0.12188408591801525,0],[0,0,0,0,0.040552940208821664,0.093564705238684653,0.15678843892490743,0.22856918998921461,0.30703215174722781,0.39013346180684727,0.47569809582743627,0.56145013821688283,0.64503844741815797,0.72405963941680229,0.79607976786026236,0.85865583145144508,0.90935818737302565,0.94579506656886148,0.96564070027104543,0.96666916950776871,0.94679718441268035,0.90414102491360038,0.83709681156932203,0.74446153037817098,0.62563141887512042,0.48096571077418548,0.31257351914265802,0.12658311279083434,0],[0,0,0,0.0034205901615469714,0.04485943030253603,0.097871195332399019,0.1610949290186218,0.23287568008292897,0.31133864184094218,0.39443995190056164,0.48000458592115064,0.56575662831059725,0.64934493751187228,0.7283661295105166,0.80038625795397667,0.86296232154515939,0.91366467746674007,0.9501015566625759,0.96994719036475985,0.97097565960148313,0.95110367450639477,0.9084475150073148,0.84140330166303645,0.7487680204718854,0.62993790896883484,0.48527220086789985,0.31688000923637238,0.13088960288454871,0],[0,0,0,0.0073663725670417776,0.048805212708030836,0.10181697773789383,0.16504071142411661,0.23682146248842378,0.31528442424643699,0.39838573430605645,0.48395036832664545,0.56970241071609196,0.65329071991736709,0.73231191191601142,0.80433204035947148,0.86690810395065421,0.91761045987223477,0.9540473390680706,0.97389297277025455,0.97492144200697783,0.95504945691188947,0.9123932974128095,0.84534908406853115,0.7527138028773801,0.63388369137432954,0.48921798327339466,0.3208257916418672,0.13483538529004352,0],[0,0,0,0.010980806354981956,0.052419646495971015,0.105431411525834,0.16865514521205677,0.24043589627636397,0.31889885803437718,0.40200016809399663,0.48756480211458564,0.5733168445040322,0.65690515370530733,0.73592634570395166,0.80794647414741172,0.87052253773859445,0.92122489366017501,0.95766177285601084,0.97750740655819479,0.97853587579491808,0.95866389069982971,0.91600773120074974,0.84896351785647139,0.75632823666532034,0.63749812516226978,0.49283241706133485,0.32444022542980738,0.1384498190779837,0],[0,0,0,0.014290958706145059,0.055729798847134117,0.1087415638769971,0.17196529756321988,0.24374604862752705,0.32220901038554028,0.40531032044515974,0.49087495446574875,0.57662699685519525,0.66021530605647039,0.73923649805511471,0.81125662649857477,0.8738326900897575,0.92453504601133807,0.96097192520717389,0.98081755890935785,0.98184602814608113,0.96197404305099277,0.9193178835519128,0.85227367020763445,0.7596383890164834,0.64080827751343283,0.49614256941249796,0.32775037778097049,0.14175997142914679,0]],\"type\":\"surface\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n#### Magarey's generic infection model\n\nIn the early 2000s, Magarey and collaborators [@magarey2005] proposed a generic infection model for foliar fungal pathogens, designed to predict infection periods based on limited data on temperature and wetness requirements. The model uses cardinal temperatures (minimum, optimum, maximum) and the minimum wetness duration (Wmin) necessary for infection. The model can incorporate inputs based on estimated cardinal temperatures and surface wetness duration. These values are available for numerous pathogens and can be consulted in the literature (See table 2 of the paper by @magarey2005).\n\nThe model utilizes a temperature response function, which is adjusted to the pathogen's minimum and optimum wetness duration needs, allowing it to be broadly applicable even with limited data on specific pathogens. The model was validated with data from 53 studies, showing good accuracy and adaptability, even for pathogens lacking comprehensive data [@magarey2005].\n\nThe function is given by\n\n$f(T) = \\left( \\frac{T_{\\text{max}} - T}{T_{\\text{max}} - T_{\\text{opt}}} \\right)^{\\frac{T_{\\text{opt}} - T_{\\text{min}}}{T_{\\text{max}} - T_{\\text{opt}}}} \\times \\left( \\frac{T - T_{\\text{min}}}{T_{\\text{opt}} - T_{\\text{min}}} \\right)^{\\frac{T_{\\text{opt}} - T_{\\text{min}}}{T_{\\text{opt}} - T_{\\text{min}}}}$\n\nwhere $T$ is the temperature, $T_{\\text{min}}$ is the minimum temperature, $T_{\\text{opt}}$ is the optimum temperature, and $T_{\\text{max}}$ is the maximum temperature for infection.\n\nThe wetness duration requirement is given by\n\n$W(T) = \\frac{W_{\\text{min}}}{f(T)} \\leq W_{\\text{max}}$\n\nwhere $W_{\\text{min}}$ is the minimum wetness duration requirement, and $W_{\\text{max}}$ is an optional upper limit on $W(T)$.\n\nLet's write the functions for estimating the required wetness duration at each temperature.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemp_response <- function(T, Tmin, Topt, Tmax) {\n  if (T < Tmin || T > Tmax) {\n    return(0)\n  } else {\n    ((Tmax - T) / (Tmax - Topt))^((Topt - Tmin) / (Tmax - Topt)) * \n    ((T - Tmin) / (Topt - Tmin))^((Topt - Tmin) / (Topt - Tmin))\n  }\n}\n\n# Define the function to calculate wetness duration requirement W(T)\nwetness_duration <- function(T, Wmin, Tmin, Topt, Tmax, Wmax = Inf) {\n  f_T <- temp_response(T, Tmin, Topt, Tmax)\n  if (f_T == 0) {\n    return(0)  # Infinite duration required if outside temperature range\n  }\n  W <- Wmin / f_T\n  return(min(W, Wmax))  # Apply Wmax as an upper limit if specified\n}\n```\n:::\n\n\n\n\n\nLet's set the parameters for the fungus *Venturia inaequalis*, the cause of apple scab.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters for Venturia inaequalis (apple scab)\nT <- seq(0, 35, by = 0.5) \nWmin <- 6                  \nTmin <- 1                  \nTopt <- 20                 \nTmax <- 35                 \nWmax <- 40.5                \n\n# Calculate wetness duration required at each temperature\nW_T <- sapply(T, wetness_duration, Wmin, Tmin, Topt, Tmax, Wmax)\n\ntemperature_data_applescab <- data.frame(\n  Temperature = T,\n  Wetness_Duration = W_T\n)\n```\n:::\n\n\n\n\n\nAnd now the parameters for the fungus *Phakopsora pachyrhizi*, the cause of soybean rust in soybean.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Parameters for Phakposora pachyrhizi\nT <- seq(0, 35, by = 0.5)  \nWmin <- 8                \nTmin <- 10                  \nTopt <- 23                 \nTmax <- 28                \nWmax <- 12                 \n\n# Calculate wetness duration required at each temperature\nW_T <- sapply(T, wetness_duration, Wmin, Tmin, Topt, Tmax, Wmax)\n\ntemperature_data_soyrust <- data.frame(\n  Temperature = T,\n  Wetness_Duration = W_T)\n```\n:::\n\n\n\n\n\nWe can produce the plots for each pathogen.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\napplescab <- ggplot(temperature_data_applescab, aes(x = Temperature, y = Wetness_Duration)) +\n  geom_line(color = \"black\", linewidth = 1, linetype =1) +\n  theme_r4pde(font_size = 14)+\n  labs(x = \"Temperature (¬∞C)\", y = \"Wetness Duration (hours)\", \n       subtitle = \"Venturia inaequalis\")+\n  theme(plot.subtitle = element_text(face = \"italic\"))\n\nsoyrust <- ggplot(temperature_data_soyrust, aes(x = Temperature, y = Wetness_Duration)) +\n  geom_line(color = \"black\", linewidth = 1, linetype =1) +\n  theme_r4pde(font_size = 14)+\n  labs(x = \"Temperature (¬∞C)\", y = \"Wetness Duration (hours)\", \n       subtitle = \"Phakopsora pachyrizhi\")+ \n  theme(plot.subtitle = element_text(face = \"italic\"))\n\nlibrary(patchwork)\napplescab | soyrust\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Latency period models\n\nThe latent period can be defined as \"the length of time between the start of the infection process by a unit of inoculum and the start of production of infectious units\" [@madden2007]. The latent period, analogous to the reproductive maturity age of nonparasitic organisms, defines the generation time between infections and is a key factor in pathogen development and epidemic progress in plant disease epidemiology [@plantdi1963]. As a critical trait of aggressiveness, especially in polycyclic diseases, it largely determines the potential number of infection cycles within a season, impacting the overall epidemic intensity [@lannou2012].\n\n#### Parabolic function\n\nThe effects of temperature on the length of the incubation and latent periods of hawthorn powdery mildew, caused by *Podosphaera clandestina*, were studied by @xu2000. In that work, the authors inoculated the leaves and, each day after inoculation, the upper surface of each leaf was examined for mildew colonies and conidiophores using a pen-microscope (√ó50). Sporulation was recorded at the leaf level, noting the number of colonies and the first appearance dates of colonies and sporulation for each leaf.\n\nThe latent period (LP) was defined as the time from inoculation to the first day of observed sporulation on the leaf. Due to the skewed distribution of LP across temperatures and inoculations, medians were used to summarize LP rather than means [@xu2000].\n\nLet's look at two plots extracted from the paper. The first, on the left-hand side, is the original number of days of the latent period of each evaluated temperature (note: the solid symbol is for constant temperature while the open circle is for fluctuating temperature). On the right-hand side, the relationship between temperature and rates of development of powdery mildew under constant temperature during the latent periods; the solid line indicates the fitted model. The rate of fungal development was calculated as the reciprocal of the corresponding observed incubation (in hours) and latent periods.\n\n![Source: @xu2000](imgs/modeling-latent.png){#fig-latent fig-align=\"center\"}\n\nThe latent period data in days for the solid black circle (constant temperature) above was extracted using the {digitize} R package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlatent <- tibble::tribble(\n   ~T, ~days,\n  10L,   13L,\n  11L,   16L,\n  13L,    8L,\n  14L,    9L,\n  15L,    7L,\n  16L,    7L,\n  17L,    6L,\n  18L,    6L,\n  19L,    6L,\n  20L,    6L,\n  21L,    5L,\n  22L,    5L,\n  23L,    6L,\n  24L,    6L,\n  25L,    5L,\n  26L,    7L,\n  27L,    7L,\n  28L,   10L\n  )\n```\n:::\n\n\n\n\n\nLet's reproduce the two plots using the datapoints.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|fig-width: 10\n#|fig-height: 4\nlibrary(ggplot2)\nlibrary(r4pde)\n\np_latent <- latent |> \n  ggplot(aes(T, days))+\n  geom_point()+\n  theme_r4pde()\n\nlatent_rate <- data.frame(\n  T = latent$T,  # Scale temperature\n  R = 1/latent$days/24\n)\n\np_latent_rate <- latent_rate |> \n  ggplot(aes(T, R))+\n  geom_point()+\n  theme_r4pde()\n\nlibrary(patchwork)\np_latent | p_latent_rate\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n\n\nWe will fit the parabolic function proposed by @bernard2013 which predicts a thermal response curve (developmental rate, R), which is the relationship between the inverse of latent period and temperature. We need to enter the values for optimum temperature (where latent period is shortest) and the minimum latent period. The model is given by:\n\n$R(T) = \\frac{k}{\\text{LP}_{\\text{min}} + \\text{a} \\times (T - T_{\\text{opt}})^2}$\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary package\n#library(minpack.lm)\n\n# Define the model formula\n# model_formula <- R ~ (a + b * T)^(c * T)\nLPmin <- 5 # minimum latent period\nTopt <- 21 # Optimal temperature\nmodel_formula2 <- R ~ k / (LPmin + a * (T - Topt)^2)\n\n# Set initial parameter estimates\n#start_values <- list(a = 0.1, b = 0.01, c = 0.01)\nstart_values2 <- list(a = 0.1, k = 1)\n# Fit the model\n#fit_rate <- nlsLM(model_formula, data = latent_rate, start = start_values)\nfit_rate2 <- nls(model_formula2, data = latent_rate, start = start_values2)\n\n# View the summary of the fit\nsummary(fit_rate2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: R ~ k/(LPmin + a * (T - Topt)^2)\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \na 0.060274   0.010705    5.63 3.76e-05 ***\nk 0.039520   0.001464   26.99 9.05e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.0006936 on 16 degrees of freedom\n\nNumber of iterations to convergence: 6 \nAchieved convergence tolerance: 3.183e-06\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_rate2$m$getAllPars()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         a          k \n0.06027417 0.03952035 \n```\n\n\n:::\n\n```{.r .cell-code}\na <- fit_rate2$m$getAllPars()[1]\nk <- fit_rate2$m$getAllPars()[2]\n```\n:::\n\n\n\n\n\nNow we reproduce the plot with the fitted data. Note that the curve is not the same shown in the paper because we used a different equation.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nT <- seq(10, 29, 0.1)\n#R <- (a + b * T)^(c * T)\nR <- k / (LPmin + a * (T - Topt)^2)\ndat2 <- data.frame(T, R)\n\ndat2 |>\n  ggplot(aes(T, R)) +\n  geom_line() +\n  geom_point(data = latent_rate, aes(T, R)) +\n  theme_r4pde(font_size = 16) +\n  labs(x = \"Temperature\", y = \"Inverse of the latent period (hour -1)\", \n       title = \"\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Field data\n\nWhile pathogen inoculum, host resistance, and agronomic factors are sometimes included alongside weather in empirically derived models using field data [@shah2013; @cao2015; @mehra2017], only a few models explicitly incorporate non-weather factors [@mehra2016; @paul2004]. In most cases, these models primarily rely on weather variables as predictors [@gonz√°lez-dom√≠nguez2023]. This focus reflects the critical role of weather in driving key processes in the disease cycle, such as pathogen survival, dispersal, host infection, and reproduction [@dewolf2007]. Consequently, a primary objective for plant epidemiologists is to identify and quantify the relationships between weather conditions and measures of disease intensity [@shah2019; @eljarroudi2017; @pietravalle2003; @coakley1988; @delponte2006; @shah2013; @coakley1988a].\n\nIn modeling efforts, the disease variable can be represented either as a continuous measure (e.g., incidence or severity) or as categorical data, which may be binary (e.g., non-epidemic vs. epidemic) or multinomial (e.g., low, moderate, and high severity). This variability in response types informs the selection of suitable modeling techniques, ensuring that the model accurately captures the nature of the data and the relationships between weather variables and disease outcomes.\n\nIn this section, I will demonstrate several modeling approaches that can be applied when field data is available. These examples will cover a range of techniques, starting with variable construction, which involves transforming raw weather data into summary measures that can effectively represent conditions relevant to disease outcomes. Next, variable selection methods will be explored to identify the most influential predictors, ensuring that models are both accurate and interpretable. The focus will then shift to model fitting, showing how different models, such as linear and logistic regression, can be used to capture relationships between weather variables and disease endpoints. Finally, model evaluation will be addressed, emphasizing metrics like accuracy, sensitivity, and area under the curve (AUC), which are crucial for assessing the predictive performance and reliability of the models developed.\n\nFollows a typical workflow for developing a disease prediction model, starting with disease data collection and weather data retrieval. The process includes data pre-processing, feature engineering, variable selection, model fitting, cross-validation, model tuning, and evaluation, followed by interpretation. Iterative feedback between model evaluation and variable selection aims to optimize model performance.\n\n![Key steps for developing a plant disease prediction model](imgs/modeling-workflow.png){#fig-workflow fig-align=\"center\"}\n\n### Variable creation and selection\n\nVariable construction, particularly for weather-related variables, involves not only data transformation methods but also requires an understanding of how diseases respond to specific weather conditions at particular growth stages [@dec√≥l2024; @dewolf2003]. This approach ensures that the variables derived accurately capture biologically relevant processes, improving the realism and relevance of the model inputs.\n\nIn addition, data mining techniques are employed to systematically explore time-series data and identify potential weather-disease relationships [@shah2019; @pietravalle2003; @coakley1988]. These techniques involve creating lagged variables, moving averages, or window-based summaries that capture delayed or cumulative effects of weather on disease outcomes. By integrating system knowledge with data mining, researchers aim to construct variables that are both biologically meaningful and statistically robust, improving the chances of identifying predictors that enhance model accuracy and interpretability.\n\n#### Window-pane\n\n##### Variable construction\n\nWith regards to weather variable creation and selection for data-mining purposes, window-pane analysis, first introduced in the mid-1980s [@coakley1985], has been widely used in modeling studies in plant pathology [@pietravalle2003; @calverojr1996; @tebeest2008a; @gouache2015a; @coakley1988; @kriss2010; @dallalana2021; @coakley1988a]. This method aids in identifying weather conditions that are most strongly associated with disease outcomes by segmenting a continuous time series (e.g. daily temperature, relative humidity, and rainfall), into discrete, fixed-length windows.\n\nThe analysis involves summarizing conditions within each window (e.g., mean, sum, count) and correlating these summaries with disease outcomes, which may be expressed as continuous measures (e.g., severity) or as categorical variables (e.g., low vs. high levels). This approach allows users to set specific start and end times, as well as window lengths, enabling the exploration of different temporal relationships between weather and disease. By sliding the start and end points along the series, multiple overlapping windows are generated, making it possible to identify the most informative variables for modeling. The selected optimal fixed-time and fixed-window-length variables derived from this analysis serve as predictors in model development, helping to improve the accuracy and relevance of disease forecasting models.\n\nHere's an R code that demonstrates how the windows are defined over a 28-day period using four fixed window lengths (7, 14, 21, and 28 days), generating a total of 46 variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Define total days and window lengths\nmax_days <- 28\nwindow_lengths <- c(7, 14, 21, 28)\n\n# Create an empty data frame for all sliding windows\nwindow_data <- data.frame()\n\n# Populate the data frame with start and end points for each window\nvar_id <- 1  # Variable ID for each window\n\nfor (length in sort(window_lengths)) {  # Sort window lengths from shortest to longest\n  for (start_day in 0:(max_days - length)) {\n    end_day <- start_day + length\n    window_data <- rbind(\n      window_data,\n      data.frame(\n        start = start_day,\n        end = end_day,\n        var_id = var_id,\n        window_length = length\n      )\n    )\n    var_id <- var_id + 1  # Increment variable ID\n  }\n}\n\n# Convert window_length to a factor for correct ordering in the legend\nwindow_data$window_length <- factor(window_data$window_length, levels = sort(unique(window_data$window_length)))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwindow_data |> \n  ggplot(aes(x = start, xend = end, y = var_id, yend = var_id)) +\n  geom_segment(linewidth = 2) +  # Line segments for each window\n  scale_x_continuous(breaks = 0:max_days, limits = c(0, max_days)) +\n  scale_y_continuous(breaks = 1:var_id) +\n  labs(title = \"Window-pane\",\n    subtitle = \"Each variable of 7, 14, 21 and 28 days length over 28 days\",\n    x = \"Days\", y = \"Variable ID\", color = \"Window Length (days)\") +\n  r4pde::theme_r4pde(font_size = 14) +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-33-1.png){width=768}\n:::\n:::\n\n\n\n\n\nThe window pane analysis requires a spreadsheet program [@kriss2010] or a specific algorithm that automates the creation of sliding windows at defined starting and ending times relative to a reference date. In the seminal work, software was programmed in the FORTRAN language and named WINDOW [@coakley1985]. It enabled the creation of windows and the calculation of summary statistics, including correlation with disease severity. Building on the original idea, a Genstat 6.1 algorithm was developed in the early 2000s, incorporating further adjustments such as the implementation of bootstrapping analysis to validate correlations and misclassifications identified by window pane [@pietravalle2003; @tebeest2008a]. More recently, window pane analysis including variable creation and analysis has been conducted in R using custom-made scripts [@gouache2015a; @dallalana2021].\n\nI will demonstrate the `windowpane()` function of the {r4pde} package developed to facilitate the creation of variables using the window pane approach. First, let's load a dataset that contains information on the disease, as well as metadata, including a key date that will be used as the starting point for window creation. The BlastWheat dataset, which is included in the {r4pde} package, was provided by @dec√≥l2024.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(r4pde)\nlibrary(dplyr)\ntrials <- BlastWheat\nglimpse(trials)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 143\nColumns: 10\n$ study      <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, ‚Ä¶\n$ year       <dbl> 2012, 2012, 2012, 2012, 2012, 2013, 2013, 2013, 2013, 2014,‚Ä¶\n$ location   <chr> \"Dourados\", \"Palotina\", \"Londrina\", \"Planaltina\", \"Itaber√°\"‚Ä¶\n$ state      <chr> \"MS\", \"PR\", \"PR\", \"DF\", \"SP\", \"MS\", \"MG\", \"DF\", \"SP\", \"MG\",‚Ä¶\n$ latitude   <dbl> -22.27516, -24.35483, -23.35916, -15.60387, -24.06832, -22.‚Ä¶\n$ longitude  <dbl> -54.81640, -53.75794, -51.16476, -47.71381, -49.15575, -54.‚Ä¶\n$ heading    <chr> \"10-05-2012\", \"09-06-2012\", \"01-06-2012\", \"03-05-2012\", \"15‚Ä¶\n$ inc_mean   <dbl> 93.30, 40.50, 100.00, 35.50, 7.71, 48.70, 22.00, 46.50, 68.‚Ä¶\n$ index_mean <dbl> 68.65, 11.73, 92.86, 6.36, 0.35, 9.17, 2.91, 10.41, 41.86, ‚Ä¶\n$ yld_mean   <dbl> 1097.00, 1219.38, 495.12, 1747.44, 2148.31, 506.00, 1562.75‚Ä¶\n```\n\n\n:::\n:::\n\n\n\n\n\nWe can note that the heading date, which will be used as reference date in our analysis, is not defined as date object, which needs correction.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrials$heading = as.Date(trials$heading, format = \"%d-%m-%Y\")\nglimpse(trials$heading)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Date[1:143], format: \"2012-05-10\" \"2012-06-09\" \"2012-06-01\" \"2012-05-03\" \"2012-04-15\" ...\n```\n\n\n:::\n:::\n\n\n\n\n\nThe weather data for our analysis will be downloaded from NASA POWER. Since we have multiple trials with different heading dates, a wrapper function for the `get_power()` function from the {nasapower} package was created, included in {r4pde}, and named `get_nasapower()`. This function enables the download of data for a period \"around\" the key date, which can be defined by the user. In our case, we will download data from 28 days before and 28 days after the heading date.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_data <- get_nasapower(\n  data = trials,\n  days_around = 28,\n  date_col = \"heading\"\n)\n\n# save the data for faster rendering\nwrite_csv(weather_data, \"data/weather_windowpane.csv\")\n```\n:::\n\n\n\n\n\nNow we can see the weather data and join the two dataframes.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read the data\nweather_data <- readr::read_csv(\"data/weather_windowpane.csv\")\n\nglimpse(weather_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 8,151\nColumns: 14\n$ LON         <dbl> -54.8164, -54.8164, -54.8164, -54.8164, -54.8164, -54.8164‚Ä¶\n$ LAT         <dbl> -22.27516, -22.27516, -22.27516, -22.27516, -22.27516, -22‚Ä¶\n$ YEAR        <dbl> 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012, 2012‚Ä¶\n$ MM          <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5‚Ä¶\n$ DD          <dbl> 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26‚Ä¶\n$ DOY         <dbl> 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114‚Ä¶\n$ YYYYMMDD    <date> 2012-04-12, 2012-04-13, 2012-04-14, 2012-04-15, 2012-04-1‚Ä¶\n$ T2M         <dbl> 24.31, 25.83, 24.99, 24.15, 22.72, 23.33, 23.76, 24.83, 24‚Ä¶\n$ RH2M        <dbl> 83.69, 77.62, 81.69, 82.69, 74.62, 74.44, 70.19, 67.75, 77‚Ä¶\n$ PRECTOTCORR <dbl> 0.02, 1.13, 11.00, 0.06, 0.00, 0.04, 0.00, 0.03, 24.08, 20‚Ä¶\n$ T2M_MAX     <dbl> 28.61, 31.01, 30.01, 29.43, 30.33, 30.69, 31.51, 32.49, 30‚Ä¶\n$ T2M_MIN     <dbl> 20.82, 20.43, 21.11, 19.04, 16.31, 17.37, 17.15, 17.69, 20‚Ä¶\n$ T2MDEW      <dbl> 21.19, 21.23, 21.38, 20.75, 17.47, 18.01, 17.29, 17.85, 20‚Ä¶\n$ study       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1‚Ä¶\n```\n\n\n:::\n\n```{.r .cell-code}\n# apply a full join\ntrials_weather <- full_join(trials, weather_data) \n```\n:::\n\n\n\n\n\nWe are now ready to use the windowpane function to create new variables. The function has several arguments. Note the two date variables: `end_date`, which serves as the reference for sliding the windows, and `date_col`, which represents the date for each day in the time series. The `summary_type` specifies the statistic to be calculated, while the `direction` determines whether the sliding windows will move backward, forward, or in both directions relative to the end date. Lastly, the `group_by` argument specifies the index variable for the epidemic or study.\n\nWe will create new variables based on the mean daily temperature (T2M), with each variable representing the mean value over one of the four window lengths (7, 14, 21, and 28 days) defined in the `window_length` argument. We will only generate variables that cover periods before the heading date, using \"backward\" in the `direction` argument.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create window variables separated for each weather variable\n\nwp_T2M <- windowpane(\n  data = trials_weather,\n  end_date_col = heading,\n  date_col = YYYYMMDD,\n  variable = T2M,  \n  summary_type = \"mean\",\n  threshold = NULL,\n  window_lengths = c(7, 14, 21, 28),\n  direction = \"backward\",\n  group_by_cols = \"study\", \n)\n\nwpT2M_MIN_15 <- windowpane(\n    data = trials_weather,\n    end_date_col = heading,\n    date_col = YYYYMMDD,\n    variable = T2M_MIN,   \n    summary_type = \"below_threshold\",\n    threshold = 15,\n    window_lengths = c(7, 14, 21, 28),\n    direction = \"backward\",\n    group_by_cols = \"study\", \n  )\n\nwpT2M_MIN <- windowpane(\n    data = trials_weather,\n    end_date_col = heading,\n    date_col = YYYYMMDD,\n    variable = T2M_MIN,   \n    summary_type = \"mean\",\n    threshold = NULL,\n    window_lengths = c(7, 14, 21, 28),\n    direction = \"backward\",\n    group_by_cols = \"study\", \n  )\n\nwpT2M_MAX <- windowpane(\n    data = trials_weather,\n    end_date_col = heading,\n    date_col = YYYYMMDD,\n    variable = T2M_MAX,   \n    summary_type = \"mean\",\n    threshold = NULL,\n    window_lengths = c(7, 14, 21, 28),\n    direction = \"backward\",\n    group_by_cols = \"study\", \n  )\n\nwpPREC <- windowpane(\n    data = trials_weather,\n    end_date_col = heading,\n    date_col = YYYYMMDD,\n    variable = PRECTOTCORR,   \n    summary_type = \"sum\",\n    threshold = NULL,\n    window_lengths = c(7, 14, 21, 28),\n    direction = \"backward\",\n    group_by_cols = \"study\", \n  )\n\nwpRH2M <- windowpane(\n    data = trials_weather,\n    end_date_col = heading,\n    date_col = YYYYMMDD,\n    variable = RH2M,   \n    summary_type = \"mean\",\n    threshold = NULL,\n    window_lengths = c(7, 14, 21, 28),\n    direction = \"backward\",\n    group_by_cols = \"study\", \n  )\n\n# combine all datasets\nwp_all <- cbind(wp_T2M, wpT2M_MIN_15, wpT2M_MIN, wpT2M_MAX, wpPREC, wpRH2M)\n```\n:::\n\n\n\n\n\n##### Correlations and multiple hypothesis test\n\nThe window pane analysis begins by quantifying the associations between each summary weather variable and disease response using a specific correlation coefficient (Pearson or Spearman). Usually, Spearman's rank correlation can be preferred due to its ability to measure monotonic relationships and its robustness to outliers. In other cases, Spearman was used because the disease data was ordinal [@kriss2010].\n\nIn a recent study, @dallalana2021, differing from @kriss2010, proposed the estimation of the precision of these correlations via bootstrapping, where a high number of samples (e.g. 1000) are randomly drawn (with replacement) from the original dataset. For each bootstrap sample, correlations between weather variables and disease outcomes are calculated, and the average across samples is used as the final measure of association. This approach ensures a more reliable estimation of the correlations by capturing variability and improving statistical robustness.\n\nThe window-pane analysis involves numerous tests, as each time window generates a separate test statistic. Because many tests are conducted, the global significance level becomes higher than the critical significance level set for individual tests, increasing the risk of false positives [@kriss2010]. Additionally, the correlations among test statistics are influenced by overlapping time windows, shared data, and large-scale climatic patterns. To address this issue, @kriss2010 proposed the use of the Simes' method, which tests the global null hypothesis that none of the individual correlations are significant. Simes' method orders p-values and rejects the global null hypothesis if any adjusted p-value meets a specific threshold.\n\nWhile this method indicates whether at least one correlation is significant, it does not provide significance for individual correlations. Therefore, the authors proposed that the individual correlation coefficients should be compared against a more stringent significance level (Œ± = 0.005 instead of 0.05), reducing the likelihood of false positives but increasing false negatives. Although this adjustment is independent of the Simes' method, there was a general alignment: significant global results often corresponded to significant individual correlations, and non-significant global results typically lacked significant individual correlations [@kriss2010].\n\nLet's calculate the bootstrapped correlation coefficients combined with the Sime's method. First, we need to subset our variables to the specific combination of weather and window.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  T2M_MIN_7 = wp_all |> dplyr::select(starts_with(\"length7_T2M_MIN_mean\"))\n  T2M_MIN_14 = wp_all |> dplyr::select(starts_with(\"length14_T2M_MIN_mean\"))\n  T2M_MIN_21 = wp_all |> dplyr::select(starts_with(\"length21_T2M_MIN_mean\"))\n  T2M_MIN_28 = wp_all |> dplyr::select(starts_with(\"length28_T2M_MIN_mean\"))\n \n  T2M_MAX_7 = wp_all |> dplyr::select(starts_with(\"length7_T2M_MAX_mean\"))\n  T2M_MAX_14 = wp_all |> dplyr::select(starts_with(\"length14_T2M_MAX_mean\"))\n  T2M_MAX_21 = wp_all |> dplyr::select(starts_with(\"length21_T2M_MAX_mean\"))\n  T2M_MAX_28 = wp_all |> dplyr::select(starts_with(\"length28_T2M_MAX_mean\"))\n  \n  T2M_7 = wp_all |> select(starts_with(\"length7_T2M_mean\"))\n  T2M_14 = wp_all |> select(starts_with(\"length14_T2M_mean\"))\n  T2M_21 = wp_all |> select(starts_with(\"length21_T2M_mean\"))\n  T2M_28 = wp_all |> select(starts_with(\"length28_T2M_mean\"))\n  \n  RH2M_7 = wp_all |> select(starts_with(\"length7_RH2M_mean\"))\n  RH2M_14 = wp_all |> select(starts_with(\"length14_RH2M_mean\"))\n  RH2_21 = wp_all |> select(starts_with(\"length21_RH2M_mean\"))\n  RH2_28 = wp_all |> select(starts_with(\"length28_RH2M_mean\"))\n  \n  PRECTOTCORR_7 = wp_all |> select(starts_with(\"length7_PRECTOTCORR\"))\n  PRECTOTCORR_14 = wp_all |> select(starts_with(\"length14_PRECTOTCORR\"))\n  PRECTOTCORR_21 = wp_all |> select(starts_with(\"length21_PRECTOTCORR\"))\n  PRECTOTCORR_28 = wp_all |> select(starts_with(\"length28_PRECTOTCORR\"))\n  \n  T2M_MINb_7 = wp_all |> select(starts_with(\"length7_T2M_MIN_below\"))\n  T2M_MINb_14 = wp_all |> select(starts_with(\"length14_T2M_MIN_below\"))\n  T2M_MINb_21 = wp_all |> select(starts_with(\"length21_T2M_MIN_below\"))\n  T2M_MINb_28 = wp_all |> select(starts_with(\"length28_T2M_MIN_below\"))\n```\n:::\n\n\n\n\n\nNow, we can use the `windowpane_tests()` function from the {r4pde} package to analyze each of the datasets created above. This function will compute the bootstrapped correlation coefficients for the variables of interest and apply the Simes' procedure to account for multiple testing, providing adjusted P-values for more robust statistical inference.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(boot)\ndata <- T2M_MINb_7 \ndata$inc <- trials$inc_mean \nresponse_var <- 'inc'  \nresults <- windowpane_tests(data, response_var, corr_type = \"spearman\", R = 1000)\nresults_TMINb <- results$results\n\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$results\n                                  variable correlation      p_value  mean_corr\n1  length7_T2M_MIN_below_threshold_-18_-24  -0.5295915 1.040432e-11 -0.5249507\n2  length7_T2M_MIN_below_threshold_-17_-23  -0.5136581 5.359609e-11 -0.5130773\n3  length7_T2M_MIN_below_threshold_-15_-21  -0.5116609 6.543248e-11 -0.5063511\n4  length7_T2M_MIN_below_threshold_-10_-16  -0.5063934 1.100732e-10 -0.5008654\n5  length7_T2M_MIN_below_threshold_-11_-17  -0.5054218 1.210402e-10 -0.5013972\n6  length7_T2M_MIN_below_threshold_-16_-22  -0.5038720 1.407514e-10 -0.4988078\n7  length7_T2M_MIN_below_threshold_-12_-18  -0.4972482 2.659657e-10 -0.4921962\n8  length7_T2M_MIN_below_threshold_-19_-25  -0.4951918 3.231718e-10 -0.4943599\n9   length7_T2M_MIN_below_threshold_-9_-15  -0.4913413 4.638201e-10 -0.4853357\n10  length7_T2M_MIN_below_threshold_-7_-13  -0.4882483 6.180090e-10 -0.4853013\n11   length7_T2M_MIN_below_threshold_-3_-9  -0.4793727 1.386299e-09 -0.4775091\n12    length7_T2M_MIN_below_threshold_0_-6  -0.4757057 1.922737e-09 -0.4737155\n13  length7_T2M_MIN_below_threshold_-8_-14  -0.4743890 2.160334e-09 -0.4731947\n14 length7_T2M_MIN_below_threshold_-14_-20  -0.4742346 2.189972e-09 -0.4734724\n15  length7_T2M_MIN_below_threshold_-4_-10  -0.4735015 2.336183e-09 -0.4693049\n16   length7_T2M_MIN_below_threshold_-2_-8  -0.4730773 2.425031e-09 -0.4741065\n17   length7_T2M_MIN_below_threshold_-1_-7  -0.4698400 3.218863e-09 -0.4678987\n18  length7_T2M_MIN_below_threshold_-6_-12  -0.4663226 4.364062e-09 -0.4625572\n19 length7_T2M_MIN_below_threshold_-13_-19  -0.4630281 5.785628e-09 -0.4610996\n20  length7_T2M_MIN_below_threshold_-5_-11  -0.4594875 7.807700e-09 -0.4582524\n21 length7_T2M_MIN_below_threshold_-20_-26  -0.4334293 6.401965e-08 -0.4305574\n22 length7_T2M_MIN_below_threshold_-21_-27  -0.4291061 8.925631e-08 -0.4271509\n      sd_corr median_corr rank  m simes_threshold significant_simes\n1  0.05792860  -0.5281375    1 22     0.002272727              TRUE\n2  0.06219467  -0.5156222    2 22     0.004545455              TRUE\n3  0.06085362  -0.5081182    3 22     0.006818182              TRUE\n4  0.06439511  -0.5032007    4 22     0.009090909              TRUE\n5  0.06317908  -0.5034083    5 22     0.011363636              TRUE\n6  0.06375940  -0.4989540    6 22     0.013636364              TRUE\n7  0.06625604  -0.4921979    7 22     0.015909091              TRUE\n8  0.06260022  -0.4976638    8 22     0.018181818              TRUE\n9  0.06759529  -0.4847309    9 22     0.020454545              TRUE\n10 0.06787472  -0.4880106   10 22     0.022727273              TRUE\n11 0.06497033  -0.4802147   11 22     0.025000000              TRUE\n12 0.06536201  -0.4736488   12 22     0.027272727              TRUE\n13 0.06529500  -0.4757740   13 22     0.029545455              TRUE\n14 0.06578540  -0.4759618   14 22     0.031818182              TRUE\n15 0.06580619  -0.4740651   15 22     0.034090909              TRUE\n16 0.06212626  -0.4755563   16 22     0.036363636              TRUE\n17 0.06178866  -0.4722236   17 22     0.038636364              TRUE\n18 0.06805414  -0.4621550   18 22     0.040909091              TRUE\n19 0.06631706  -0.4606907   19 22     0.043181818              TRUE\n20 0.06542673  -0.4562920   20 22     0.045454545              TRUE\n21 0.06440558  -0.4348640   21 22     0.047727273              TRUE\n22 0.06557457  -0.4305249   22 22     0.050000000              TRUE\n   individual_significant\n1                    TRUE\n2                    TRUE\n3                    TRUE\n4                    TRUE\n5                    TRUE\n6                    TRUE\n7                    TRUE\n8                    TRUE\n9                    TRUE\n10                   TRUE\n11                   TRUE\n12                   TRUE\n13                   TRUE\n14                   TRUE\n15                   TRUE\n16                   TRUE\n17                   TRUE\n18                   TRUE\n19                   TRUE\n20                   TRUE\n21                   TRUE\n22                   TRUE\n\n$summary_table\n               Metric         Value\n1 Global P-value (Pg)  2.288950e-10\n2     Max Correlation -4.271509e-01\n\n$global_significant\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\nThe window pane tests results indicate strong, statistically significant negative correlations between the response variable, the number of days when the TMIN was lower than 15 ^o^C, and the selected predictors over a 7-day period. The correlations range from approximately -0.56 to -0.50, with all P-values below the global significance threshold after Simes' correction, suggesting that these predictors are robustly associated with the response.\n\nThe global P-value, which accounts for multiple testing, is exceptionally low, confirming a significant overall relationship, while the highest observed correlation is -0.50. These findings highlight that low-temperature conditions over 7 days are consistently linked with the response variable, emphasizing the importance of temperature variability in this context.\n\nLet's apply the test function to 7-day long windows for three other variables: relative humidity, precipitation and maximum temperature.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(r4pde)\ndata1 <- RH2M_7 \ndata1$inc <- trials$inc_mean \nresponse_var <- 'inc'  \nresults1 <- windowpane_tests(data1, response_var, corr_type = \"spearman\", R = 1000)\nresults_RH <- results1$results\n\n\ndata2 <- PRECTOTCORR_7 \ndata2$inc <- trials$inc_mean \nresponse_var <- 'inc'  \nresults2 <- windowpane_tests(data2, response_var, corr_type = \"spearman\", R = 1000)\nresults_PREC <- results2$results\n\n\ndata3 <- T2M_MAX_7 # enter the dataset\ndata3$inc <- trials$inc_mean \nresponse_var <- 'inc'  \nresults3 <- windowpane_tests(data3, response_var, corr_type = \"spearman\", R = 1000)\nresults_TMAX <- results3$results\n```\n:::\n\n\n\n\n\nThe first variable in the results dataframe contains the name of the variable. We can extract the starting and ending day from each window using the `extract` function, which allows for regex-based extraction into new columns. In this case, two new columns will be created representing the extreme days of the window.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use strcapture to extract components into new columns\ndf_TMINb7 <- results_TMINb |>\n  extract(variable, into = c(\"variable_prefix\", \"low\", \"high\"), \n          regex = \"^(.*)_(-?\\\\d+)_(-?\\\\d+)$\", convert = TRUE)\n\n\ndf_RH7 <- results_RH |>\n  extract(variable, into = c(\"variable_prefix\", \"low\", \"high\"), \n          regex = \"^(.*)_(-?\\\\d+)_(-?\\\\d+)$\", convert = TRUE)\n\n\ndf_PREC7 <- results_PREC |>\n  extract(variable, into = c(\"variable_prefix\", \"low\", \"high\"), \n          regex = \"^(.*)_(-?\\\\d+)_(-?\\\\d+)$\", convert = TRUE)\n\ndf_TMAX7 <- results_TMAX |>\n  extract(variable, into = c(\"variable_prefix\", \"low\", \"high\"), \n          regex = \"^(.*)_(-?\\\\d+)_(-?\\\\d+)$\", convert = TRUE)\n```\n:::\n\n\n\n\n\nNow we can plot the mean correlation for the start day of each window.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_TMIN <- df_TMINb7 |> \n  ggplot(aes(low, mean_corr, fill = p_value))+\n  ylim(-1, 1)+\n  geom_col()+\n  theme_r4pde(font_size = 12)+\n  labs(title = \"N. days TMIN < 15C\",\n       subtitle = \"7-day window\",\n       y = \"Spearman's correlation\",\n       x = \"Day relative to heading date \")\n\np_RH <- df_RH7 |> \n  ggplot(aes(low, mean_corr, fill = p_value))+\n  ylim(-1, 1)+\n  geom_col()+\n  theme_r4pde(font_size = 12)+\n  labs(title = \"Relative humidity\", \n       subtitle = \"7-day window\",\n       y = \"Spearman's correlation\",\n       x = \"Day relative to heading date \")\n\np_TMAX <- df_TMAX7 |> \nggplot(aes(low, mean_corr, fill = p_value))+\n  ylim(-1, 1)+\n  geom_col()+\n  theme_r4pde(font_size = 12)+\n  labs(title = \"Max. temperature\", \n       subtitle = \"7-day window\",\n       y = \"Spearman's correlation\",\n       x = \"Day relative to heading date \")\n\n\np_PREC <- df_PREC7 |> \n  ggplot(aes(low, mean_corr, fill = p_value))+\n  ylim(-1, 1)+\n  geom_col()+\n  theme_r4pde(font_size = 12)+\n  labs(title = \"Cumulative rainfall\", \n       subtitle = \"7-day window\",\n       y = \"Spearman's correlation\",\n       x = \"Day relative to heading date \")\n    \nscale_common <- scale_fill_viridis_c(limits = c(0, 1), \n                                     na.value = \"grey90\")\n\np_TMIN <- p_TMIN + scale_common\np_TMAX <- p_TMAX + scale_common\np_RH <- p_RH + scale_common\np_PREC <- p_PREC + scale_common\n\n# Combine plots using patchwork and collect guides\n(p_TMIN | p_TMAX) / (p_RH | p_PREC) + \n  plot_layout(guides = \"collect\")\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\n\n\n**Interpretation**. All 7-day-length variables but maximum temperature were strongly associated with the incidence of wheat blast. These three variables can be used as candidates for developing predictions models.\n\n#### Functional data analysis\n\nFunctional Data Analysis (FDA) is a statistical approach used to analyze and model data that varies continuously over time or space. It represents entire data sequences (e.g., time series) as smooth functions, allowing for the exploration of trends, patterns, and relationships in complex, continuous processes rather than relying on discrete, segmented data points [@ramsay2005functional; @Gertheiss2024].\n\nIn the FDA framework, scalar-on-function and function-on-scalar models are two types of FDA models, designed to examine relationships between functional predictors and outcomes. Function-on-scalar models use single values (e.g., mean daily relative humidity) as predictors to explain the shape of an entire outcome curve (e.g. disease). Meanwhile, in scalar-on-function models, time series data (e.g., daily temperatures) are used as predictors to identify which parts of the series are linked to a single outcome. Together, these FDA models offer complementary insights, allowing either for predicting a scalar outcome from curves or understanding how scalar predictors influence entire functions [@ramsay2005functional].\n\nInitially applied in plant pathology to study the relationship between Fusarium head blight outbreaks and weather variables over time (using the function-on-scalar model) [@shah2019a], FDA has since been adopted in other plant pathology studies with similar objectives [@shah2019; @hjelkrem2021a; @alves2022a].\n\nIn particular, @shah2019 used FDA as a basis to develop logistic regression models for large-scale deployment by utilizing FDA through a scalar-on-function approach to predict plant diseases - in this approach, the model identifies which parts of the time series (e.g., certain weeks or days) are most associated with the disease outcome, helping to predict whether an epidemic is likely to occur based on patterns in the weather series. Moreover, FDA was employed to identify the most relevant temporal regions of weather series associated with disease outbreaks, improving prediction by summarizing key windows across critical growth stages. The authors discussed that , unlike traditional window-pane analysis, FDA reduces statistical testing issues and offers a more refined method for incorporating novel predictors into simple, effective models [@shah2019].\n\nWith the objective of identifying temporal regions of the weather series, Alves et al. (unpublished) proposed the use of a function-on-scalar model to gain insights about the time series related to a binary disease outcome by identifying significant regions in the weather series where the curves diverge. The function-on-scalar approach here compares the average functional trajectories of two groups: epidemic vs. non-epidemic. It identifies time regions where the mean weather curves for the two groups differ significantly. While the model doesn't directly predict a binary response, it aids in diagnosing critical time points in the series that differentiate the two disease outcomes, supporting model development and refinement for binary classification.\n\nFor that purpose, the authors used the `ITP2bspline()` function of the R package {fdatest} that implements the Interval Testing Procedure (ITP) to compare two functional populations (epidemic vs. non-epidemic) evaluated on a uniform grid. It represents data using B-spline basis functions and assesses the significance of each basis coefficient with interval-wise control of the Family Wise Error Rate (FWER) [@pini2016].\n\nIn this section, I will first demonstrate how to fit the function-on-scalar regression with the objective of visualizing two curves, the difference coefficient function and the overall mean coefficient curve. The former shows how the effect of a weather-related variable on the response variable changes over the days relative to a reference date (e.g. planting date, flowering). It helps to identify critical windows when the weather variations have the most substantial impact. The latter represents the cumulative or overall effect of weather over the time period. It helps assess whether the influence of weather variable accumulates or stabilizes over time.\n\nThen, I will demonstrate the Interval Testing Procedure (ITP) to compare two functional populations (epidemic vs. non-epidemic) and identify exactly the days in the series that the two populations are significantly different. We will keep analyzing the data on wheat blast epidemics in Brazil.\n\n##### Function-on-scalar regression\n\nThe following analysis uses function-on-scalar regression to explore the relationship between relative humidity at 2 meters (RH2M) and the occurrence of wheat blast epidemics. Let's first load the necessary libraries.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(r4pde)\nlibrary(refund)\nlibrary(ggplot2)\n```\n:::\n\n\n\n\n\nThe first step involves reading and merging two datasets:\n\n\\- `trials`: Contains disease data with heading dates.\n\n\\- `weather_data`: Contains weather data for specific time windows. It was created in the previous section on window pane and can be downloaded [here](https://raw.githubusercontent.com/emdelponte/epidemiology-R/refs/heads/main/data/weather_windowpane.csv).\n\nThe datasets are merged into `trials_weather`, and the resulting data is transformed into a wide format where each column represents time points (days), and rows correspond to individual studies. The binary epidemic status is created, where:\n\n-   1 indicates an epidemic (if `inc_mean > 20`).\n-   0 indicates no epidemic (if `inc_mean <= 20`).\n\nThe weather variable (`RH2M`) is used as the predictor, and time points (days) are calculated relative to the heading date.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load the disease datase\ntrials <- r4pde::BlastWheat\ntrials$heading = as.Date(trials$heading, format = \"%d-%m-%Y\")\n\n# load the weather data constructed in previous section\nweather_data <- readr::read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/refs/heads/main/data/weather_windowpane.csv\")\ntrials_weather <- full_join(trials, weather_data)\n\n# create epidemic variable and number of days relative to heading\ndat_wide_RH <- trials_weather |>\n    mutate(epidemic = if_else(inc_mean > 20, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) |>\n    dplyr::select(study, epidemic, days, RH2M) |>\n    pivot_wider(id_cols = c(study, epidemic), \n                names_from = days, values_from = RH2M)\n```\n:::\n\n\n\n\n\nThe response vector is the epidemic status (0 or 1), while the predictor matrix contains the values of the specified weather variable across time. The model fits smooth functions to represent the effects of time and the epidemic status on the weather variable using penalized splines. The function-on-scalar regression model is given by:\n\n$y_{ij} = \\beta_0(t_j) + \\beta_1(t_j) x_i + \\epsilon_{ij}$\n\nwhere: $y_{ij}$ is the value of the weather variable for study $i$ at time $j$; $\\beta_0(t_j)$ is the smooth function for the overall mean effect over time; $\\beta_1(t_j)$ is the smooth function representing the effect of epidemic status over time; $x_i$ is the binary epidemic status (0 or 1); and $\\epsilon{ij}$ is the error term.\n\nWe can now fit the model using the `pffr()` function of the {refund} package.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- dat_wide_RH$epidemic  # Response vector\ny <- dat_wide_RH |> \n  select(-study, -epidemic) |> \n  as.matrix()  # Matrix of predictors\n\nyind <- as.numeric(colnames(y))\n\nFOSR_RH <- pffr(y ~ x, \n             yind = yind,\n             bs.yindex = list(bs = \"ps\", k = 30, m = c(2, 1)), \n             bs.int = list(bs = \"ps\", k = 30, m = c(2, 1)),\n                algorithm = \"gam\")\n```\n:::\n\n\n\n\n\nLet's extract the coefficients of the model fit object and prepare the data and plot using gpplot.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  coef_list <- coef(FOSR_RH)$smterms\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nusing seWithMean for  s(yind.vec) .\n```\n\n\n:::\n\n```{.r .cell-code}\n  mean_df <- data.frame(\n    time = coef_list[[1]]$coef[, \"yind.vec\"],\n    value = coef_list[[1]]$coef[, \"value\"],\n    lower = coef_list[[1]]$coef[, \"value\"] - 1.96 * coef_list[[1]]$coef[, \"se\"],\n    upper = coef_list[[1]]$coef[, \"value\"] + 1.96 * coef_list[[1]]$coef[, \"se\"],\n    term = \"Overall Mean\"\n  )\n  \n  x_df <- data.frame(\n    time = coef_list[[2]]$coef[, \"yind.vec\"],\n    value = coef_list[[2]]$coef[, \"value\"],\n    lower = coef_list[[2]]$coef[, \"value\"] - 1.96 * coef_list[[2]]$coef[, \"se\"],\n    upper = coef_list[[2]]$coef[, \"value\"] + 1.96 * coef_list[[2]]$coef[, \"se\"],\n    term = \"Difference\"\n  )\n  \n  plot_df <- bind_rows(mean_df, x_df)\n  \n\n  ggplot(plot_df, aes(x = time, y = value)) +\n    geom_ribbon(aes(ymin = lower, ymax = upper), \n                alpha = 0.2) +\n    geom_line(linewidth = 1.2) +\n    facet_grid(rows = vars(term), \n               scales = \"free_y\") +\n    theme_r4pde(font_size = 12) +\n    geom_hline(aes(yintercept = 0), \n               color = \"grey\", \n               linetype = \"dashed\") +\n    geom_vline(aes(xintercept = 0), \n               color = \"grey\", \n               linetype = \"dashed\") +\n    labs(x = \"Day relative to wheat heading\", y = \"Coefficient Function\",\n         title = \"RH2M\") +\n    theme(strip.text = element_text(face = \"bold\", size = rel(1.0)),\n          axis.title = element_text(face = \"bold\", size = 12))\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n\n\n\n\nBecause we have several weather variables, we can facilitate the process by creating a function named `fosr()` that can be applied for the other variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the function for function-on-scalar regression\nfosr <- function(data, weather_var) {\n  \n  # Step 1: Prepare the dataset and transform to wide format\n  dat_wide <- data %>%\n    mutate(epidemic = if_else(inc_mean > 20, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) %>%\n      dplyr::select(study, epidemic, days, !!sym(weather_var)) %>%\n    pivot_wider(id_cols = c(study, epidemic), names_from = days, values_from = !!sym(weather_var))\n  \n\n  x <- dat_wide$epidemic  # Response vector\n  y <- dat_wide |>\n    dplyr::select(-study, -epidemic) |>\n    as.matrix()  # Matrix of predictors\n  \n  m2 <- pffr(y ~ x, \n             yind = yind,\n             bs.yindex = list(bs = \"ps\", k = 30, m = c(2, 1)), \n             bs.int = list(bs = \"ps\", k = 30, m = c(2, 1)),\n                algorithm = \"gam\")\n\n  coef_list <- coef(m2)$smterms\n  \n  mean_df <- data.frame(\n    time = coef_list[[1]]$coef[, \"yind.vec\"],\n    value = coef_list[[1]]$coef[, \"value\"],\n    lower = coef_list[[1]]$coef[, \"value\"] - 1.96 * coef_list[[1]]$coef[, \"se\"],\n    upper = coef_list[[1]]$coef[, \"value\"] + 1.96 * coef_list[[1]]$coef[, \"se\"],\n    term = \"Overall Mean\"\n  )\n  \n  x_df <- data.frame(\n    time = coef_list[[2]]$coef[, \"yind.vec\"],\n    value = coef_list[[2]]$coef[, \"value\"],\n    lower = coef_list[[2]]$coef[, \"value\"] - 1.96 * coef_list[[2]]$coef[, \"se\"],\n    upper = coef_list[[2]]$coef[, \"value\"] + 1.96 * coef_list[[2]]$coef[, \"se\"],\n    term = \"Difference\"\n  )\n  \n  plot_df <- bind_rows(mean_df, x_df)\n  \n   ggplot(plot_df, aes(x = time, y = value)) +\n    geom_ribbon(aes(ymin = lower, ymax = upper), \n                alpha = 0.2) +\n    geom_line(linewidth = 1.2) +\n    facet_grid(rows = vars(term), \n               scales = \"free_y\") +\n    theme_r4pde(font_size = 10) +\n    geom_hline(aes(yintercept = 0), \n               color = \"grey\", \n               linetype = \"dashed\") +\n    geom_vline(aes(xintercept = 0), \n               color = \"grey\", \n               linetype = \"dashed\") +\n    labs(x = \"Day relative to wheat heading\", y = \"Coefficient Function\",\n         title = weather_var) +\n    theme(strip.text = element_text(face = \"bold\", size = rel(1.0)),\n          axis.title = element_text(face = \"bold\", size = 10))\n}\n```\n:::\n\n\n\n\n\nNow we can apply the function to the other variables and obtain plots for each variable.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmin <- fosr(trials_weather, \"T2M_MIN\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nusing seWithMean for  s(yind.vec) .\n```\n\n\n:::\n\n```{.r .cell-code}\ntmax <- fosr(trials_weather, \"T2M_MAX\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nusing seWithMean for  s(yind.vec) .\n```\n\n\n:::\n\n```{.r .cell-code}\nrh <- fosr(trials_weather, \"RH2M\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nusing seWithMean for  s(yind.vec) .\n```\n\n\n:::\n\n```{.r .cell-code}\nprec <- fosr(trials_weather, \"PRECTOTCORR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nusing seWithMean for  s(yind.vec) .\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)\n\n(tmin |tmax)/(rh | prec)\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-49-1.png){width=672}\n:::\n:::\n\n\n\n\n\n##### Interval test procedure\n\nFor this test, we need to subset the data into two epidemic conditions, transform from long to wide format and create a matrix object.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_epidemic <- trials_weather |> \n  mutate(epidemic = if_else(inc_mean > 20, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) |>\n  filter(epidemic == 1) |> \n  dplyr::select(RH2M, days, study)\n\ndf_non_epidemic <- trials_weather |> \n   mutate(epidemic = if_else(inc_mean > 20, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) |>\n  filter(epidemic == 0) |> \n  dplyr::select(RH2M, days, study)\n\n# Pivot data to wide format for FDA\ndf_epidemic_wide <- df_epidemic |>\n  group_by(study) |>\n  pivot_wider(names_from = days, values_from = RH2M) |>\n  ungroup() |>\n  dplyr::select(-study)\n\ndf_non_epidemic_wide <- df_non_epidemic |>\n  group_by(study) |>\n  pivot_wider(names_from = days, values_from = RH2M) |>\n  ungroup() |>\n  dplyr::select(-study)\n\n# Convert to matrix\ndata_epidemic <- as.matrix(df_epidemic_wide)\ndata_non_epidemic <- as.matrix(df_non_epidemic_wide)\n```\n:::\n\n\n\n\n\nNow we can now apply the function specifying each new data in each data argument.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fdatest)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'fdatest' was built under R version 4.1.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: fda\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: splines\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: fds\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: rainbow\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: MASS\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'MASS'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:patchwork':\n\n    area\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:plotly':\n\n    select\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    select\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: pcaPP\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: RCurl\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'RCurl'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:tidyr':\n\n    complete\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: deSolve\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'fda'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:boot':\n\n    melanoma\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:graphics':\n\n    matplot\n```\n\n\n:::\n\n```{.r .cell-code}\n# Perform FDA test\nitp_result <- ITP2bspline(data1 = data_epidemic, \n                          data2 = data_non_epidemic, \n                          B = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"First step: basis expansion\"\nSwapping 'y' and 'argvals', because 'y' is  simpler,\n  and 'argvals' should be;  now  dim(argvals) =  57 ;  dim(y) =  57 x 143 \n[1] \"Second step: joint univariate tests\"\n[1] \"Third step: interval-wise combination and correction\"\n[1] \"creating the p-value matrix: end of row 2 out of 57\"\n[1] \"creating the p-value matrix: end of row 3 out of 57\"\n[1] \"creating the p-value matrix: end of row 4 out of 57\"\n[1] \"creating the p-value matrix: end of row 5 out of 57\"\n[1] \"creating the p-value matrix: end of row 6 out of 57\"\n[1] \"creating the p-value matrix: end of row 7 out of 57\"\n[1] \"creating the p-value matrix: end of row 8 out of 57\"\n[1] \"creating the p-value matrix: end of row 9 out of 57\"\n[1] \"creating the p-value matrix: end of row 10 out of 57\"\n[1] \"creating the p-value matrix: end of row 11 out of 57\"\n[1] \"creating the p-value matrix: end of row 12 out of 57\"\n[1] \"creating the p-value matrix: end of row 13 out of 57\"\n[1] \"creating the p-value matrix: end of row 14 out of 57\"\n[1] \"creating the p-value matrix: end of row 15 out of 57\"\n[1] \"creating the p-value matrix: end of row 16 out of 57\"\n[1] \"creating the p-value matrix: end of row 17 out of 57\"\n[1] \"creating the p-value matrix: end of row 18 out of 57\"\n[1] \"creating the p-value matrix: end of row 19 out of 57\"\n[1] \"creating the p-value matrix: end of row 20 out of 57\"\n[1] \"creating the p-value matrix: end of row 21 out of 57\"\n[1] \"creating the p-value matrix: end of row 22 out of 57\"\n[1] \"creating the p-value matrix: end of row 23 out of 57\"\n[1] \"creating the p-value matrix: end of row 24 out of 57\"\n[1] \"creating the p-value matrix: end of row 25 out of 57\"\n[1] \"creating the p-value matrix: end of row 26 out of 57\"\n[1] \"creating the p-value matrix: end of row 27 out of 57\"\n[1] \"creating the p-value matrix: end of row 28 out of 57\"\n[1] \"creating the p-value matrix: end of row 29 out of 57\"\n[1] \"creating the p-value matrix: end of row 30 out of 57\"\n[1] \"creating the p-value matrix: end of row 31 out of 57\"\n[1] \"creating the p-value matrix: end of row 32 out of 57\"\n[1] \"creating the p-value matrix: end of row 33 out of 57\"\n[1] \"creating the p-value matrix: end of row 34 out of 57\"\n[1] \"creating the p-value matrix: end of row 35 out of 57\"\n[1] \"creating the p-value matrix: end of row 36 out of 57\"\n[1] \"creating the p-value matrix: end of row 37 out of 57\"\n[1] \"creating the p-value matrix: end of row 38 out of 57\"\n[1] \"creating the p-value matrix: end of row 39 out of 57\"\n[1] \"creating the p-value matrix: end of row 40 out of 57\"\n[1] \"creating the p-value matrix: end of row 41 out of 57\"\n[1] \"creating the p-value matrix: end of row 42 out of 57\"\n[1] \"creating the p-value matrix: end of row 43 out of 57\"\n[1] \"creating the p-value matrix: end of row 44 out of 57\"\n[1] \"creating the p-value matrix: end of row 45 out of 57\"\n[1] \"creating the p-value matrix: end of row 46 out of 57\"\n[1] \"creating the p-value matrix: end of row 47 out of 57\"\n[1] \"creating the p-value matrix: end of row 48 out of 57\"\n[1] \"creating the p-value matrix: end of row 49 out of 57\"\n[1] \"creating the p-value matrix: end of row 50 out of 57\"\n[1] \"creating the p-value matrix: end of row 51 out of 57\"\n[1] \"creating the p-value matrix: end of row 52 out of 57\"\n[1] \"creating the p-value matrix: end of row 53 out of 57\"\n[1] \"creating the p-value matrix: end of row 54 out of 57\"\n[1] \"creating the p-value matrix: end of row 55 out of 57\"\n[1] \"creating the p-value matrix: end of row 56 out of 57\"\n[1] \"creating the p-value matrix: end of row 57 out of 57\"\n[1] \"Interval Testing Procedure completed\"\n```\n\n\n:::\n:::\n\n\n\n\n\nHere, we can see the p-values for each time point as well as which time points were significant considering p \\< 0.05.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# global p-values\nitp_result$corrected.pval\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n[39] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n```\n\n\n:::\n\n```{.r .cell-code}\n# significant components\nwhich(itp_result$corrected.pval < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\n[51] 51 52 53 54 55 56 57\n```\n\n\n:::\n:::\n\n\n\n\n\nThe plot function produces two graphs, one for the curves and another for the p-values where the shaded area indicate the significance.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot FDA results\nplot(itp_result, main = \"RH2M\", \n     xrange = c(-28, 28), \n     xlab = 'Day', xaxt = 'n')\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n\n```{.r .cell-code}\naxis(1, at = seq(-28, 28, by = 2), \n     labels = seq(-28, 28, by = 2))\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-53-2.png){width=672}\n:::\n:::\n\n\n\n\n\nBecause we may have several weather variables, we can avoid repeating the code for each variable by creating a function. The arguments are the data and weather variable. Optionally, the user can define the threshold for disease.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_ITP_test <- function(data, weather_var, threshold = 20, B = 100) {\n  \n  # Convert the weather_var input to symbol for dplyr's select function\n  weather_var_sym <- sym(weather_var)\n  \n  # Filter and prepare epidemic data\n  df_epidemic <- data |> \n    mutate(epidemic = if_else(inc_mean > threshold, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) |> \n    filter(epidemic == 1) |> \n    dplyr::select(!!weather_var_sym, days, study)\n  \n  # Filter and prepare non-epidemic data\n  df_non_epidemic <- data |> \n    mutate(epidemic = if_else(inc_mean > threshold, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD))) |> \n    filter(epidemic == 0) |> \n    dplyr::select(!!weather_var_sym, days, study)\n  \n  # Pivot epidemic data to wide format\n  df_epidemic_wide <- df_epidemic |> \n    group_by(study) |> \n    pivot_wider(names_from = days, values_from = !!weather_var_sym) |> \n    ungroup() |> \n    dplyr::select(-study)\n  \n  # Pivot non-epidemic data to wide format\n  df_non_epidemic_wide <- df_non_epidemic |> \n    group_by(study) |> \n    pivot_wider(names_from = days, values_from = !!weather_var_sym) |> \n    ungroup() |> \n    dplyr::select(-study)\n  \n  # Convert to matrix\n  data_epidemic <- as.matrix(df_epidemic_wide)\n  data_non_epidemic <- as.matrix(df_non_epidemic_wide)\n  \n  # Perform FDA test\n  itp_result <- ITP2bspline(data1 = data_epidemic, \n                            data2 = data_non_epidemic, \n                            B = B)\n  \n  return(itp_result)\n}\n```\n:::\n\n\n\n\n\nApplying the function to each variable.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nitp_tmin <- run_ITP_test(data = trials_weather, weather_var = \"T2M_MIN\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"First step: basis expansion\"\nSwapping 'y' and 'argvals', because 'y' is  simpler,\n  and 'argvals' should be;  now  dim(argvals) =  57 ;  dim(y) =  57 x 143 \n[1] \"Second step: joint univariate tests\"\n[1] \"Third step: interval-wise combination and correction\"\n[1] \"creating the p-value matrix: end of row 2 out of 57\"\n[1] \"creating the p-value matrix: end of row 3 out of 57\"\n[1] \"creating the p-value matrix: end of row 4 out of 57\"\n[1] \"creating the p-value matrix: end of row 5 out of 57\"\n[1] \"creating the p-value matrix: end of row 6 out of 57\"\n[1] \"creating the p-value matrix: end of row 7 out of 57\"\n[1] \"creating the p-value matrix: end of row 8 out of 57\"\n[1] \"creating the p-value matrix: end of row 9 out of 57\"\n[1] \"creating the p-value matrix: end of row 10 out of 57\"\n[1] \"creating the p-value matrix: end of row 11 out of 57\"\n[1] \"creating the p-value matrix: end of row 12 out of 57\"\n[1] \"creating the p-value matrix: end of row 13 out of 57\"\n[1] \"creating the p-value matrix: end of row 14 out of 57\"\n[1] \"creating the p-value matrix: end of row 15 out of 57\"\n[1] \"creating the p-value matrix: end of row 16 out of 57\"\n[1] \"creating the p-value matrix: end of row 17 out of 57\"\n[1] \"creating the p-value matrix: end of row 18 out of 57\"\n[1] \"creating the p-value matrix: end of row 19 out of 57\"\n[1] \"creating the p-value matrix: end of row 20 out of 57\"\n[1] \"creating the p-value matrix: end of row 21 out of 57\"\n[1] \"creating the p-value matrix: end of row 22 out of 57\"\n[1] \"creating the p-value matrix: end of row 23 out of 57\"\n[1] \"creating the p-value matrix: end of row 24 out of 57\"\n[1] \"creating the p-value matrix: end of row 25 out of 57\"\n[1] \"creating the p-value matrix: end of row 26 out of 57\"\n[1] \"creating the p-value matrix: end of row 27 out of 57\"\n[1] \"creating the p-value matrix: end of row 28 out of 57\"\n[1] \"creating the p-value matrix: end of row 29 out of 57\"\n[1] \"creating the p-value matrix: end of row 30 out of 57\"\n[1] \"creating the p-value matrix: end of row 31 out of 57\"\n[1] \"creating the p-value matrix: end of row 32 out of 57\"\n[1] \"creating the p-value matrix: end of row 33 out of 57\"\n[1] \"creating the p-value matrix: end of row 34 out of 57\"\n[1] \"creating the p-value matrix: end of row 35 out of 57\"\n[1] \"creating the p-value matrix: end of row 36 out of 57\"\n[1] \"creating the p-value matrix: end of row 37 out of 57\"\n[1] \"creating the p-value matrix: end of row 38 out of 57\"\n[1] \"creating the p-value matrix: end of row 39 out of 57\"\n[1] \"creating the p-value matrix: end of row 40 out of 57\"\n[1] \"creating the p-value matrix: end of row 41 out of 57\"\n[1] \"creating the p-value matrix: end of row 42 out of 57\"\n[1] \"creating the p-value matrix: end of row 43 out of 57\"\n[1] \"creating the p-value matrix: end of row 44 out of 57\"\n[1] \"creating the p-value matrix: end of row 45 out of 57\"\n[1] \"creating the p-value matrix: end of row 46 out of 57\"\n[1] \"creating the p-value matrix: end of row 47 out of 57\"\n[1] \"creating the p-value matrix: end of row 48 out of 57\"\n[1] \"creating the p-value matrix: end of row 49 out of 57\"\n[1] \"creating the p-value matrix: end of row 50 out of 57\"\n[1] \"creating the p-value matrix: end of row 51 out of 57\"\n[1] \"creating the p-value matrix: end of row 52 out of 57\"\n[1] \"creating the p-value matrix: end of row 53 out of 57\"\n[1] \"creating the p-value matrix: end of row 54 out of 57\"\n[1] \"creating the p-value matrix: end of row 55 out of 57\"\n[1] \"creating the p-value matrix: end of row 56 out of 57\"\n[1] \"creating the p-value matrix: end of row 57 out of 57\"\n[1] \"Interval Testing Procedure completed\"\n```\n\n\n:::\n\n```{.r .cell-code}\nitp_tmax <- run_ITP_test(data = trials_weather, weather_var = \"T2M_MAX\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"First step: basis expansion\"\nSwapping 'y' and 'argvals', because 'y' is  simpler,\n  and 'argvals' should be;  now  dim(argvals) =  57 ;  dim(y) =  57 x 143 \n[1] \"Second step: joint univariate tests\"\n[1] \"Third step: interval-wise combination and correction\"\n[1] \"creating the p-value matrix: end of row 2 out of 57\"\n[1] \"creating the p-value matrix: end of row 3 out of 57\"\n[1] \"creating the p-value matrix: end of row 4 out of 57\"\n[1] \"creating the p-value matrix: end of row 5 out of 57\"\n[1] \"creating the p-value matrix: end of row 6 out of 57\"\n[1] \"creating the p-value matrix: end of row 7 out of 57\"\n[1] \"creating the p-value matrix: end of row 8 out of 57\"\n[1] \"creating the p-value matrix: end of row 9 out of 57\"\n[1] \"creating the p-value matrix: end of row 10 out of 57\"\n[1] \"creating the p-value matrix: end of row 11 out of 57\"\n[1] \"creating the p-value matrix: end of row 12 out of 57\"\n[1] \"creating the p-value matrix: end of row 13 out of 57\"\n[1] \"creating the p-value matrix: end of row 14 out of 57\"\n[1] \"creating the p-value matrix: end of row 15 out of 57\"\n[1] \"creating the p-value matrix: end of row 16 out of 57\"\n[1] \"creating the p-value matrix: end of row 17 out of 57\"\n[1] \"creating the p-value matrix: end of row 18 out of 57\"\n[1] \"creating the p-value matrix: end of row 19 out of 57\"\n[1] \"creating the p-value matrix: end of row 20 out of 57\"\n[1] \"creating the p-value matrix: end of row 21 out of 57\"\n[1] \"creating the p-value matrix: end of row 22 out of 57\"\n[1] \"creating the p-value matrix: end of row 23 out of 57\"\n[1] \"creating the p-value matrix: end of row 24 out of 57\"\n[1] \"creating the p-value matrix: end of row 25 out of 57\"\n[1] \"creating the p-value matrix: end of row 26 out of 57\"\n[1] \"creating the p-value matrix: end of row 27 out of 57\"\n[1] \"creating the p-value matrix: end of row 28 out of 57\"\n[1] \"creating the p-value matrix: end of row 29 out of 57\"\n[1] \"creating the p-value matrix: end of row 30 out of 57\"\n[1] \"creating the p-value matrix: end of row 31 out of 57\"\n[1] \"creating the p-value matrix: end of row 32 out of 57\"\n[1] \"creating the p-value matrix: end of row 33 out of 57\"\n[1] \"creating the p-value matrix: end of row 34 out of 57\"\n[1] \"creating the p-value matrix: end of row 35 out of 57\"\n[1] \"creating the p-value matrix: end of row 36 out of 57\"\n[1] \"creating the p-value matrix: end of row 37 out of 57\"\n[1] \"creating the p-value matrix: end of row 38 out of 57\"\n[1] \"creating the p-value matrix: end of row 39 out of 57\"\n[1] \"creating the p-value matrix: end of row 40 out of 57\"\n[1] \"creating the p-value matrix: end of row 41 out of 57\"\n[1] \"creating the p-value matrix: end of row 42 out of 57\"\n[1] \"creating the p-value matrix: end of row 43 out of 57\"\n[1] \"creating the p-value matrix: end of row 44 out of 57\"\n[1] \"creating the p-value matrix: end of row 45 out of 57\"\n[1] \"creating the p-value matrix: end of row 46 out of 57\"\n[1] \"creating the p-value matrix: end of row 47 out of 57\"\n[1] \"creating the p-value matrix: end of row 48 out of 57\"\n[1] \"creating the p-value matrix: end of row 49 out of 57\"\n[1] \"creating the p-value matrix: end of row 50 out of 57\"\n[1] \"creating the p-value matrix: end of row 51 out of 57\"\n[1] \"creating the p-value matrix: end of row 52 out of 57\"\n[1] \"creating the p-value matrix: end of row 53 out of 57\"\n[1] \"creating the p-value matrix: end of row 54 out of 57\"\n[1] \"creating the p-value matrix: end of row 55 out of 57\"\n[1] \"creating the p-value matrix: end of row 56 out of 57\"\n[1] \"creating the p-value matrix: end of row 57 out of 57\"\n[1] \"Interval Testing Procedure completed\"\n```\n\n\n:::\n\n```{.r .cell-code}\nitp_prec <- run_ITP_test(data = trials_weather, weather_var = \"PRECTOTCORR\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"First step: basis expansion\"\nSwapping 'y' and 'argvals', because 'y' is  simpler,\n  and 'argvals' should be;  now  dim(argvals) =  57 ;  dim(y) =  57 x 143 \n[1] \"Second step: joint univariate tests\"\n[1] \"Third step: interval-wise combination and correction\"\n[1] \"creating the p-value matrix: end of row 2 out of 57\"\n[1] \"creating the p-value matrix: end of row 3 out of 57\"\n[1] \"creating the p-value matrix: end of row 4 out of 57\"\n[1] \"creating the p-value matrix: end of row 5 out of 57\"\n[1] \"creating the p-value matrix: end of row 6 out of 57\"\n[1] \"creating the p-value matrix: end of row 7 out of 57\"\n[1] \"creating the p-value matrix: end of row 8 out of 57\"\n[1] \"creating the p-value matrix: end of row 9 out of 57\"\n[1] \"creating the p-value matrix: end of row 10 out of 57\"\n[1] \"creating the p-value matrix: end of row 11 out of 57\"\n[1] \"creating the p-value matrix: end of row 12 out of 57\"\n[1] \"creating the p-value matrix: end of row 13 out of 57\"\n[1] \"creating the p-value matrix: end of row 14 out of 57\"\n[1] \"creating the p-value matrix: end of row 15 out of 57\"\n[1] \"creating the p-value matrix: end of row 16 out of 57\"\n[1] \"creating the p-value matrix: end of row 17 out of 57\"\n[1] \"creating the p-value matrix: end of row 18 out of 57\"\n[1] \"creating the p-value matrix: end of row 19 out of 57\"\n[1] \"creating the p-value matrix: end of row 20 out of 57\"\n[1] \"creating the p-value matrix: end of row 21 out of 57\"\n[1] \"creating the p-value matrix: end of row 22 out of 57\"\n[1] \"creating the p-value matrix: end of row 23 out of 57\"\n[1] \"creating the p-value matrix: end of row 24 out of 57\"\n[1] \"creating the p-value matrix: end of row 25 out of 57\"\n[1] \"creating the p-value matrix: end of row 26 out of 57\"\n[1] \"creating the p-value matrix: end of row 27 out of 57\"\n[1] \"creating the p-value matrix: end of row 28 out of 57\"\n[1] \"creating the p-value matrix: end of row 29 out of 57\"\n[1] \"creating the p-value matrix: end of row 30 out of 57\"\n[1] \"creating the p-value matrix: end of row 31 out of 57\"\n[1] \"creating the p-value matrix: end of row 32 out of 57\"\n[1] \"creating the p-value matrix: end of row 33 out of 57\"\n[1] \"creating the p-value matrix: end of row 34 out of 57\"\n[1] \"creating the p-value matrix: end of row 35 out of 57\"\n[1] \"creating the p-value matrix: end of row 36 out of 57\"\n[1] \"creating the p-value matrix: end of row 37 out of 57\"\n[1] \"creating the p-value matrix: end of row 38 out of 57\"\n[1] \"creating the p-value matrix: end of row 39 out of 57\"\n[1] \"creating the p-value matrix: end of row 40 out of 57\"\n[1] \"creating the p-value matrix: end of row 41 out of 57\"\n[1] \"creating the p-value matrix: end of row 42 out of 57\"\n[1] \"creating the p-value matrix: end of row 43 out of 57\"\n[1] \"creating the p-value matrix: end of row 44 out of 57\"\n[1] \"creating the p-value matrix: end of row 45 out of 57\"\n[1] \"creating the p-value matrix: end of row 46 out of 57\"\n[1] \"creating the p-value matrix: end of row 47 out of 57\"\n[1] \"creating the p-value matrix: end of row 48 out of 57\"\n[1] \"creating the p-value matrix: end of row 49 out of 57\"\n[1] \"creating the p-value matrix: end of row 50 out of 57\"\n[1] \"creating the p-value matrix: end of row 51 out of 57\"\n[1] \"creating the p-value matrix: end of row 52 out of 57\"\n[1] \"creating the p-value matrix: end of row 53 out of 57\"\n[1] \"creating the p-value matrix: end of row 54 out of 57\"\n[1] \"creating the p-value matrix: end of row 55 out of 57\"\n[1] \"creating the p-value matrix: end of row 56 out of 57\"\n[1] \"creating the p-value matrix: end of row 57 out of 57\"\n[1] \"Interval Testing Procedure completed\"\n```\n\n\n:::\n\n```{.r .cell-code}\nitp_tmin$corrected.pval\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.00 0.02 0.04 0.00 0.00 0.00 0.00 0.00 0.01 0.00 0.00 0.00 0.00 0.00 0.00\n[16] 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.01 0.00 0.00 0.00 0.00 0.01 0.07 0.00\n[31] 0.00 0.02 0.01 0.02 0.01 0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.18 0.06 0.03\n[46] 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.01 0.04 0.04 0.09\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich(itp_tmin$corrected.pval < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 30 31 32 33 34 35 36 37 38 39 40 41 42 45 46 47 48 49 50 51 52 53\n[51] 54 55 56\n```\n\n\n:::\n\n```{.r .cell-code}\nitp_tmax$corrected.pval\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.05 0.05 0.08 0.22 0.09 0.09 0.08 0.09 0.13 0.56 0.28 0.18 0.22 0.38 0.47\n[16] 0.59 0.52 0.52 0.63 0.36 0.18 0.24 0.20 0.30 0.56 0.57 0.37 0.18 0.13 0.11\n[31] 0.11 0.15 0.16 0.16 0.18 0.20 0.22 0.53 0.32 0.32 0.28 0.23 0.30 0.42 0.41\n[46] 0.30 0.52 0.79 0.91 0.61 0.58 0.58 0.46 0.33 0.00 0.05 0.07\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich(itp_tmax$corrected.pval < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 55\n```\n\n\n:::\n\n```{.r .cell-code}\nitp_prec$corrected.pval\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0.00 0.18 0.42 0.10 0.37 0.05 0.00 0.00 0.94 0.08 0.02 0.06 0.00 0.00 0.25\n[16] 0.00 0.00 0.00 0.01 0.49 0.00 0.03 0.01 0.01 0.19 0.07 0.01 0.01 0.00 0.00\n[31] 0.00 0.00 0.00 0.30 0.00 0.00 0.04 0.03 0.00 0.00 0.03 0.19 0.83 0.62 0.52\n[46] 0.41 0.77 0.92 0.92 0.92 0.41 0.18 0.00 0.00 0.00 0.06 0.01\n```\n\n\n:::\n\n```{.r .cell-code}\nwhich(itp_prec$corrected.pval < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  1  7  8 11 13 14 16 17 18 19 21 22 23 24 27 28 29 30 31 32 33 35 36 37 38\n[26] 39 40 41 53 54 55 57\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(itp_tmin, main = \"TMIN\", \n     xrange = c(-28, 28), \n     xlab = 'Day', xaxt = 'n')\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-1.png){width=672}\n:::\n\n```{.r .cell-code}\naxis(1, at = seq(-28, 28, by = 2), \n     labels = seq(-28, 28, by = 2))\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(itp_tmax, main = \"TMAX\", \n     xrange = c(-28, 28), \n     xlab = 'Day', xaxt = 'n')\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-3.png){width=672}\n:::\n\n```{.r .cell-code}\naxis(1, at = seq(-28, 28, by = 2), \n     labels = seq(-28, 28, by = 2))\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(itp_prec, main = \"PREC\", \n     xrange = c(-28, 28), \n     xlab = 'Day', xaxt = 'n')\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-5.png){width=672}\n:::\n\n```{.r .cell-code}\naxis(1, at = seq(-28, 28, by = 2), \n     labels = seq(-28, 28, by = 2))\n```\n\n::: {.cell-output-display}\n![](prediction-disease-modeling_files/figure-html/unnamed-chunk-55-6.png){width=672}\n:::\n:::\n\n\n\n\n\n**Interpretation**: Based on the results above, minimum temperature and relative humidity had a significant influence across the entire range of days, particularly during the pre-heading period. Maximum temperature did not affect the epidemics at any time. Lastly, precipitation influenced wheat blast during several short intervals, with the most notable impact occurring over a longer seven-day period around the heading stage. Therefore, TMIN, RH and PREC can be tested further as candidate predictors in prediction models.\n\n### Model fitting\n\n#### Logistic regression models\n\nLogistic regression is a statistical modeling technique used to predict the probability of a binary outcome based on one or more predictor variables [@james2021]. In the context of plant disease prediction, the logistic model relates factors like environmental conditions (usually weather), host characteristics (e.g., cultivar resistance), and pathogen presence to the likelihood of disease occurrence. This occurrence can be expressed as presence or absence [@mila2004] or as a classification of incidence/severity based on an epidemic threshold [@dewolf2003; @dec√≥l2024]. By integrating these variables, the model enables researchers to assess disease risk under varying conditions and to develop decision support systems. This modeling approach has been used successfully in several studies in the field [@harikrishnan2008; @xu2013; @romero2021; @shah2013; @mila2004; @dec√≥l2024; @willbur2018; @dewolf2003], demonstrating its efficacy in predicting disease outbreaks and informing early intervention efforts.\n\nThe logistic model uses the logistic function to transform a linear combination of predictors into a probability between 0 and 1. This transformation ensures that the predicted values are valid probabilities, facilitating meaningful interpretations. By estimating the influence of each predictor on the odds of disease, logistic regression helps identify significant risk factors. Additionally, the model's coefficients provide insights into the strength and direction of the association between predictors and disease risk, offering valuable information for understanding the underlying mechanisms of disease development and progression.\n\nThe logistic regression model predicts the probability $P$ of the binary outcome $Y = 1 \\mid X$ (e.g., presence or absence of disease) given a set of predictor variables $X$. The model uses the logistic function to ensure the predicted probabilities lie between 0 and 1:\n\n$P(Y = 1 \\mid X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p)}}$\n\nAlternatively, the model can be expressed in terms of the log-odds (also known as the logit function):\n\n$\\log\\left( \\frac{P(Y = 1 \\mid X)}{1 - P(Y = 1 \\mid X)} \\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_p X_p$\n\nCompared to more complex machine learning models, logistic regression offers a high degree of interpretability, which is crucial in many scientific and practical applications. While models like neural networks, random forests, or support vector machines can achieve high predictive accuracy, they often function as \"black boxes\" where the relationship between predictors and the outcome is not easily understood [@molnar2019]. In contrast, logistic regression provides clear and direct interpretations of model parameters, allowing researchers and practitioners to understand how each predictor variable influences the probability of disease occurrence. This transparency makes logistic regression a preferred choice in contexts where explaining the underlying relationships is as important as prediction accuracy. The balance between interpretability and predictive performance justifies the choice of logistic regression in several contexts, especially when insights into the data are essential for decision-making, which is the case in plant disease prediction contexts.\n\nIn this section, we will keep working with the wheat blast disease data and expand on the previous sections on variable construction and selection, a usual step prior to testing the prediction variables in the logistic regression model.\n\n##### Data preparation\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(r4pde)\nlibrary(tidyverse)\n\n# load the disease datase\ntrials <- r4pde::BlastWheat\ntrials$heading = as.Date(trials$heading, format = \"%d-%m-%Y\")\n\n# load the weather data \nweather_data <- readr::read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/refs/heads/main/data/weather_windowpane.csv\")\n\n# join the two datasets\ntrials_weather <- full_join(trials, weather_data)\n\n# create epidemic variable and number of days relative to heading\ntrials_weather <- trials_weather |>\n    mutate(epidemic = if_else(inc_mean > 20, 1, 0),\n           days = as.numeric(-(heading - YYYYMMDD)))\n```\n:::\n\n\n\n\n\nLet's create a few weather-related variables based on the original variables available from the NASA POWER. First, we need to group by study and epidemic and then filter the days to only the pre-heading (28 days) since will attempt to develop a model using only pre-heading variables. We will not include mean daily maximum temperature given its weak association based on window pane and not significant influence based on the interval test procedure of the FDA (see previous section).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nepi_weather <- trials_weather |> \n  group_by(study, epidemic) |> \n  filter(days >= -28 & days <= -1) |> \n  summarise(\n    tmin_pre = mean(T2M_MIN, na.rm = TRUE),\n    rh_pre = mean(RH2M, na.rm = TRUE),\n    prec_pre = mean(PRECTOTCORR, na.rm = TRUE))|> \n  ungroup() |> \n  dplyr::select(- study)\n```\n:::\n\n\n\n\n\n##### Model fitting\n\nNow we can fit the model and look at the summary.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model fitting\nm_logistic <- glm(epidemic ~ tmin_pre + rh_pre + prec_pre, \n                      data = epi_weather, \n                      family = binomial)\n\n# Model summary\nsummary(m_logistic)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = epidemic ~ tmin_pre + rh_pre + prec_pre, family = binomial, \n    data = epi_weather)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1986  -0.5938   0.3459   0.6545   2.1343  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -20.16698    3.87801  -5.200 1.99e-07 ***\ntmin_pre      0.27391    0.08610   3.181  0.00147 ** \nrh_pre        0.22020    0.04734   4.652 3.29e-06 ***\nprec_pre     -0.12680    0.20907  -0.606  0.54420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 197.06  on 142  degrees of freedom\nResidual deviance: 125.11  on 139  degrees of freedom\nAIC: 133.11\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n:::\n\n\n\n\n\ninterpretation of the coefficients:\n\n-   Intercept: Estimate of -20.17, indicating the baseline log-odds of an epidemic when all predictors are zero.\n\n-   tmin_pre: Positive estimate (0.27, p = 0.00147), indicating that higher minimum temperatures are significantly associated with an increased probability of an epidemic.\n\n-   rh_pre: Positive estimate (0.22, p \\< 0.001), suggesting that higher relative humidity is strongly associated with an increased probability of an epidemic.\n\n-   prec_pre: Negative but non-significant estimate (-0.13, p = 0.544), indicating no significant relationship between precipitation and epidemic occurrence.\n\nModel fit\n\n-   The null deviance (197.06) reflects the fit of a model without predictors, while the residual deviance (125.11) indicates the fit of the full model with predictors. A significant reduction in deviance suggests that the predictors improve model fit.\n\n-   The AIC (133.11) helps evaluate model performance, with lower values indicating better fit.\n\nLet's fit again the model using only the two significant variables.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_logistic <- glm(epidemic ~ tmin_pre + rh_pre, \n                      data = epi_weather, \n                      family = binomial)\n```\n:::\n\n\n\n\n\n::: callout-important\nConclusion: Minimum temperature and relative humidity before the event are significant predictors of epidemics, while precipitation is not. This suggests that warmer and more humid conditions may increase the likelihood of an epidemic, aligning with expectations for many plant diseases including wheat blast.\n:::\n\nWe can check the accuracy of the model in predicting the training data.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# Obtain the predicted probability\npred_probs <- predict(m_logistic, epi_weather, type = \"response\")\n\n# Convert probabilities to binary outcomes using 0.5 as the threshold\npred_classes <- ifelse(pred_probs >= 0.5, 1, 0)\n\n# Calculate accuracy\nactual_classes <- epi_weather$epidemic\naccuracy <- mean(pred_classes == actual_classes)\naccuracy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7832168\n```\n\n\n:::\n:::\n\n\n\n\n\nThe `confusionMatrix()` function of the {caret} package gives a more complete information about the perfomrance of the model on the training set.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create the confusion matrix\nconfusionMatrix(data = as.factor(as.numeric(pred_probs > 0.50)),  mode= \"everything\",  reference = as.factor(epi_weather$epidemic))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 48 14\n         1 17 64\n                                          \n               Accuracy : 0.7832          \n                 95% CI : (0.7066, 0.8477)\n    No Information Rate : 0.5455          \n    P-Value [Acc > NIR] : 2.797e-09       \n                                          \n                  Kappa : 0.5611          \n                                          \n Mcnemar's Test P-Value : 0.7194          \n                                          \n            Sensitivity : 0.7385          \n            Specificity : 0.8205          \n         Pos Pred Value : 0.7742          \n         Neg Pred Value : 0.7901          \n              Precision : 0.7742          \n                 Recall : 0.7385          \n                     F1 : 0.7559          \n             Prevalence : 0.4545          \n         Detection Rate : 0.3357          \n   Detection Prevalence : 0.4336          \n      Balanced Accuracy : 0.7795          \n                                          \n       'Positive' Class : 0               \n                                          \n```\n\n\n:::\n:::\n\n\n\n\n\n##### Model evaluation\n\nIt is highly desirable to evaluate model performance metrics using data that was not \"seen\" by the model during training. If the dataset is sufficiently large (e.g., more than 300 observations), it can be split into training and test sets, typically using an 80:20 ratio. For smaller datasets, alternatives like leave-one-out cross-validation (LOOCV) can be applied, as was done in the original wheat blast model study, which had 143 cases available [@dec√≥l2024].\n\nThe Leave-One-Out Cross-Validation (LOOCV) is a resampling method used to evaluate model performance, particularly with small datasets. In LOOCV, the model is trained repeatedly, each time using all but one observation, which is set aside for testing. This process is repeated until every observation has served as the test case once. The overall performance metric is calculated by averaging the results from all iterations, providing an unbiased estimate of model accuracy [@hastie2009].\n\nLet's first create the training and test data.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_index <- createDataPartition(epi_weather$epidemic, p = 0.8, list = FALSE)\ntrain_data <- epi_weather[train_index, ]\ntest_data <- epi_weather[-train_index, ]\n```\n:::\n\n\n\n\n\nNow we fit the logistic model on the training data and obtain the predictions.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the model on training data\nm_logistic2 <- glm(epidemic ~ tmin_pre + rh_pre, \n                   data = train_data, \n                   family = binomial)\n\n# Predict on the test data\npred <- predict(m_logistic2, newdata = test_data, type = \"response\")\n```\n:::\n\n\n\n\n\nLet's build now the confusion matrix for the test data.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusion_matrix <- confusionMatrix(data = as.factor(as.numeric(pred > 0.5)), reference = as.factor(test_data$epidemic), mode = \"everything\")\nprint(confusion_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 10  0\n         1  6 12\n                                         \n               Accuracy : 0.7857         \n                 95% CI : (0.5905, 0.917)\n    No Information Rate : 0.5714         \n    P-Value [Acc > NIR] : 0.01543        \n                                         \n                  Kappa : 0.5882         \n                                         \n Mcnemar's Test P-Value : 0.04123        \n                                         \n            Sensitivity : 0.6250         \n            Specificity : 1.0000         \n         Pos Pred Value : 1.0000         \n         Neg Pred Value : 0.6667         \n              Precision : 1.0000         \n                 Recall : 0.6250         \n                     F1 : 0.7692         \n             Prevalence : 0.5714         \n         Detection Rate : 0.3571         \n   Detection Prevalence : 0.3571         \n      Balanced Accuracy : 0.8125         \n                                         \n       'Positive' Class : 0              \n                                         \n```\n\n\n:::\n:::\n\n\n\n\n\nThe code below provides a comparative evaluation of model accuracy using two different cross-validation techniques, the LOOCV and 10-fold cross validation. The latter is similar to the LOOCV code, but with the addition of `K = 10`, which specifies 10-fold cross-validation. Here, the dataset is divided into 10 subsets (folds), with the model trained on 9 folds and tested on the remaining fold. This process repeats for all 10 folds, averaging the results. For both we need a custom cost function that evaluates the performance of a binary classifier. Note that we will use the model 1 built with all observations, not the training data.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(boot)\n\ncost <- function(r, pi = 0) mean(abs(r - pi) > 0.5)\n\n# LOOCV (accuracy)\n1 - cv.glm(epi_weather, m_logistic, cost = cost)$delta[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7762238\n```\n\n\n:::\n\n```{.r .cell-code}\n# K-fold CV K=10 (accuracy)\n1 - cv.glm(epi_weather, m_logistic, K = 10, cost = cost)$delta[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7762238\n```\n\n\n:::\n:::\n\n\n\n\n\nWe can conclude that using only two variables from relatively long periods before heading, the model can reasonably predict wheat blast. We can further explore the effect of other variables from the post-heading period, as well as variables from shorter intervals around heading and flowering---periods when infections are likely to occur.\n\nFor instance, in the FDA section, rainfall around heading was significantly associated with the epidemics. In the original paper, the best models with two to five predictors achieved accuracies between 0.80 and 0.85, with one model including rainfall during the 7-day period after heading, consistent with the FDA results from the previous section.\n\nVariable selection is a critical process that combines statistical techniques with biological knowledge to identify the most relevant predictors for a given model. Approaches can range from simple methods, like selecting the most correlated variables at periods of time know as most critical for infection or epidemic development [@dewolf2003], to more advanced algorithms designed to optimize predictive power, such as regularization techniques like lasso or elastic-net [@dec√≥l2024; @dallalana2021a; @dewolf2023].\n\nRegularization methods not only help in selecting significant predictors but also in handling multicollinearity and reducing model complexity [@hastie2009]. These methods will be demonstrated further in the following sections, where Lasso and similar techniques are discussed in detail.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/htmlwidgets-1.6.3/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.0/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.0/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}