[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R4PDE",
    "section": "",
    "text": "Welcome\nR for Plant Disease Epidemiology (R4PDE) is a dynamic book project rooted in the teachings of the annual graduate course, FIP 602 - Plant Disease Epidemiology, a key part of the curriculum in the Graduate Program in Plant Pathology at Universidade Federal de Viçosa.\nDesigned for those passionate about studying and modeling plant disease epidemics with R, the book offers an exploration of diverse methods for describing, visualizing, and analyzing epidemic data collected over time or space. Readers should ideally have a foundational knowledge of R to best utilize the examples.\nHowever, R4PDE is not a resource for learning data science through R, there are already well-established books such as R for data science for that purpose. Portuguese-speaking readers are recommended Análises Ecológicas no R and Software R para avaliação de dados experimentais as excellent R learning resources, with an added focus on statistics using R.\nThe book often draws upon data and replicates analyses from The Study of Plant Disease Epidemics (Madden et al. 2017). A mix of general and specific R packages are utilized to conduct common plant disease epidemiology data analysis, notably epifitter and epiphy, both designed by plant pathologists. In conjunction with this book, a new R package r4pde has been developed and can be installed from GitHub using:\n# install.packages(\"remotes\")\nremotes::install_github(\"emdelponte/r4pde\")\nAs a work in progress, the book is frequently updated and edited. The website is free to use, licensed under a Creative Commons licence, and the code for all analyses can be found on GitHub. While there are no immediate plans for a printed version, it is under consideration as the book further develops. The website is hosted by https://www.netlify.com/.\nContributions to R4PDE are subject to a Contributor Code of Conduct, and by contributing, you agree to adhere to its terms."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R4PDE",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo those who have contributed fixes and improvements via pull request or other form of contact: Adam Sparks (@adamhsparks), Remco Stam (@remco-stam)\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058."
  },
  {
    "objectID": "author.html",
    "href": "author.html",
    "title": "About the author",
    "section": "",
    "text": "I, Emerson M. Del Ponte, serve as a Professor at the Departamento de Fitopatologia, Universidade Federal de Viçosa in Brazil. My academic journey includes a DSc in Plant Pathology, which I obtained from Universidade Federal de Pelotas in 2004, and a year-long visit to Cornell University in the Bergstrom Lab. Following this, I spent nearly two years as a postdoctoral associate working on a project related to disease risk assessment and prediction at the Yang Lab, Iowa State University. This experience led me to the Universidade Federal do Rio Grande do Sul, Brazil, where I joined as an assistant professor of plant pathology. My peer-reviewed publications are available on various academic platforms, such as ORCID, Google Scholar, and ResearchGate.\nI am a fervent advocate for an open and reproducible research model and culture, which I believe can lead to more accessible, transparent, and reliable scientific knowledge. This belief inspired my co-founding of the Open Plant Pathology initiative alongside Adam Sparks. In my Lab, students use the R language for all statistics and data science-related activities. All data and computational codes generated during our research are made accessible before the peer-review process. The code can be located on GitHub. Our research findings are mostly organized and shared as a research compendium, and we archive preprints of manuscripts in the Open Science Framework (OSF)."
  },
  {
    "objectID": "intro.html#introduction",
    "href": "intro.html#introduction",
    "title": "1  Introduction",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nDisease in plants can be defined as any malfunctioning of host cells and tissues that results from continuous irritation by a pathogenic agent or environmental factor and leads to development of symptoms (Agrios 2005a). When caused by pathogenic agent, the disease results from the combination of three elements: susceptible host plant, a virulent pathogen, and favorable environmental conditions - the famous disease triangle. When a pathogen population establishes and causes disease in a host population, the phenomenon is called an epidemic, or the disease in populations. Among several definitions of epidemic, a comprehensive one is the change in disease intensity in a host population over time and space (Madden et al. 2017).\nDifferent versions of the disease triangle, by the inclusion of other elements (e.g. man and time), as points and/or dimensions, have been proposed to illustrate an epidemic (Agrios 2005b). One we prefer is the disease prism where a series of triangles sequentially stacked illustrates the development of plant disease through time (Francl 2001).\n\n\n\nFigure 1.1: The plant disease prism as a model of plant disease epidemics"
  },
  {
    "objectID": "intro.html#importance-of-epidemics",
    "href": "intro.html#importance-of-epidemics",
    "title": "1  Introduction",
    "section": "1.2 Importance of epidemics",
    "text": "1.2 Importance of epidemics\nEpidemics bear significant economic importance due to their potential to decrease crop yields, diminish product quality, and escalate control costs, contingent on their intensity level. Numerous historical examples of widespread epidemics, reaching pandemic levels and resulting in catastrophic effects on crops, have been documented (Agrios 2005b). The Irish potato famine of 1845–1847, caused by the late blight pathogen (Phytophthora infestans), is a famous example of a well-documented pandemic. This disease notably altered the course of history in Europe and the United States, and was pivotal in the evolution of the science of plant pathology. During the 1840s, the pathogen ravaged potato crops, which were a dietary staple for the Irish. The disease outbreak was triggered by the introduction of a novel, virulent pathogen population that found suitable environmental conditions (cool and wet weather) for infection and development within a dense population of susceptible hosts.\nHowever, there are several reasons why devastating epidemics may continue to unfold. Recent history has seen severe epidemics reaching pandemic levels due to the incursion of pathogens into regions where they had previously been absent (refer to Box 1). Alternatively, new pathogenic strains might emerge as a result of factors driving genetic diversity within the local pathogen population. A case in point is the Ug99 strain of the wheat stem rust, which poses a significant threat to global wheat production. First identified in Uganda in 1998, an asexual lineage has propagated through Africa and the Middle East, causing catastrophic epidemics. Research suggests that Ug99 emerged via somatic hybridization and nuclear exchange between isolates from different lineages (Li et al. 2019). Finally, disease emergence or re-emergence can be influenced by shifts in climatic patterns. For instance, the Fusarium head blight of wheat caused by the fungus Fusarium graminearum. In Southern Brazil, the increased frequency of severe epidemics resulting in greater yield loss since the early 1990s has been linked to alterations in rainfall patterns across decades (Duffeck et al. 2020).\n\n\n\n\n\n\nBox 1: Diseases on the move\n\n\n\nIn Brazil, the soybean rust pathogen (Phakopsora pachyrhizi) first reached southern Brazil in 2002 (Yorinori et al. 2005). The disease spread to all production regions of the country in the following few years, severely reducing yields. To overcome the problem, farmers have relied on massive applications of fungicides on soybeans, which dramatically increased the production costs with the need for sequential fungicide sprays to combat the disease. Total economic loss have been estimated at around US$ 2 billion yearly (Godoy et al. 2016). More recently, wheat blast, a disease that originated in the south of Brazil in 1984, and have been restricted to South America, was firstly spotted in South Asia, Bangladesh, in 2016. Blast epidemics in that occasion devastated more than 15,000 ha of wheat and reduced yield of wheat in the affected field up to 100% (Malaker et al. 2016; Islam et al. 2019). The disease was later found in Zambia, thus also becoming a threat to wheat production in Africa (Tembo et al. 2020). In Brazil, the wheat blast disease is a current threat to expansion of wheat cultivation in the tropics(Cruz and Valent 2017)."
  },
  {
    "objectID": "intro.html#history-of-epidemiology",
    "href": "intro.html#history-of-epidemiology",
    "title": "1  Introduction",
    "section": "1.3 History of Epidemiology",
    "text": "1.3 History of Epidemiology\nBotanical epidemiology, or the study of plant disease epidemics, is a discipline with roots tracing back to the early 1960s. However, its origins can be linked to events from centuries and decades prior. For instance, in 1728, Duhamel de Monceau presented the earliest known epidemiological work on a disease, referred to as ‘Death,’ that afflicted saffron crocus (Rhizoctonia violacea). Fast forward to 1858, a textbook detailing plant diseases, written by Julius Kuhn, made its debut, introducing the concept of an epidemic as illustrated by the Irish late blight epidemics of 1845-46. Subsequently, in 1901, H.M. Ward adopted an ecological perspective to the study of plant diseases in his seminal book, Disease in Plants. By 1946, Gäumann penned the first book exclusively devoted to plant disease epidemiology.\nFurther evolution of this field was marked by the publication of a chapter titled “Analysis of Epidemics” by J.E. Vanderplank in Plant Pathology, vol. 3, edited by Horsfall and Dimond, in 1960. Vanderplank elaborated on his pioneering ideas in his 1963 book, “Plant Diseases: Epidemics and Control”(Vanderplank 1963). He is universally recognized as the foundational figure of plant disease epidemiology (Zadoks and Schein 1988; Thresh 1998), his landmark book being the first to comprehensively describe and quantify plant disease epidemics, and offering a theoretical framework for epidemic analysis.\nIn the same year, the first International Epidemiology Workshop was convened in Pau, France. This event constitutes an important milestone in the historical narrative, significantly contributing to the molding of this emergent discipline.\n\n\n\nFigure 1.2: Group photo of the First International Epidemiology Workshop\n\n\n\n\n\n\nAgrios, G. N. 2005a. INTRODUCTION. In Elsevier, p. 3–75. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50007-5.\n\n\nAgrios, G. N. 2005b. Plant disease epidemiology. In Elsevier, p. 265–291. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50014-2.\n\n\nCruz, C. D., and Valent, B. 2017. Wheat blast disease: danger on the move. Tropical Plant Pathology. 42:210–222 Available at: http://dx.doi.org/10.1007/s40858-017-0159-z.\n\n\nDuffeck, M. R., Santos Alves, K. dos, Machado, F. J., Esker, P. D., and Del Ponte, E. M. 2020. Modeling Yield Losses and Fungicide Profitability for Managing Fusarium Head Blight in Brazilian Spring Wheat. Phytopathology®. 110:370–378 Available at: http://dx.doi.org/10.1094/PHYTO-04-19-0122-R.\n\n\nFrancl, L. J. 2001. The..disease triangle: A plant pathological paradigm revisited. The Plant Health Instructor. Available at: http://dx.doi.org/10.1094/PHI-T-2001-0517-01.\n\n\nGodoy, C. V., Seixas, C. D. S., Soares, R. M., Marcelino-Guimarães, F. C., Meyer, M. C., and Costamilan, L. M. 2016. Asian soybean rust in brazil: Past, present, and future. Pesquisa Agropecuária Brasileira. 51:407–421 Available at: http://dx.doi.org/10.1590/S0100-204X2016000500002.\n\n\nIslam, M. T., Kim, K.-H., and Choi, J. 2019. Wheat Blast in Bangladesh: The Current Situation and Future Impacts. The Plant Pathology Journal. 35:1–10 Available at: http://dx.doi.org/10.5423/ppj.rw.08.2018.0168.\n\n\nLi, F., Upadhyaya, N. M., Sperschneider, J., Matny, O., Nguyen-Phuc, H., Mago, R., et al. 2019. Emergence of the Ug99 lineage of the wheat stem rust pathogen through somatic hybridisation. Nature Communications. 10 Available at: http://dx.doi.org/10.1038/s41467-019-12927-7.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMalaker, P. K., Barma, N. C. D., Tiwari, T. P., Collis, W. J., Duveiller, E., Singh, P. K., et al. 2016. First Report of Wheat Blast Caused by Magnaporthe oryzae Pathotype triticum in Bangladesh. Plant Disease. 100:2330–2330 Available at: http://dx.doi.org/10.1094/pdis-05-16-0666-pdn.\n\n\nTembo, B., Mulenga, R. M., Sichilima, S., M’siska, K. K., Mwale, M., Chikoti, P. C., et al. 2020. Detection and characterization of fungus (Magnaporthe oryzae pathotype Triticum) causing wheat blast disease on rain-fed grown wheat (Triticum aestivum L.) in Zambia ed. Zonghua Wang. PLOS ONE. 15:e0238724 Available at: http://dx.doi.org/10.1371/journal.pone.0238724.\n\n\nThresh, J. M. 1998. In memory of James Edward Vanderplank 19091997. Plant Pathology. 47:114–115 Available at: http://dx.doi.org/10.1046/j.1365-3059.2998.00220.x.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control. Elsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X.\n\n\nYorinori, J. T., Paiva, W. M., Frederick, R. D., Costamilan, L. M., Bertagnolli, P. F., Hartman, G. E., et al. 2005. Epidemics of Soybean Rust (Phakopsora pachyrhizi) in Brazil and Paraguay from 2001 to 2003. Plant Disease. 89:675–677 Available at: http://dx.doi.org/10.1094/PD-89-0675.\n\n\nZadoks, J. C., and Schein, R. D. 1988. James Edward Vanderplank: Maverick* and Innovator. Annual Review of Phytopathology. 26:31–37 Available at: http://dx.doi.org/10.1146/annurev.py.26.090188.000335."
  },
  {
    "objectID": "data-terminology.html#disease-quantification",
    "href": "data-terminology.html#disease-quantification",
    "title": "2  Disease variables",
    "section": "2.1 Disease quantification",
    "text": "2.1 Disease quantification\nStudies on the progress of epidemics in time or their spread in space cannot be conducted without data collected in the field - or in same cases simulated. The study of plant disease quantification is known as Phytopathometry, a branch of plant pathology tasked with the science of disease measurement, but which has strong roots in epidemiology (Bock et al. 2021).\nHistorically, disease quantification has been performed visually, but advances in both imaging and remote sensing (without contact with the object) technologies have directly impacted the field during the last several decades. Therefore, the quantity of disease can be obtained via estimation (visually by human eye) or measurement (remote sensing technologies: RGB, MSI, HSI) Figure 2.1.\nWhile measuring or estimating disease with digital or remote sensing tehcnology is a a more objective task, visual assessment is largely subjective and, as such, known to vary among human raters. This occurs because raters vary in their inherent abilities, training, or are more or less affected by the chosen method (e.g. scales). Disease is estimated or measured on a specimen in a population, or on a sample of specimens drawn from a population. The specimen can be a plant organ, an individual plant, a group of plants, a field or a farm, and these also dictate how terms are defined to refer to disease quantity.\n\n\n\nFigure 2.1: Different approaches used to obtain estimates or measures of plant disease. RGB = red, green, blue; MSI = multispectral imaging; HSI = hyperspectral imaging.\n\n\nFinally, when developing new or improving existing disease assessment methods, it is important to assess the reliability of the assessments by different raters or instruments as well as accuracy - how close the estimations or measurements are from reference (gold standard) values. There are several methods that can be used to assess reliability, precision and accuracy of estimates or measures (see definitions). The choice of the methods to use depends on the objective of the work, but largely on the type or nature of the data, as it will be discussed further."
  },
  {
    "objectID": "data-terminology.html#disease-variables",
    "href": "data-terminology.html#disease-variables",
    "title": "2  Disease variables",
    "section": "2.2 Disease variables",
    "text": "2.2 Disease variables\nA general term used to refer to the quantity of disease expressed by any means is disease intensity. This term has little or no practical value as it only suggest that the disease is more or less “intense”. We need specific terms to refer to disease quantity and standardize methodology. A primary task in disease assessment is to classify each specimen, usually in a sample or in the population, as diseased or not diseased. This binary (yes/no or 1/0) assessment may be sufficient to express disease intensity if the goal is to obtain, for example, the number or proportion of diseased specimens in a sample or a population of specimens.\nThe above leads to two terms: disease incidence and prevalence. While incidence is commonly used to refer to the proportion or number (count) of plants (or their organs) as the observational units at the field scale or below, prevalence is used when referring to the proportion or number of fields or farms with diseased plants in a large production area or region (Nutter et al. 2006) Figure 2.2. Hence, prevalence is equivalent to incidence, only differing in the spatial scale of the sampling unit.\n\n\n\nFigure 2.2: Schematic representation of how prevalence and incidence of plant diseases are calculated depending on the spatial scale of the assessment\n\n\nIn many cases we need to ascertain the degree to which a specimen is diseased, which is a definition of disease severity. Elsewhere, severity is defined restrictively as the proportion of the unit that is symptomatic (Nutter et al. 2006). However, a broader view of severity encompasses other metrics including nominal or ordinal scores, lesion count together with percent area affected (ratio scale). Ordinal scales are divided into rank-ordered classes (see specific section) defined based on either the percentage scale or descriptions of symptoms (Bock et al. 2021). In some cases disease is expressed in terms of (average) lesion size or area, which can be considered a measure of severity. These variables represent different levels of measurements which carry low (nominal scale) to high (ratio scale) information about the disease quantity Figure 2.3.\n\n\n\nFigure 2.3: Scales and associated levels of measurement used to describe severity of plant diseases"
  },
  {
    "objectID": "data-terminology.html#data-types",
    "href": "data-terminology.html#data-types",
    "title": "2  Disease variables",
    "section": "2.3 Data types",
    "text": "2.3 Data types\nThe data used to express disease as incidence or any kind of severity measures vary in their nature as they can be discrete or continuous.\n\nDiscrete variables are countable (involve integers) at a finite amount of time. That is, only a limited number of values (nominal or ordinal) is possible and these cannot be subdivided into parts. For example, a plant or plant part can be either disease or not diseased (nominal data). One can’t count 1.5 diseased plants. Also, a plant classified as diseased may exhibit a certain number of lesions (count data) or be classified into a specific class of severity (ordinal data, common in ordinal scales, e.g., 1-9). Disease data in the form of counts usually relate to the number of infections per sampling units. Most commonly, counts refer to the pathogen population that is assessed, such as number of airborne or soilborne propagules.\nContinuous variables, different from discrete, can be measured on a scale and can have any numeric value between two numbers. For example, the size of a lesion on a plant can be measured at a very precise scale (cm or mm). An estimate of severity in percent scale (% diseased area) can take any value between non zero and 100%. Although discrete at the individual level, incidence at the sample level can be treated as continuous, as it can take any value in proportion or percentage.\n\nThe disease variables can also be described by a statistical distribution, which are models that give the probability that a particular value (or a range of values) will be drawn from a specific distribution. Knowledge about statistical or mathematical distributions constitute an important step to improve our understanding of data-collection methods, designs of experiments and data analysis such as data summarization or hypothesis testing."
  },
  {
    "objectID": "data-terminology.html#statistical-distributions-and-simulation",
    "href": "data-terminology.html#statistical-distributions-and-simulation",
    "title": "2  Disease variables",
    "section": "2.4 Statistical distributions and simulation",
    "text": "2.4 Statistical distributions and simulation\n\n2.4.1 Binomial distribution\nFor incidence (and prevalence), the data is binary at the individual level, as there are only two possible outcomes in a trial: the plant or plant part is disease or not diseased. The statistical distribution that best describe the incidence data at the individual level is the binomial distribution.\nLet’s simulate the binomial outcomes for a range of probabilities in a sample of 100 units, using the rbinom() function in R. For a single trial (e.g., status of plants in a single plant row), the size argument is set to 1.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 14)) # set global theme\n\nset.seed(123) # for reproducibility\nP.1 &lt;- rbinom(100, size = 1, prob = 0.1)\nP.3 &lt;- rbinom(100, size = 1, prob = 0.3)\nP.7 &lt;- rbinom(100, size = 1, prob = 0.7)\nP.9 &lt;- rbinom(100, size = 1, prob = 0.9)\nbinomial_data &lt;- data.frame(P.1, P.3, P.7, P.9)\n\nWe can then visualize the plots.\n\nbinomial_data |&gt;\n  pivot_longer(1:4, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"darkorange\",\n                 bins = 10) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.4: Binomial distribution to describe binary data\n\n\n\n\n\n\n2.4.2 Beta distribution\nDisease incidence (or prevalence) at the sample or population level can be expressed as proportion of diseased individuals. The same applies to disease severity when expressed as proportion of the organ area affected (a ratio variable). For such cases, the beta distribution, which is bounded between 0 and 1, provides a good description. Let’s simulate some data using the rbeta() function.\n\nbeta1.5 &lt;- rbeta(n = 1000, shape1 = 1, shape2 = 5)\nbeta5.5 &lt;- rbeta(n = 1000, shape1 = 5, shape2 = 5)\nbeta_data &lt;- data.frame(beta1.5, beta5.5)\n\nNotice that there are two shape parameters in the beta distribution: shape1 and shape2 to be defined. This makes the distribution very flexible and with different potential shapes as we can see below.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 14)) # set global theme\n\nbeta_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"darkorange\",\n                 color = \"white\",\n                 bins = 15) +\n  scale_x_continuous(limits = c(0, 1)) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.5: Binomial distribution to describe proportion data\n\n\n\n\n\n\n2.4.3 Poisson distribution\nThe number of diseased plants, plant parts or individual symptoms (lesions) are discrete variables (integers) which cannot take negative values. These can be described by a Poisson distribution, a discrete distribution that counts the number of events in a Poisson process. In R, we can used the rpois() function to obtain 100 random observations following a Poisson distribution. For such, we need to inform the number of observation (n = 100) and lambda, the vector of means.\n\npoisson5 &lt;- rpois(100, lambda = 10)\npoisson35 &lt;- rpois(100, lambda = 35)\npoisson_data &lt;- data.frame(poisson5, poisson35)\n\n\npoisson_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"darkorange\",\n                 color = \"white\",\n                 bins = 15) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.6: Binomial distribution to describe count data\n\n\n\n\n\n\n2.4.4 Gamma distribution\nWhen working with a continuous variables, such as lesion size, these random variables are usually described by the normal distribution. However, the problem is that the normal (Gaussian) distribution includes negative values, an unrealistic situation. Therefore, we can use the gamma distribution, which cannot take negative values, to simulate continuous plant disease data. We can use the rgamma() function that requires the number of samples (n = 100 in our case) and the shape, or the mean value.\n\ngamma10 &lt;- rgamma(n = 100, shape = 10, scale = 1)\ngamma35 &lt;- rgamma(n = 100, shape = 35, scale = 1)\ngamma_data &lt;- data.frame(gamma10, gamma35)\n\n\ngamma_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"darkorange\",\n                 color = \"white\",\n                 bins = 15) +\n  ylim(0, max(gamma_data$gamma35)) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.7: Gamma distribution to describe continuous data\n\n\n\n\n\n\n2.4.5 Simulating ordinal data\nFor ordinal data, such as a limited number of ranked-values in an ordinal scale (e.g. 0 to 5) we can use the sample() function and define the probability associated with each rank. Let’s generate 30 units with a distinct ordinal score. In the first situation, the higher probabilities (0.5) are for scores 4 and 5 and lower (0.1) for scores 0 and 1, and in the second situation is the converse.\n\nordinal1 &lt;- sample(0:5, 30, replace = TRUE, prob = c(0.1, 0.1, 0.2, 0.2, 0.5, 0.5))\nordinal2 &lt;- sample(0:5, 30, replace = TRUE, prob = c(0.5, 0.5, 0.2, 0.2, 0.1, 0.1))\nordinal_data &lt;- data.frame(ordinal1, ordinal2)\n\n\nordinal_data |&gt;\n  pivot_longer(1:2, names_to = \"P\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(value)) +\n  geom_histogram(fill = \"darkorange\",\n                 color = \"white\",\n                 bins = 6) +\n  facet_wrap( ~ P) \n\n\n\n\nFigure 2.8: Sampling of ordinal data\n\n\n\n\n\n\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D., Mahlein, A.-K., and Del Ponte, E. M. 2021. A phytopathometry glossary for the twenty-first century: towards consistency and precision in intra- and inter-disciplinary dialogues. Tropical Plant Pathology. 47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nNutter, F. W., Esker, P. D., and Netto, R. A. C. 2006. Disease Assessment Concepts and the Advancements Made in Improving the Accuracy and Precision of Plant Disease Data. European Journal of Plant Pathology. 115:95–103 Available at: http://dx.doi.org/10.1007/s10658-005-1230-z."
  },
  {
    "objectID": "data-ordinal.html#ordinal-scales",
    "href": "data-ordinal.html#ordinal-scales",
    "title": "3  Ordinal scales",
    "section": "3.1 Ordinal scales",
    "text": "3.1 Ordinal scales\nThe ordinal scales are structured as rank-ordered numeric classes in a finite number of classes. The reasons for using ordinal scales include convenience and speed of rating (Madden et al. 2017). There are two common types of ordinal scales in plant pathological research: quantitative and qualitative (Chiang and Bock 2021).\n\n3.1.1 Quantitative ordinal\nIn the quantitative ordinal scale, each score represents a defined interval of the percentage scale. The most well-known quantitative ordinal scale is the Horsfall-Barratt (HB) scale, developed in the early 1940s when the science of plant pathology was in need of more quantitative approaches (Hebert 1982). The HB scale splits the percent scale into twelve consecutive logarithmic-based intervals of severity from 0 to 100%. The intervals increase in size from 0 to 50% and decline from 50 to 100%.\n\n\n\n\n\n\nControversy of the H-B scale\n\n\n\nThe divisions of the H-B scale were based on two assumptions. First, on the logarithmic relationship between the intensity of a stimulus and sensation. Second, that the rater tends to focus on objects that are of smaller size when observing objects of two colors (Madden et al. 2017). The basis is the so-called Weber-Fechner law. There is little experimental evidence of the assumptions. To date, evidence shows a linear relationship, not a logarithmic, between visually estimated and actual severity (Nutter and Esker 2006). Also, those authors showed that raters more accurately discriminated disease severity between 25% and 50% compared to what the H-B scale allowed. New scale structure have been proposed to overcome the issues associated with the H-B scale (Liu et al. 2019; Chiang et al. 2014). The Chiang scale follows a linear relationship with percentage area diseased at severities &gt;10% (class 6 on the scale)\n\n\nLet’s input the HB scale data and store as a data frame in R so we can prepare a table and a plot.\n\nHB &lt;- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',    0,   \n  1,    '0+ to 3',  1.5,   \n  2,    '3+ to 6',  4.5,   \n  3,   '6+ to 12',  9.0,  \n  4,  '12+ to 25', 18.5, \n  5,  '25+ to 50', 37.5, \n  6,  '50+ to 75', 62.5, \n  7,  '75+ to 88', 81.5, \n  8,  '88+ to 94', 91.0, \n  9,  '94+ to 97', 95.5, \n  10,'97+ to 100', 98.5,  \n  11,      '100',   100 \n  )\nknitr::kable(HB, align = \"c\")\n\n\n\nTable 3.1: The Horsfal-Barrat quantitative ordinal scale used as a tool for assessing plant disease severity\n\n\nordinal\nrange\nmidpoint\n\n\n\n\n0\n0\n0.0\n\n\n1\n0+ to 3\n1.5\n\n\n2\n3+ to 6\n4.5\n\n\n3\n6+ to 12\n9.0\n\n\n4\n12+ to 25\n18.5\n\n\n5\n25+ to 50\n37.5\n\n\n6\n50+ to 75\n62.5\n\n\n7\n75+ to 88\n81.5\n\n\n8\n88+ to 94\n91.0\n\n\n9\n94+ to 97\n95.5\n\n\n10\n97+ to 100\n98.5\n\n\n11\n100\n100.0\n\n\n\n\n\n\nLet’s visualize the different sizes of the percent interval encompassing each score.\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw())\nHB |&gt; \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_x_continuous(breaks = c(0, 3, 6, 12, 25, 50, 75, 88, 94, 97))+\n  scale_y_continuous(breaks = c(1:12))+\n  geom_vline(aes(xintercept = 3), linetype = 2)+\n  geom_vline(aes(xintercept = 6), linetype = 2)+\n  geom_vline(aes(xintercept = 12), linetype = 2)+\n  geom_vline(aes(xintercept = 25), linetype = 2)+\n  geom_vline(aes(xintercept = 50), linetype = 2)+\n  geom_vline(aes(xintercept = 75), linetype = 2)+\n  geom_vline(aes(xintercept = 88), linetype = 2)+\n  geom_vline(aes(xintercept = 94), linetype = 2)+\n  geom_vline(aes(xintercept = 97), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"HB score\")\n\n\n\n\n\nFigure 3.1: Ordinal scores of the Horsfal-Barrat scale\n\n\n\n\nWe can repeat those procedures to visualize the Chiang scale.\n\nchiang &lt;- tibble::tribble(\n  ~ordinal, ~'range', ~midpoint,\n  0,          '0',     0,   \n  1,  '0+ to 0.1',  0.05,   \n  2,'0.1+ to 0.5',   0.3,   \n  3,  '0.5+ to 1',  0.75,  \n  4,    '1+ to 2',   1.5, \n  5,    '2+ to 5',     3, \n  6,   '5+ to 10',   7.5, \n  7,  '10+ to 20',    15, \n  8,  '20+ to 30',    25, \n  9,  '30+ to 40',    35, \n  10, '40+ to 50',    45,  \n  11, '50+ to 60',    55,\n  12, '60+ to 70',    65,\n  13, '70+ to 80',    75,\n  14, '80+ to 90',    85,\n  15,'90+ to 100',   95\n  )\nknitr::kable(chiang, align = \"c\")\n\n\n\nTable 3.2: The Chiang quantitative ordinal scale used as a tool for assessing plant disease severity\n\n\nordinal\nrange\nmidpoint\n\n\n\n\n0\n0\n0.00\n\n\n1\n0+ to 0.1\n0.05\n\n\n2\n0.1+ to 0.5\n0.30\n\n\n3\n0.5+ to 1\n0.75\n\n\n4\n1+ to 2\n1.50\n\n\n5\n2+ to 5\n3.00\n\n\n6\n5+ to 10\n7.50\n\n\n7\n10+ to 20\n15.00\n\n\n8\n20+ to 30\n25.00\n\n\n9\n30+ to 40\n35.00\n\n\n10\n40+ to 50\n45.00\n\n\n11\n50+ to 60\n55.00\n\n\n12\n60+ to 70\n65.00\n\n\n13\n70+ to 80\n75.00\n\n\n14\n80+ to 90\n85.00\n\n\n15\n90+ to 100\n95.00\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw())\nchiang |&gt; \n  ggplot(aes(midpoint, ordinal))+\n  geom_point(size =2)+\n  geom_line()+\n  scale_y_continuous(breaks = c(0:15))+\n  scale_x_continuous(breaks = c(0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100))+\n  geom_vline(aes(xintercept = 0), linetype = 2)+\n  geom_vline(aes(xintercept = 0.1), linetype = 2)+\n  geom_vline(aes(xintercept = 0.5), linetype = 2)+\n  geom_vline(aes(xintercept = 1), linetype = 2)+\n  geom_vline(aes(xintercept = 2), linetype = 2)+\n  geom_vline(aes(xintercept = 5), linetype = 2)+\n  geom_vline(aes(xintercept = 10), linetype = 2)+\n  geom_vline(aes(xintercept = 20), linetype = 2)+\n  geom_vline(aes(xintercept = 30), linetype = 2)+\n   geom_vline(aes(xintercept = 40), linetype = 2)+\n   geom_vline(aes(xintercept = 50), linetype = 2)+\n   geom_vline(aes(xintercept = 60), linetype = 2)+\n   geom_vline(aes(xintercept = 70), linetype = 2)+\n   geom_vline(aes(xintercept = 80), linetype = 2)+\n   geom_vline(aes(xintercept = 90), linetype = 2)+\n   geom_vline(aes(xintercept = 100), linetype = 2)+\n  labs(x = \"Percent severity\", y = \"Chiang score\")\n\n\n\n\n\nFigure 3.2: Ordinal scores of the Chiang scale\n\n\n\n\n\n\n3.1.2 Qualitative ordinal\nIn the qualitative ordinal scale, each class provides a description of the symptoms. An example is the ordinal 0-3 scale for rating eyespot of wheat developed by (Scott and Hollins 1974).\n\nOrdinal scale for rating eyespot of wheat (Scott and Hollins 1974)\n\n\n\n\n\n\nClass\nDescription\n\n\n\n\n0\nuninfected\n\n\n1\nslight eyespot (or or more small lesion occupying in total less than half of the circumference of the stem)\n\n\n2\nmoderate eyespot (one or more lesions occupying at least half the circumference of the stem)\n\n\n3\nsevere eyespot (stem completely girdled by lesions; tissue softened so that lodging would really occur)"
  },
  {
    "objectID": "data-ordinal.html#disease-severity-index-dsi",
    "href": "data-ordinal.html#disease-severity-index-dsi",
    "title": "3  Ordinal scales",
    "section": "3.2 Disease severity index (DSI)",
    "text": "3.2 Disease severity index (DSI)\nUsually, when quantitative or qualitative ordinal scales are used, the scores are transformed into an index on a percentage basis, such as the disease severity index (DSI) which are used in data analysis. The DSI is a single number that summarizes a large amount of information on disease severity (Chester 1950). The formula for a DSI (%) can be written as follows:\n\\(DSI = \\frac{∑(class \\ freq. \\ ✕ \\ score \\  of \\ class)} {total \\ n \\ ✕ \\ maximal \\ class} ✕ 100\\)\nThe DSI() is part of the r4pde package. It allows to automate the calculation of the disease severity index (DSI) in a series of units (e.g. leaves) that are further classified according to ordinal scores. The function requires three arguments:\n\nunit = the vector of the number of each unit\nclass = the vector of the scores for the units\nmax = the maximum value of the scale\n\nLet’s use a toy data set composed of 12 units where each received an ordinal score. The vectors were arranged as a data frame named scores.\n\nunit &lt;- c(1:12)\nclass &lt;- c(2,3,1,1,3,4,5,0,2,5,2,1)\nratings &lt;- data.frame(unit, class)\nknitr::kable(ratings)\n\n\n\n\nunit\nclass\n\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n1\n\n\n4\n1\n\n\n5\n3\n\n\n6\n4\n\n\n7\n5\n\n\n8\n0\n\n\n9\n2\n\n\n10\n5\n\n\n11\n2\n\n\n12\n1\n\n\n\n\n\nThe ordinal score used in this example has 6 as the maximum score. The function returns the DSI value.\n\nlibrary(r4pde)\nDSI(ratings$unit, ratings$class, 6)\n\n[1] 40.27778\n\n\nLet’s work now with a situation of multiple plots (5 replicates) where a fixed number of 12 samples were taken and assessed using an ordinal score. Let’s input the data using the tribble() function. Note that the data is in the wide format.\n\nexp &lt;- tibble::tribble(\n  ~rep, ~`1`, ~`2`, ~`3`, ~`4`, ~`5`, ~`6`, ~`7`, ~`8`, ~`9`, ~`10`, ~`11`,~`12`,\n  1, 2, 3, 1, 1, 3, 4, 5, 0, 2, 5, 2, 1,\n  2, 3, 4, 4, 6, 5, 4, 4, 0, 2, 1, 1, 5,\n  3, 5, 6, 6, 5, 4, 2, 0, 0, 0, 0, 2, 0,\n  4, 5, 6, 0, 0, 0, 3, 3, 2, 1, 0, 2, 3, \n  5, 0, 0, 0, 0, 2, 3, 2, 5, 6, 2, 1, 0,\n)\nknitr::kable(exp)\n\n\n\n\nrep\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n\n1\n2\n3\n1\n1\n3\n4\n5\n0\n2\n5\n2\n1\n\n\n2\n3\n4\n4\n6\n5\n4\n4\n0\n2\n1\n1\n5\n\n\n3\n5\n6\n6\n5\n4\n2\n0\n0\n0\n0\n2\n0\n\n\n4\n5\n6\n0\n0\n0\n3\n3\n2\n1\n0\n2\n3\n\n\n5\n0\n0\n0\n0\n2\n3\n2\n5\n6\n2\n1\n0\n\n\n\n\n\nAfter reshaping the data to the long format, we can calculate the DSI for each plot/replicate as follows:\n\nres &lt;- exp |&gt; \n  pivot_longer(2:13, names_to = \"unit\", values_to = \"class\") |&gt;\n  group_by(rep) |&gt; \n  summarise(DSI = DSI(unit, class, 6))\n\nAnd here we have the results of the DSI for each replicate.\n\nknitr::kable(res, align = \"c\")\n\n\n\n\nrep\nDSI\n\n\n\n\n1\n40.27778\n\n\n2\n54.16667\n\n\n3\n41.66667\n\n\n4\n34.72222\n\n\n5\n29.16667\n\n\n\n\n\n\n\n\n\nChester, K. S. 1950. Plant disease losses : Their appraisal and interpretation /. Available at: http://dx.doi.org/10.5962/bhl.title.86198.\n\n\nChiang, K.-S., and Bock, C. H. 2021. Understanding the ramifications of quantitative ordinal scales on accuracy of estimates of disease severity and data analysis in plant pathology. Tropical Plant Pathology. 47:58–73 Available at: http://dx.doi.org/10.1007/s40858-021-00446-0.\n\n\nChiang, K.-S., Liu, S.-C., Bock, C. H., and Gottwald, T. R. 2014. What Interval Characteristics Make a Good Categorical Disease Assessment Scale? Phytopathology®. 104:575–585 Available at: http://dx.doi.org/10.1094/phyto-10-13-0279-r.\n\n\nHebert, T. T. 1982. The rationale for the horsfall-barratt plant disease assessment scale. Phytopathology. 72:1269 Available at: http://dx.doi.org/10.1094/phyto-72-1269.\n\n\nLiu, H. I., Tsai, J. R., Chung, W. H., Bock, C. H., and Chiang, K. S. 2019. Effects of Quantitative Ordinal Scale Design on the Accuracy of Estimates of Mean Disease Severity. Agronomy. 9:565 Available at: http://dx.doi.org/10.3390/agronomy9090565.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nNutter, F. W., and Esker, P. D. 2006. The Role of Psychophysics in Phytopathology: The WeberFechner Law Revisited. European Journal of Plant Pathology. 114:199–213 Available at: http://dx.doi.org/10.1007/s10658-005-4732-9.\n\n\nScott, P. R., and Hollins, T. W. 1974. Effects of eyespot on the yield of winter wheat. Annals of Applied Biology. 78:269–279 Available at: http://dx.doi.org/10.1111/j.1744-7348.1974.tb01506.x."
  },
  {
    "objectID": "data-actual-severity.html#the-actual-severity-measure",
    "href": "data-actual-severity.html#the-actual-severity-measure",
    "title": "4  Image analysis",
    "section": "4.1 The actual severity measure",
    "text": "4.1 The actual severity measure\nAmong the different ways to express plant disease severity, the percent area affected (symptomatic) by the disease is one of the most common especially when dealing with diseases that affect leaves. To evaluate whether the visual estimates of plant disease severity are sufficiently accurate (as seen in the previous chapter), one needs the actual severity values. These are also needed when preparing standard area diagrams (SADs) which are diagrammatic representations of severity values used as an aid prior or during the visual assessment to standardize and produce more accurate results across different raters (Del Ponte et al. 2017).\nThe actual severity values are usually approximated using image analysis where the image is segmented and each pixel of the image is labeled according to three different classes:\n\nDiseased (or symptomatic)\nNon-diseased (or healthy)\nBackground (the non-plant portion of the image)\n\nThe ratio between the diseased area and total area of the unit (e.g. the whole plant organ or section image) gives the proportion of diseased area or the percent area affected (when multiplied by 100). Several different proprietary or open-source software has been used by researchers to determine the actual severity according to a review on standard area diagrams (Del Ponte et al. 2017).\nHere, we will use the measure_disease() function of the pliman (Plant IMage ANalysis) (Olivoto 2022) R package to measures percent area affected. The package was compared with other software for determining plant disease severity on five different plant diseases and showed to produce accurate results for most of the cases (Olivoto et al. 2022).\nThere are basically two methods to measure severity. The first is based on image palettes that define each class of the image. The second is based on RGB-based indices (Alves et al. 2021). Let’s see the first method and also one interactive way of setting the color palettes."
  },
  {
    "objectID": "data-actual-severity.html#image-palettes",
    "href": "data-actual-severity.html#image-palettes",
    "title": "4  Image analysis",
    "section": "4.2 Image palettes",
    "text": "4.2 Image palettes\nThe most critical is the initial step, when the user needs to correctly define the color palettes for each class. In pliman the palettes are actually separate images representing each of three classes named background (b), symptomatic (s) and healthy (h).\nThe reference image palettes can be constructed by manually sampling small areas of the image and producing a composite image. Of course, the results may vary depending on how these areas are chosen. A work on the validation of the pliman to determine disease severity showed the effect of different palettes prepared independently by three researchers (Olivoto et al. 2022). The observation of the processed masks during the calibration of the palettes is important to create reference palettes that are most representative of the respective class.\nHere, I cut and pasted several sections of images representative of each class from a few leaves into a Google slide. Once the image palette was ready, I exported each one as a separate image PNG file (JPG also works). These were named: sbr_b.png, sbr_h.png and sbr_s.png. They can be found here in this folder for downloading.\n\n\n\nFigure 4.1: Preparation of image palettes by manually sampling fraction of the images that represent background, heatlhy leaf and lesions\n\n\nNow that we have the image palettes, we need to import them into the environment, using image_import() function for further analysis. Let’s create an image object for each palette named h (healthy), s (symptoms) and b (background).\n\nlibrary(pliman)\nh &lt;- image_import(\"imgs/sbr_h.png\")\ns &lt;- image_import(\"imgs/sbr_s.png\")\nb &lt;- image_import(\"imgs/sbr_b.png\")\n\nWe can visualize the imported image palettes using the image_combine() function.\n\nimage_combine(h, s, b, ncol =3)\n\n\n\n\nFigure 4.2: Image palettes created to segment images into background, sypomtoms and healthy area of the image"
  },
  {
    "objectID": "data-actual-severity.html#measuring-severity",
    "href": "data-actual-severity.html#measuring-severity",
    "title": "4  Image analysis",
    "section": "4.3 Measuring severity",
    "text": "4.3 Measuring severity\n\n4.3.1 Single image\nTo determine severity in a single image (e.g. img46.png), the image file needs to be loaded and assigned to an object using the same image_import() function used to load the palettes. We can then visualize the image, again using image_combine().\n\n\n\n\n\n\nTip\n\n\n\nThe collection of images used in this chapter can be found here.\n\n\n\nimg &lt;- image_import(\"imgs/originals/img46.png\")\nimage_combine(img)\n\n\n\n\nFigure 4.3: Imported image for further analysis\n\n\n\n\nNow the fun begins with the measure_disease() function. Four arguments are needed when using the reference image palettes, the one representing the target image and each of the three images of the color palettes. As the author of the package says “pliman will take care of all details!”. The severity is the value shown under symptomatic in the output.\n\nset.seed(123)\nmeasure_disease(\n  img = img,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = TRUE\n)\n\n\n\n\n$severity\n   healthy symptomatic\n1 92.68302    7.316983\n\n$shape\nNULL\n\n$statistics\nNULL\n\nattr(,\"class\")\n[1] \"plm_disease\"\n\n\n\n\n4.3.2 Multiple images\nMeasuring severity in single images is fun, but usually we don’t have a single image to process but several. It would take a longer time to process each one using the above procedure, thus becoming tedious.\nTo automate the process, pliman offers a batch processing approach. For such, instead of using img argument, one can use pattern and define the prefix of names of the images. In addition, we also need to define the folder where the original files are located.\nIf the users wants to save the processed masks, the save_image argument needs to be set to TRUE and the directory where the images will be saved also should be informed. Check below how to process 10 images of soybean rust symptoms. The outcome is a list object with the measures of the percent healthy and percent symptomatic area for each leaf in the severity object.\n\npliman &lt;- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE\n)\n\nProcessing image img11 |====                                     | 10% 00:00:00 \n\n\nProcessing image img35 |========                                 | 20% 00:00:02 \n\n\nProcessing image img37 |============                             | 30% 00:00:03 \n\n\nProcessing image img38 |================                         | 40% 00:00:03 \n\n\nProcessing image img46 |====================                     | 50% 00:00:04 \n\n\nProcessing image img5 |=========================                 | 60% 00:00:06 \n\n\nProcessing image img63 |=============================            | 70% 00:00:08 \n\n\nProcessing image img67 |=================================        | 80% 00:00:09 \n\n\nProcessing image img70 |=====================================    | 90% 00:00:11 \n\n\nProcessing image img75 |=========================================| 100% 00:00:12 \n\nseverity &lt;- pliman$severity\nseverity\n\n     img  healthy symptomatic\n1  img11 70.80072  29.1992835\n2  img35 46.96430  53.0357002\n3  img37 60.49390  39.5060986\n4  img38 79.14737  20.8526306\n5  img46 93.15143   6.8485680\n6   img5 20.53977  79.4602312\n7  img63 97.15698   2.8430190\n8  img67 99.83723   0.1627709\n9  img70 35.58683  64.4131683\n10 img75 93.04517   6.9548329\n\n\nWith the argument save_image set to TRUE, the images are all saved in the folder with the standard prefix “proc.”\n\n\n\nFigure 4.4: Images created by pliman and exported to a specific folder\n\n\nLet’s have a look at one of the processed images.\n\n\n\nFigure 4.5: Figure created by pliman after batch processing to segment the images and calculate percent area covered by symptoms. The symptomatic area is delinated in the image."
  },
  {
    "objectID": "data-actual-severity.html#how-good-are-these-measurements",
    "href": "data-actual-severity.html#how-good-are-these-measurements",
    "title": "4  Image analysis",
    "section": "4.4 How good are these measurements?",
    "text": "4.4 How good are these measurements?\nThese 10 images were previously processed in QUANT software for measuring severity which is also based on image threshold. Let’s create a tibble for the image code and respective “actual” severity - assuming QUANT measures as reference.\n\nlibrary(tidyverse)\nquant &lt;- tribble(\n  ~img, ~actual,\n   \"img5\",     75,\n  \"img11\",     24,\n  \"img35\",     52,\n  \"img37\",     38,\n  \"img38\",     17,\n  \"img46\",      7,\n  \"img63\",    2.5,\n  \"img67\",   0.25,\n  \"img70\",     67,\n  \"img75\",     10\n  )\n\nWe can now combine the two dataframes and produce a scatter plot relating the two measures.\n\ndat &lt;- left_join(severity, quant)\n\nJoining, by = \"img\"\n\ndat %&gt;%\n  ggplot(aes(actual, symptomatic)) +\n  geom_point(size = 5, shape = 16, color = \"gray50\") +\n  ylim(0, 100) +\n  xlim(0, 100) +\n  geom_abline(slope = 1, intercept = 0) +\n  theme_light() +\n  labs(x = \"Quant\",\n       y = \"pliman\")\n\n\n\n\nFigure 4.6: Scatter plot for the relationship between severity values measured by pliman and Quant software\n\n\n\n\nThe concordance correlation coefficient is a test for agreement between two observers or two methods (see previous chapter). It is an indication of how accurate the pliman measures are compared with a standard. The coefficient is greater than 0.99 (1.0 is perfect concordance), suggesting an excellent agreement!\n\nlibrary(epiR)\nccc &lt;- epi.ccc(dat$actual, dat$symptomatic)\nccc$rho.c\n\n        est     lower     upper\n1 0.9940941 0.9774812 0.9984606\n\n\nIn conclusion, the most critical step, as mentioned, is the definition of the reference image palettes. A few preliminary runs may be needed for a few images to check whether the segmentation is being performed correctly, based on visual judgement. This is no different than any other color-threshold based methods when the choices made by the user affect the final result and contribute to variation among assessors. The cons are the same encountered in the direct competitors, which is the necessity to have images obtained at uniform and controlled conditions, especially a contrasting background."
  },
  {
    "objectID": "data-actual-severity.html#creating-palettes-interactively",
    "href": "data-actual-severity.html#creating-palettes-interactively",
    "title": "4  Image analysis",
    "section": "4.5 Creating palettes interactively",
    "text": "4.5 Creating palettes interactively\nPliman offers another function measure_disease_iter() which allows the user to pick up samples in the image to create the color palettes for each required clss (background, healthy and symptoms). Check the video below!\n\n\n\n\n\nAlves, K. S., Guimarães, M., Ascari, J. P., Queiroz, M. F., Alfenas, R. F., Mizubuti, E. S. G., et al. 2021. RGB-based phenotyping of foliar disease severity under controlled conditions. Tropical Plant Pathology. 47:105–117 Available at: http://dx.doi.org/10.1007/S40858-021-00448-Y.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J., Machado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding Severity Estimation: Scientometrics, Pathosystems, and Methodological Trends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available at: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nOlivoto, T. 2022. Lights, camera, pliman! An R package for plant image analysis. Methods in Ecology and Evolution. 13:789–798 Available at: http://dx.doi.org/10.1111/2041-210X.13803.\n\n\nOlivoto, T., Andrade, S. M. P., and M. Del Ponte, E. 2022. Measuring plant disease severity in R: introducing and evaluating the pliman package. Tropical Plant Pathology. 47:95–104 Available at: http://dx.doi.org/10.1007/s40858-021-00487-5."
  },
  {
    "objectID": "data-accuracy.html",
    "href": "data-accuracy.html",
    "title": "5  Reliability and accuracy",
    "section": "",
    "text": "6 Severity data"
  },
  {
    "objectID": "data-accuracy.html#terminology",
    "href": "data-accuracy.html#terminology",
    "title": "5  Reliability and accuracy",
    "section": "6.1 Terminology",
    "text": "6.1 Terminology\nDisease severity, mainly when expressed in percent area diseased assessed visually, is acknowledged as a more difficult and less time- and cost-effective plant disease variable to obtain. However, errors may occur even when assessing a more objective measure such as incidence. This is the case when an incorrect assignment or confusion of symptoms occur. In either case, the quality of the assessment of any disease variable is very important and should be gauged in the studies. Several terms can be used when evaluating the quality of disease assessments, including reliability, precision, accuracy or agreement.\nReliability: The extent to which the same estimates or measurements of diseased specimens obtained under different conditions yield similar results. There are two types. The inter-rater reliability (or reproducibility) is a measure of consistency of disease assessment across the same specimens between raters or devices. The intra-rater reliability (or repeatability) measures consistency by the same rater or instrument on the same specimens (e.g. two assessments in time by the same rater).\n\n\n\nFigure 6.1: Two types of reliability of estimates or measures of plant disease intensity\n\n\nPrecision: A statistical term to express the measure of variability of the estimates or measurements of disease on the same specimens obtained by different raters (or instruments). However, reliable or precise estimates (or measurements) are not necessarily close to an actual value, but precision is a component of accuracy or agreement.\nAccuracy or agreement: These two terms can be treated as synonymous in plant pathological research. They refer to the closeness (or concordance) of an estimate or measurement to the actual severity value for a specimen on the same scale. Actual values may be obtained using various methods, against which estimates or measurements using an experimental assessment method are compared.\nAn analogy commonly used to explain accuracy and precision is the archer shooting arrows at a target and trying to hit the bull’s eye (center of the target) with each of five arrows. The figure below is used to demonstrate four situations from the combination of two levels (high and low) for precision and accuracy. The figure was produced using the ggplot function of ggplot2 package.\n\n\nCode\nlibrary(ggplot2)\ntarget &lt;- \n  ggplot(data.frame(c(1:10),c(1:10)))+\n  geom_point(aes(x = 5, y = 5), size = 71.5, color = \"black\")+\n  geom_point(aes(x = 5, y = 5), size = 70, color = \"orange\")+\n  geom_point(aes(x = 5, y = 5), size = 60, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 50, color = \"orange\")+\n  geom_point(aes(x = 5, y = 5), size = 40, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 30, color = \"orange\")+\n  geom_point(aes(x = 5, y = 5), size = 20, color = \"white\")+\n  geom_point(aes(x = 5, y = 5), size = 10, color = \"orange\")+\n  geom_point(aes(x = 5, y = 5), size = 4, color = \"white\")+\n  ylim(0,10)+\n  xlim(0,10)+\n  theme_void()\n\nhahp &lt;- target +\n  labs(subtitle = \"High Accuracy High Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 5.2), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 4.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.8, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 5), shape = 4, size =2, color = \"blue\")\n\n\nlahp &lt;- target +\n  labs(subtitle = \"Low Accuracy High Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 6, y = 6), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6, y = 6.2), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6, y = 5.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.8, y = 6), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 6.2, y = 6), shape = 4, size =2, color = \"blue\")\n\n\nhalp &lt;- target +\n  labs(subtitle = \"High Accuracy Low Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5, y = 5.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.8, y = 4.4), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.4, y = 5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.6, y = 5.6), shape = 4, size =2, color = \"blue\")\n\nlalp &lt;- target +\n  labs(subtitle = \"Low Accuracy Low Precision\")+\n  theme(plot.subtitle = element_text(hjust = 0.5))+\n  geom_point(aes(x = 5.5, y = 5.5), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.5, y = 5.4), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 6.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 4.8, y = 3.8), shape = 4, size =2, color = \"blue\")+\n  geom_point(aes(x = 5.2, y = 3), shape = 4, size =2, color = \"blue\")\n\n\nlibrary(patchwork)\n(hahp | lahp) /\n(halp | lalp)\n\n\n\n\n\nFigure 6.2: The accuracy and precision of the archer is determined by the location of the group of arrows\n\n\n\n\nAnother way to visualize accuracy and precision is via scatter plots for the relationship between the actual values and the estimates.\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw())\ndat &lt;- \ntibble::tribble(\n  ~actual,   ~ap,   ~ip,   ~ai,   ~ii,\n        0,     0,    10,     0,    25,\n       10,    10,    20,     5,    10,\n       20,    20,    30,    30,    10,\n       30,    30,    40,    30,    45,\n       40,    40,    50,    30,    35,\n       50,    50,    60,    60,    65,\n       60,    60,    70,    50,    30\n  )\n\nap &lt;- dat |&gt; \n  ggplot(aes(actual, ap))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n    geom_smooth(method = \"lm\")+\n   geom_point(color = \"orange\", size = 3)+\n   ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"High Acccuracy High Precision\")\n\nip &lt;- dat |&gt; \n  ggplot(aes(actual, ip))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"Low Acccuracy High Precision\")\n\nai &lt;- dat |&gt; \n  ggplot(aes(actual, ai))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"High Acccuracy Low precision\")\n\nii &lt;- dat |&gt; \n  ggplot(aes(actual, ii))+\n  geom_abline(intercept = 0, slope = 1, \n              linetype = 2, size = 1)+\n  geom_smooth(method = \"lm\", se = F)+\n  geom_point(color = \"orange\", size = 3)+\n  ylim(0,70)+\n  xlim(0,70)+\n  labs(x = \"Actual\", y = \"Estimate\",\n       title = \"Low Acccuracy Low Precision\")\n\nlibrary(patchwork)\n(ap | ip) / (ai | ii)\n\n\n\n\n\nFigure 6.3: Scatter plots for the relationship between actual and estimated values representing situations of low or high precision and accuracy. The dashed line indicates the perfect concordance and the solid blue line represents the fit of the linear regression model"
  },
  {
    "objectID": "data-accuracy.html#statistical-summaries",
    "href": "data-accuracy.html#statistical-summaries",
    "title": "5  Reliability and accuracy",
    "section": "6.2 Statistical summaries",
    "text": "6.2 Statistical summaries\nA formal assessment of the quality of estimates or measures is made using statistical summaries of the data expressed as indices that represent reliability, precision and accuracy. These indices can further be used to test hypothesis such as if one or another method is superior than the other. The indices or the tests vary according to the nature of the variable, whether continuous, binary or categorical.\n\n6.2.1 Inter-rater reliability\nTo calculate measures of inter-rater reliability (or reproducibility) we will work with a fraction of a larger dataset used in a published study. There, the authors tested the effect of standard area diagrams (SADs) on the reliability and accuracy of visual estimates of severity of soybean rust.\nThe selected dataset consists of five columns with 20 rows. The first is the leaf number and the others correspond to assessments of percent soybean rust severity by four raters (R1 to R4). Each row correspond to one symptomatic leaf. Let’s assign the tibble to a dataframe called sbr (an acronym for soybean rust). Note that the variable is continuous.\n\nlibrary(tidyverse)\nsbr &lt;- tribble(\n~leaf, ~R1, ~R2,  ~R3, ~R4,\n1, 0.6, 0.6,  0.7, 0.6,\n2,   2, 0.7,    5,   1,\n3,   5,   5,    8,   5,\n4,   2,   4,    6,   2,\n5,   6,  14,   10,   7,\n6,   5,   6,   10,   5,\n7,  10,  18, 12.5,  12,\n8,  15,  30,   22,  10,\n9,   7,   2,   12,   8,\n10,  6,   9, 11.5,   8,\n11,  7,   7,   20,   9,\n12,  6,  23,   22,  14,\n13, 10,  35, 18.5,  20,\n14, 19,  10,    9,  10,\n15, 15,  20,   19,  20,\n16, 17,  30,   18,  13,\n17, 19,  53,   33,  38,\n18, 17, 6.8,   15,   9,\n19, 15,  20,   18,  16,\n20, 18,  22,   24,  15\n         )\n\nLet’s explore the data using various approaches. First, we can visualize how the individual estimates by the raters differ for a same leaf.\n\n# set the global theme\ntheme_set(theme_bw())\nlibrary(ggthemes)\n\n# transform from wide to long format\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(2:5, names_to = \"rater\",\n               values_to = \"estimate\") \n\n# create the plot\nsbr2 |&gt; \n  ggplot(aes(leaf, estimate, color = rater,\n             group = leaf))+\n  geom_line(color = \"black\")+\n  geom_point(size = 2)+\n  scale_color_colorblind()+\n  labs(y = \"Severity estimate (%)\",\n       x = \"Leaf number\",\n       color = \"Rater\")\n\n\n\n\nFigure 6.4: Visual estimates of soybean rust severity for each leaf by each of four raters\n\n\n\n\nAnother interesting visualization is the correlation matrix of the estimates between all possible pair of raters. The ggpairs function of the GGally package is handy for this task.\n\nlibrary(GGally)\ntheme_set(theme_light())\n\n# create a new dataframe with only raters\nraters &lt;- sbr |&gt; \n  select(2:5)\n\nggpairs(raters)\n\n\n\n\nFigure 6.5: Correlation plots relating severity estimates for all pairs of raters\n\n\n\n\n\n6.2.1.1 Coefficient of determination\nWe noticed earlier that the correlation coefficients varied across all pairs of rater. Sometimes, the means of squared Pearson’s R values (R2), or the coefficient of determination is used as a measure of inter-rater reliability. We can further examine the pair-wise correlations in more details using the correlation function of the performance package.\n\nlibrary(correlation)\nraters_cor &lt;- correlation(raters)\nlibrary(knitr)\nkable(raters_cor[1:3]) # only first 3 variables\n\n\n\nTable 6.1: Pearson correlation coefficients for all pairs of raters\n\n\nParameter1\nParameter2\nr\n\n\n\n\nR1\nR2\n0.6325037\n\n\nR1\nR3\n0.6825936\n\n\nR1\nR4\n0.6756986\n\n\nR2\nR3\n0.8413333\n\n\nR2\nR4\n0.8922181\n\n\nR3\nR4\n0.8615470\n\n\n\n\n\n\nThe means of coefficient of determination can be easily obtained as follows.\n\n# All pairwise R2\nround(raters_cor$r^2,2)\n\n[1] 0.40 0.47 0.46 0.71 0.80 0.74\n\n# means of R2\nround(mean(raters_cor$r^2), 2)\n\n[1] 0.59\n\n\n\n\n6.2.1.2 Intraclass Correlation Coefficient\nA common statistic to report in reliability studies is the Intraclass Correlation Coefficient (ICC). There are several formulations for the ICC whose choice depend on the particular experimental design. Following the convention of the seminal work by Shrout and Fleiss (1979), there are three main ICCs:\n\nOne-way random effects model, ICC(1,1): in our context, each leaf is rated by different raters who are considered as sampled from a larger pool of raters (random effects)\nTwo-way random effects model, ICC(2,1): both raters and leaves are viewed as random effects\nTwo-way mixed model, ICC(3,1): raters are considered as fixed effects and leaves are considered as random.\n\nAdditionally, the ICC may depend on whether the ratings are an average or not of several ratings. When an average is considered, these are called ICC(1,k), ICC(2,k) and ICC(3,k).\nThe ICC can be computed using the ICC() or the icc() functions of the psych or irr packages, respectively. They both provide the coefficient, F value, and the upper and lower bounds of the 95% confidence interval.\n\nlibrary(psych)\nic &lt;- ICC(raters)\nkable(ic$results[1:2]) # only selected columns\n\n\n\n\n\ntype\nICC\n\n\n\n\nSingle_raters_absolute\nICC1\n0.6405024\n\n\nSingle_random_raters\nICC2\n0.6464122\n\n\nSingle_fixed_raters\nICC3\n0.6919099\n\n\nAverage_raters_absolute\nICC1k\n0.8769479\n\n\nAverage_random_raters\nICC2k\n0.8797008\n\n\nAverage_fixed_raters\nICC3k\n0.8998319\n\n\n\n\n# call ic list for full results\n\nThe output of interest is a dataframe with the results of all distinct ICCs. We note that the ICC1 and ICC2 gave very close results. Now, let’s obtain the various ICCs using the irr package. Differently from the the ICC() function, this one requires further specification of the model to use.\n\nlibrary(irr)\nicc(raters, \"oneway\")\n\n Single Score Intraclass Correlation\n\n   Model: oneway \n   Type : consistency \n\n   Subjects = 20 \n     Raters = 4 \n     ICC(1) = 0.641\n\n F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 \n   F(19,60) = 8.13 , p = 1.8e-10 \n\n 95%-Confidence Interval for ICC Population Values:\n  0.44 &lt; ICC &lt; 0.813\n\n# The one used in the SBR paper\nicc(raters, \"twoway\")\n\n Single Score Intraclass Correlation\n\n   Model: twoway \n   Type : consistency \n\n   Subjects = 20 \n     Raters = 4 \n   ICC(C,1) = 0.692\n\n F-Test, H0: r0 = 0 ; H1: r0 &gt; 0 \n   F(19,57) = 9.98 , p = 6.08e-12 \n\n 95%-Confidence Interval for ICC Population Values:\n  0.503 &lt; ICC &lt; 0.845\n\n\n\n\n6.2.1.3 Overall Concordance Correlation Coefficient\nAnother useful index is the Overall Concordance Correlation Coefficient (OCCC) for evaluating agreement among multiple observers. It was proposed by Barnhart et al. (2002) based on the original index proposed by Lin (1989), earlier defined in the context of two fixed observers. In the paper, the authors introduced the OCCC in terms of the interobserver variability for assessing agreement among multiple fixed observers. As outcome, and similar to the original CCC, the approach addresses the precision and accuracy indices as components of the OCCC. The epi.occc function of the epiR packge does the job but it does compute a confidence interval.\n\nlibrary(epiR)\nepi.occc(raters, na.rm = FALSE, pairs = TRUE)\n\n\nOverall CCC           0.6372\nOverall precision     0.7843\nOverall accuracy      0.8125\n\n\n\n\n\n6.2.2 Intrarater reliability\nAs defined, the intrarater reliability is also known as repeatability, because it measures consistency by the same rater at repeated assessments (e.g. different times) on the same sample. In some studies, we may be interested in testing whether a new method increases repeatability of assessments by a single rater compared with another one. The same indices used for assessing reproducibility (interrater) can be used to assess repeatability, and these are reported at the rater level.\n\n\n6.2.3 Precision\nWhen assessing precision, one measures the variability of the estimates (or measurements) of disease on the same sampling units obtained by different raters (or instruments). A very high precision does not mean that the estimates are closer to the actual value (which is given by measures of bias). However, precision is a component of overall accuracy, or agreement. It is given by the Pearson’s correlation coefficient.\nDifferent from reliability, that requires only the estimates or measures by the raters, now we need a reference (gold standard) value to compare the estimates to. These can be an accurate rater or measures by an instrument. Let’s get back to the soybean rust severity estimation dataset and add a column for the (assumed) actual values of severity on each leaf. In that work, the actual severity values were obtained using image analysis.\n\nsbr &lt;- tibble::tribble(\n~leaf, ~actual, ~R1, ~R2,  ~R3, ~R4,\n1,    0.25, 0.6, 0.6,  0.7, 0.6,\n2,     2.5,   2, 0.7,    5,   1,\n3,    7.24,   5,   5,    8,   5,\n4,    7.31,   2,   4,    6,   2,\n5,    9.07,   6,  14,   10,   7,\n6,    11.6,   5,   6,   10,   5,\n7,   12.46,  10,  18, 12.5,  12,\n8,    13.1,  15,  30,   22,  10,\n9,   14.61,   7,   2,   12,   8,\n10,  16.06,   6,   9, 11.5,   8,\n11,   16.7,   7,   7,   20,   9,\n12,   19.5,   6,  23,   22,  14,\n13,  20.75,  10,  35, 18.5,  20,\n14,  23.56,  19,  10,    9,  10,\n15,  23.77,  15,  20,   19,  20,\n16,  24.45,  17,  30,   18,  13,\n17,  25.78,  19,  53,   33,  38,\n18,  26.03,  17, 6.8,   15,   9,\n19,  26.42,  15,  20,   18,  16,\n20,  28.89,  18,  22,   24,  15\n         )\n\nWe can explore visually via scatter plots the relationships between the actual value and the estimates by each rater (Figure 6.6). To facilitate, we need the data in the long format.\n\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(3:6, names_to = \"rater\",\n               values_to = \"estimate\") \n\nsbr2 |&gt; \n  ggplot(aes(actual, estimate))+\n  geom_point(size = 2, alpha = 0.7)+\n  facet_wrap(~rater)+\n  ylim(0,45)+\n  xlim(0,45)+\n  geom_abline(intercept = 0, slope =1)+\n  labs(x = \"Actual severity (%)\",\n       y = \"Estimate severity (%)\")\n\n\n\n\nFigure 6.6: Scatterplots for the relationship between estimated and actual severity for each rater\n\n\n\n\nThe Pearson’s r for the relationship, or the precision of the estimates by each rater, can be obtained using the correlation function of the correlation package.\n\nprecision &lt;- sbr2 |&gt; \n  select(-leaf) |&gt; \n  group_by(rater) |&gt; \n  correlation() \n\nkable(precision[1:4])\n\n\n\n\nGroup\nParameter1\nParameter2\nr\n\n\n\n\nR1\nactual\nestimate\n0.8725643\n\n\nR2\nactual\nestimate\n0.5845291\n\n\nR3\nactual\nestimate\n0.7531983\n\n\nR4\nactual\nestimate\n0.7108260\n\n\n\n\n\nThe mean precision can then be obtained.\n\nmean(precision$r)\n\n[1] 0.7302795\n\n\n\n\n6.2.4 Accuracy\n\n6.2.4.1 Absolute errors\nIt is useful to visualize the errors of the estimates which are obtained by subtracting the estimates from the actual severity values. This plot allows to visualize patterns in over or underestimations across a range of actual severity values.\n\nsbr2 |&gt; \n  ggplot(aes(actual, estimate-actual))+\n  geom_point(size = 3, alpha = 0.7)+\n  facet_wrap(~rater)+\n  geom_hline(yintercept = 0)+\n  labs(x = \"Actual severity (%)\",\n       y = \"Error (Estimate - Actual)\")\n\n\n\n\nFigure 6.7: Error (estimated - actual) of visual severity estimates\n\n\n\n\n\n\n6.2.4.2 Concordance correlation coefficient\nLin’s (1989, 2000) proposed the concordance correlation coefficient (CCC) for agreement on a continuous measure obtained by two methods. The CCC combines measures of both precision and accuracy to determine how far the observed data deviate from the line of perfect concordance. Lin’s CCC increases in value as a function of the nearness of the data reduced major axis to the line of perfect concordance (the accuracy of the data) and of the tightness of the data about its reduced major axis (the precision of the data).\nThe epi.ccc function of the epiR package allows to obtain the Lin’s CCC statistics. Let’s filter only rater 2 and calculate the CCC statistics for this rater.\n\nlibrary(epiR)\n# Only rater 2\nsbr3 &lt;- sbr2 |&gt; filter(rater == \"R2\")\nccc &lt;- epi.ccc(sbr3$actual, sbr3$estimate)\n# Concordance coefficient\nrho &lt;- ccc$rho.c[,1]\n# Bias coefficient\nCb &lt;- ccc$C.b\n# Precision\nr &lt;- ccc$C.b*ccc$rho.c[,1]\n# Scale-shift\nss &lt;- ccc$s.shift\n# Location-shift\nls &lt;- ccc$l.shift\nMetrics &lt;- c(\"Agreement\", \"Bias coefficient\", \"Precision\", \"scale-shift\", \"location-shift\")\nValue &lt;- c(rho, Cb, r, ss, ls)\nres &lt;- data.frame(Metrics, Value)\nkable(res)\n\n\n\nTable 6.2: Statitics of the concordance correlation coefficient summarizing accuracy and precision of visual severity estimates of soybean rust for a single rater\n\n\nMetrics\nValue\n\n\n\n\nAgreement\n0.5230656\n\n\nBias coefficient\n0.8948494\n\n\nPrecision\n0.4680649\n\n\nscale-shift\n1.6091178\n\n\nlocation-shift\n-0.0666069\n\n\n\n\n\n\nNow let’s create a function that will allow us to estimate the CCC for all raters in the data frame in the wide format. The function assumes that the first two columns are the actual and estimates and the rest of the columns are the raters, which is the case for our sbr dataframe . Let’s name this function ccc_byrater.\n\nccc_byrater &lt;- function(data) {\n  long_data &lt;- pivot_longer(data, cols = -c(leaf, actual),\n                            names_to = \"rater\", values_to = \"measurement\")\n  ccc_results &lt;- long_data %&gt;%\n    group_by(rater) %&gt;%\n    summarise(Agreement = as.numeric(epi.ccc(measurement, actual)$rho.c[1]),\n              `Bias coefficient` = epi.ccc(measurement, actual)$C.b,\n              Precision = Agreement * `Bias coefficient`,\n              scale_shift = epi.ccc(measurement, actual)$s.shift,\n              location_shift = epi.ccc(measurement, actual)$l.shift)\n  \n  return(ccc_results)\n}\n\nThen, we use the ccc_byrater function with the original sbr dataset - or any other dataset in the wide format of similar structure. The output is a dataframe with all CCC statistics.\n\nresults &lt;- ccc_byrater(sbr)\nknitr::kable(results)\n\n\n\n\n\n\n\n\n\n\n\n\nrater\nAgreement\nBias coefficient\nPrecision\nscale_shift\nlocation_shift\n\n\n\n\nR1\n0.5968136\n0.6839766\n0.4082065\n1.3652694\n0.9090386\n\n\nR2\n0.5230656\n0.8948494\n0.4680649\n0.6214585\n0.0666069\n\n\nR3\n0.7306948\n0.9701226\n0.7088635\n1.1028813\n0.2280303\n\n\nR4\n0.5861371\n0.8245860\n0.4833205\n1.0044929\n0.6522573"
  },
  {
    "objectID": "data-accuracy.html#accuracy-1",
    "href": "data-accuracy.html#accuracy-1",
    "title": "5  Reliability and accuracy",
    "section": "7.1 Accuracy",
    "text": "7.1 Accuracy\nIncidence data are binary at the individual level; an individual is diseased or not. Here, different from severity that is estimated, the specimen is classified. Let’s create two series of binary data, each being a hypothetical scenario of assignment of 12 plant specimens into two classes: healthy (0) or diseased (1).\n\norder &lt;- c(1:12)\nactual &lt;- c(1,1,1,1,1,1,1,1,0,0,0,0)\nclass &lt;- c(0,0,1,1,1,1,1,1,1,0,0,0)\n\ndat_inc &lt;- data.frame(order, actual, class)\ndat_inc \n\n   order actual class\n1      1      1     0\n2      2      1     0\n3      3      1     1\n4      4      1     1\n5      5      1     1\n6      6      1     1\n7      7      1     1\n8      8      1     1\n9      9      0     1\n10    10      0     0\n11    11      0     0\n12    12      0     0\n\n\nIn the example above, the rater makes 9 accurate classification and misses 3: 2 diseased plants classified as being disease-free (sample 1 and 2), and 1 healthy plant that is wrongly classified as diseased (sample 9).\nNotice that there are four outcomes:\nTP = true positive, a positive sample correctly classified\nTN = true negative, a negative sample correctly classified\nFP = false positive, a negative sample classified as positive\nFN = false negative, a positive sample classified as positive.\nThere are several metrics that can be calculated with the help of a confusion matrix, also known as error matrix. Considering the above outcomes, here is a how a confusion matrix looks like.\nSuppose a 2x2 table with notation\n\n\n\n\nActual value\n\n\n\n\n\nClassification value\nDiseased\nHealthy\n\n\nDiseased\nTP\nFP\n\n\nHealthy\nFN\nTN\n\n\n\nLet’s create this matrix using a function of the caret package.\n\nlibrary(caret)\nattach(dat_inc)\ncm &lt;- confusionMatrix(factor(class), reference = factor(actual))\ncm\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction 0 1\n         0 3 2\n         1 1 6\n                                          \n               Accuracy : 0.75            \n                 95% CI : (0.4281, 0.9451)\n    No Information Rate : 0.6667          \n    P-Value [Acc &gt; NIR] : 0.3931          \n                                          \n                  Kappa : 0.4706          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.7500          \n            Specificity : 0.7500          \n         Pos Pred Value : 0.6000          \n         Neg Pred Value : 0.8571          \n             Prevalence : 0.3333          \n         Detection Rate : 0.2500          \n   Detection Prevalence : 0.4167          \n      Balanced Accuracy : 0.7500          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nThe function returns the confusion matrix and several statistics such as accuracy = (TP + TN) / (TP + TN + FP + FN). Let’s manually calculate the accuracy and compare the results:\n\nTP = 3\nFP = 2\nFN = 1\nTN = 6\naccuracy = (TP+TN)/(TP+TN+FP+FN)\naccuracy\n\n[1] 0.75\n\n\nTwo other important metrics are sensitivity and specificity.\n\nsensitivity = TP/(TP+FN)\nsensitivity\n\n[1] 0.75\n\nspecificity = TN/(FP+TN)\nspecificity\n\n[1] 0.75\n\n\nWe can calculate some metrics using the MixtureMissing package.\n\nlibrary(MixtureMissing)\nevaluation_metrics(actual, class)\n\n$matr\n       pred_0 pred_1\ntrue_0      3      1\ntrue_1      2      6\n\n$TN\n[1] 3\n\n$FP\n[1] 1\n\n$FN\n[1] 2\n\n$TP\n[1] 6\n\n$TPR\n[1] 0.75\n\n$FPR\n[1] 0.25\n\n$TNR\n[1] 0.75\n\n$FNR\n[1] 0.25\n\n$precision\n[1] 0.8571429\n\n$accuracy\n[1] 0.75\n\n$error_rate\n[1] 0.25\n\n$FDR\n[1] 0.1428571"
  },
  {
    "objectID": "data-accuracy.html#reliability",
    "href": "data-accuracy.html#reliability",
    "title": "5  Reliability and accuracy",
    "section": "7.2 Reliability",
    "text": "7.2 Reliability\n\nlibrary(psych)\ntab &lt;- table(class, actual)\nphi(tab)\n\n[1] 0.48\n\n\n\n\n\n\nBarnhart, H. X., Haber, M., and Song, J. 2002. Overall Concordance Correlation Coefficient for Evaluating Agreement Among Multiple Observers. Biometrics. 58:1020–1027 Available at: http://dx.doi.org/10.1111/j.0006-341x.2002.01020.x.\n\n\nLin, L. I.-K. 1989. A concordance correlation coefficient to evaluate reproducibility. Biometrics. 45:255 Available at: http://dx.doi.org/10.2307/2532051.\n\n\nShrout, P. E., and Fleiss, J. L. 1979. Intraclass correlations: Uses in assessing rater reliability. Psychological Bulletin. 86:420–428 Available at: http://dx.doi.org/10.1037/0033-2909.86.2.420."
  },
  {
    "objectID": "data-sads.html#definitions",
    "href": "data-sads.html#definitions",
    "title": "6  Standard area diagrams",
    "section": "6.1 Definitions",
    "text": "6.1 Definitions\nAccording to a glossary on phytopathometry (Bock et al. 2021), standard area diagram (SAD) can be defined as “a generic term for a pictorial or graphic representation (drawing or true-color photo) of selected disease severities on plants or plant parts (leaves, fruit, flowers, etc.) generally used as an aid for more accurate visual estimation (on the percentage scale) or classification (using an ordinal scale) of severity on a specimen”.\nThe SADs, also known as diagrammatic scales, are a set of diagrams which have long use in plant pathology. The tool dates back to the late 1800s, when the Cobb scale was developed with five diagrams illustrating a range of severity values of rust pustules on wheat leaves.\nIn the last 20 years, plant pathologists have taken advantage of advances in image processing and analysis tools and from knowledge gained from the psychophysical and measurement sciences to develop SADs that are realistic (e.g. true color photographs), with appropriate validation and illustrated severities to maximize estimation accuracy. SADs have been designed in various color types (black or white, two-color or true-color) and and incremental scales (approximated linear or logarithmic) (Del Ponte et al. 2017).\nThe SADs have proven useful to increase accuracy of the visual estimates as the estimation of percentage areas is deemed more challenging than classification of severity into ordinal classes - there is a large number of options to choose from on the percentage scale, compared to the finite and small number of classes in ordinal scales. A recent quantitative review confirmed that the use of SADs most often results in improved accuracy and precision of visual estimates, but identified factors related to SAD design and structure, disease symptoms, and actual severity that affected the results. In particular, the SADs have proven greater utility for raters that inherently less accurate and diseases characterized by small and numerous lesions (Del Ponte et al. 2022). Follows examples of SADs in black and white, two-color and true-color:\n\n\n\n\nFigure 6.1: Actual photos of symptoms of loquat scab on fruit (left) and a SADs with eight diagrams (right). Each number represents severity as the percent area affected (González-Domínguez et al. 2014)\n\n\n\n\n\n\nFigure 6.2: SADs for Glomerella leaf spot on apple leaf. Each number represents severity as the percent area affected (Moreira et al. 2018)\n\n\n\n\n\n\nFigure 6.3: SADs for soybean rust. Each number represents severity as the percent area affected (Franceschi et al. 2020)\n\n\nMore SADs can be found in the SADBank, a curated collection of articles on SAD development and validation. Click on the image below to get access to the database.\n\n\n\nFigure 6.4: SADBank, a curated collection of articles"
  },
  {
    "objectID": "data-sads.html#sad-development-and-validation",
    "href": "data-sads.html#sad-development-and-validation",
    "title": "6  Standard area diagrams",
    "section": "6.2 SAD development and validation",
    "text": "6.2 SAD development and validation\nA systematic review of the literature on SADs highlighted the most important aspects related with the development and validation of the tool (Del Ponte et al. 2017). A list of best practices was proposed in the review to guide future research in the area. Follows the most important aspects to be noted:\n\n\n\n\n\n\nBest practices on SADs development\n\n\n\n\nSample a minimum number (e.g., n = 100) of specimens from natural epidemics representing the range of disease severity and typical symptoms observed.\nUse reliable image analysis software to discriminate disease symptoms from healthy areas to calculate percent area affected.\nWhen designing the illustrations for the SAD set, ensure that the individual diagrams are prepared realistically, whether line drawn, actual photos, or computer generated.\nThe number of diagrams should be no less than 6 and no more than 10, distributed approximately linearly, and spaced no more than 15% apart. Additional diagrams (±2) should be included between 0 and 10% severity.\nFor the validation trial, select at least 50 specimens representing the full range of actual severity and symptom patterns.\nWhen selecting raters (a minimum of 15) for validation, make sure they do not have previous experience in using the SAD under evaluation.\nProvide standard instructions on how to recognize the symptoms of the disease and how to assess severity, first without and then with the SAD.\nIdeally repeat the assessment in time, with a 1- or 2-week interval, both without and with the aid, using the same set of raters in order to evaluate the effect of training and experience on gains in accuracy.\nBoth pre- and posttest experiment conditions should be the same to avoid any impact of distraction on accuracy of estimates during the tests."
  },
  {
    "objectID": "data-sads.html#designing-sads-in-r",
    "href": "data-sads.html#designing-sads-in-r",
    "title": "6  Standard area diagrams",
    "section": "6.3 Designing SADs in R",
    "text": "6.3 Designing SADs in R\nThe diagrams used in the set have been designed using several methods and technology, ranging from hand drawing to actual photos (Del Ponte et al. 2017). There is an increasing tendency to use actual photos that are analysed digitally, using standard image analysis software, to determine the percent area affected. In this approach, a large set of images is analyzed and some images are chosen to represent the severities of the SAD according to the scale structure.\nIn R, the pliman package has a function called sad() which allows the automatic generation of a SADs with a pre-defined number of diagrams. Firstly, as shown in the previous chapter, the set of images to be selected needs to be analysed using the measure_disease() function. Then, a SADs is automatically generated. In the function, the specimens with the smallest and highest severity will be selected for the SAD. The intermediate diagrams are sampled sequentially to achieve the pre-defined number of images after the severity has been ordered from low to high. More details of the function here.\nLet’s use the same set of 10 soybean leaves, as seen in the previous chapter, depicting the rust symptoms and create the sbr object.\n\nlibrary(pliman)\nh &lt;- image_import(\"imgs/sbr_h.png\")\ns &lt;- image_import(\"imgs/sbr_s.png\")\nb &lt;- image_import(\"imgs/sbr_b.png\")\n\nsbr &lt;- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE,\n  show_original = FALSE, # set to TRUE for showing the original.\n  col_background = \"white\", \n  verbose = FALSE\n)\n\nWe are ready to run the sad() function to create a SADs with five diagrams side by side. The resulting SADs is in two-color as standard. Set the argument show_original to TRUE for showing the orignal image in the SADs.\n\nsad(sbr, 5, ncol = 5)\n\n\n\n\n    img  healthy symptomatic rank\n8 img67 99.84530   0.1547021    1\n5 img46 92.65801   7.3419891    3\n4 img38 80.48860  19.5114030    5\n3 img37 59.85029  40.1497100    7\n6  img5 21.02512  78.9748781   10"
  },
  {
    "objectID": "data-sads.html#analysis-of-sads-validation-data",
    "href": "data-sads.html#analysis-of-sads-validation-data",
    "title": "6  Standard area diagrams",
    "section": "6.4 Analysis of SADs validation data",
    "text": "6.4 Analysis of SADs validation data\nTo evaluate the effect of SAD on accuracy components, analyze the data, preferably using concordance analysis methods (see chapter), to fully explore which component is affected and to gain insight into the ramification of errors. Linear regression should not be used as the sole method but it could be complementary for comparison with previous literature.\nInferential methods should be used for testing hypotheses related to gain in accuracy. If parametric tests are used (paired t-test for example), make sure to check that the assumptions are not violated. Alternatively, nonparametric tests (Wilcoxon signed rank) or nonparametric bootstrapping should be used when the conditions for parametric tests are not met. More recently, a (parametric) mixed modelling framework has been used to analyse SADs validation data where raters are taken as a random effects in the model (González-Domínguez et al. 2014; Franceschi et al. 2020; Pereira et al. 2020).\n\n6.4.1 Non parametric boostrapping of differences\nBootstrap is a resampling method where large numbers of samples of the same size are repeatedly drawn, with replacement, from a single original sample. It is commonly used when thedistribution of a statistic is unknown or complicated and the sample size is too small to draw a valid inference.\nA bootstrap-based equivalence test procedure was first proposed as complementary to parametric (paired t-test) or non-parametric (Wilcoxon) to analyze severity estimation data in a study on the development and validation of a SADs for pecan scab (Yadav et al. 2012). The equivalence test was used to calculate 95% confidence intervals (CIs) for each statistic by bootstrapping using the percentile method (with an equivalence test, the null hypothesis is the converse of H0, i.e. the null hypothesis is non-equivalence). In that study, the test was used to compare means of the CCC statistics across raters under two conditions: 1) without versus with the SAD; and 2) experienced versus inexperienced raters.\nTo apply the bootstrap-based equivalence test, let’s work with the CCC data for a sample of 20 raters who estimated severity of soybean rust SAD first without and then with the aid. The CCC was calculated as shown here.\n\nsbr &lt;- tibble::tribble(\n  ~rater, ~aided, ~unaided,\n      1L,   0.97,     0.85,\n      2L,   0.97,     0.85,\n      3L,   0.95,     0.82,\n      4L,   0.93,     0.69,\n      5L,   0.97,     0.84,\n      6L,   0.96,     0.86,\n      7L,   0.98,     0.78,\n      8L,   0.93,     0.72,\n      9L,   0.94,     0.67,\n     10L,   0.95,     0.53,\n     11L,   0.94,     0.78,\n     12L,   0.98,     0.89,\n     13L,   0.96,      0.8,\n     14L,   0.98,     0.87,\n     15L,   0.98,      0.9,\n     16L,   0.98,     0.87,\n     17L,   0.98,     0.84,\n     18L,   0.97,     0.86,\n     19L,   0.98,     0.89,\n     20L,   0.98,     0.78\n  )\n\nLet’s visualize the data using boxplots. Each point in the plot represents a rater.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nsbr |&gt; \n  pivot_longer(2:3, names_to = \"condition\", values_to =\"estimate\") |&gt; \n  ggplot(aes(condition, estimate))+\n  geom_boxplot(outlier.colour = NA)+\n  geom_jitter(width = 0.05, size = 2, alpha = 0.5)+\n  ylim(0.4,1)\n\n\n\n\nWe now need to create a variable for the difference of the means of the estimates (aided minus unaided) prior to bootstrapping this difference using two specialized packages. If the 95% CI does not include zero, this means that there was a significant improvement in the statistics.\n\n# diff of means\nsbr$diff &lt;- sbr$aided - sbr$unaided\n\nsbr$diff\n\n [1] 0.12 0.12 0.13 0.24 0.13 0.10 0.20 0.21 0.27 0.42 0.16 0.09 0.16 0.11 0.08\n[16] 0.11 0.14 0.11 0.09 0.20\n\nhist(sbr$diff)\n\n\n\n\nUsing the simpleboot and boot packages:\n\nlibrary(simpleboot)\nb.mean &lt;- one.boot(sbr$diff, mean, 999)\nboot::boot.ci(b.mean)\n\nWarning in boot::boot.ci(b.mean): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = b.mean)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.1255,  0.1946 )   ( 0.1200,  0.1895 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.1295,  0.1990 )   ( 0.1310,  0.2015 )  \nCalculations and Intervals on Original Scale\n\nmean(b.mean$data)\n\n[1] 0.1595\n\nhist(b.mean)\n\n\n\n\nUsing the bootstrap package:\n\nlibrary(bootstrap)\nb &lt;- bootstrap(sbr$diff, 999, mean)\nquantile(b$thetastar, c(.025,.975))\n\n  2.5%  97.5% \n0.1285 0.1940 \n\nmean(b$thetastar)\n\n[1] 0.1592718\n\nsd(b$thetastar)\n\n[1] 0.01694609\n\nse &lt;- function(x) sqrt(var(x)/length(x))\nse(b$thetastar)\n\n[1] 0.0005361504\n\n\nBoth procedures shown above led to similar results. The 95% CIs of the differences did not include zero, so a significant improvement in accuracy can be inferred.\n\n\n6.4.2 Parametric and non-parametric paired sample tests\nIn the case that two estimates are obtained by the same rater at different times, the data are not independent. For this situation, a paired sample t-test can be used for testing whether the mean difference between two sets of observations is zero. In this test, each subject (the leaf in our case) is measured or estimated twice, resulting in pairs of observations. If the assumptions of the test are violated (e.g. lack of normality), an equivalent non-parametric test can be used, such as the Wilcoxon, also known as Wilcoxon signed-rank test. It is used when your data are not normally distributed.\nLet’s apply these two tests for our data and compare the results. We need to check whether the data are normally distributed. Then, we can also check whether the variances are equal.\n\n# normality test\nshapiro.test(sbr$aided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sbr$aided\nW = 0.82529, p-value = 0.002111\n\nshapiro.test(sbr$unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  sbr$unaided\nW = 0.83769, p-value = 0.003338\n\n# equal variance test\nvar.test(sbr$aided, sbr$unaided)\n\n\n    F test to compare two variances\n\ndata:  sbr$aided and sbr$unaided\nF = 0.037789, num df = 19, denom df = 19, p-value = 1.53e-09\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01495720 0.09547109\nsample estimates:\nratio of variances \n        0.03778862 \n\n# paired t-test\nt.test(sbr$aided, sbr$unaided, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  sbr$aided and sbr$unaided\nt = 8.812, df = 19, p-value = 3.873e-08\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1216158 0.1973842\nsample estimates:\nmean of the differences \n                 0.1595 \n\n# Wilcoxon test\nwilcox.test(sbr$aided, sbr$unaided, paired = TRUE)\n\nWarning in wilcox.test.default(sbr$aided, sbr$unaided, paired = TRUE): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sbr$aided and sbr$unaided\nV = 210, p-value = 9.449e-05\nalternative hypothesis: true location shift is not equal to 0\n\n\nAs shown above, the two assumptions were violated, so we could rely more confidently on the non-parametric test.\n\n\n6.4.3 Mixed effects modeling\nMixed models are a form of linear modeling used for hierarchical data when the response variable has a normal distribution and the predictor variables are a mix of fixed and random effects. These models are also good when data points might not be fully independent of each other, which is the case in our example (Brown 2021).\nHere we treat raters as random effects. We expect them to be samples from a larger population about which we are trying to draw conclusions. We can sample more raters who would be different from the ones we have and we can infer something about the whole population from the sampled in our analyses. The random effects capture variation that exists but isn’t relevant to the question, like variation between subjects for which we have repeated measures.\nLet’s start reshaping our data to the long format and assign them to a new data frame.\n\nsbr2 &lt;- sbr |&gt; \n  pivot_longer(2:3, names_to = \"condition\", values_to = \"estimate\")\n\nNow we fit the mixed model using the lmer function of the lme4 package. We will fit the model to the logit of the estimate because they should be bounded between zero and one. Preliminary analysis using non-transformed or log-transformed data resulted in lack of normality of residuals and heterocedasticity (not shown).\n\nlibrary(lme4) \nlibrary(car) # for logit function\nmix &lt;- lmer(logit(estimate) ~ condition + (1 | rater), data = sbr2)\n\n# Check model performance\nlibrary(performance)\ncheck_model(mix)\n\n\n\ncheck_normality(mix)\n\nOK: residuals appear as normally distributed (p = 0.381).\n\ncheck_heteroscedasticity(mix)\n\nOK: Error variance appears to be homoscedastic (p = 0.961).\n\n# Check effect of condition\ncar::Anova(mix)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: logit(estimate)\n           Chisq Df Pr(&gt;Chisq)    \ncondition 458.44  1  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Estimate the means for each group\nlibrary(emmeans)\nem &lt;- emmeans(mix, ~ condition, transform = \"response\")\nem\n\n condition response      SE   df lower.CL upper.CL\n aided        0.968 0.00359 25.5    0.960    0.975\n unaided      0.817 0.01719 25.5    0.781    0.852\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \nConfidence level used: 0.95 \n\n# Contrast the means\npairs(em)\n\n contrast        estimate     SE   df t.ratio p.value\n aided - unaided    0.151 0.0149 25.5  10.141  &lt;.0001\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \n\n# plot the means with 95% CIs\nplot(em) +\n  coord_flip()+\n  xlim(0.7,1)\n\n\n\n\nAs shown above, we can reject the null hypothesis that the means are the same between the two groups.\n\n\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D., Mahlein, A.-K., and Del Ponte, E. M. 2021. A phytopathometry glossary for the twenty-first century: towards consistency and precision in intra- and inter-disciplinary dialogues. Tropical Plant Pathology. 47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nBrown, V. A. 2021. An Introduction to Linear Mixed-Effects Modeling in R. Advances in Methods and Practices in Psychological Science. 4:251524592096035 Available at: http://dx.doi.org/10.1177/2515245920960351.\n\n\nDel Ponte, E. M., Cazón, L. I., Alves, K. S., Pethybridge, S. J., and Bock, C. H. 2022. How much do standard area diagrams improve accuracy of visual estimates of the percentage area diseased? A systematic review and meta-analysis. Tropical Plant Pathology. 47:43–57 Available at: http://dx.doi.org/10.1007/s40858-021-00479-5.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J., Machado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding Severity Estimation: Scientometrics, Pathosystems, and Methodological Trends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available at: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nFranceschi, V. T., Alves, K. S., Mazaro, S. M., Godoy, C. V., Duarte, H. S. S., and Del Ponte, E. M. 2020. A new standard area diagram set for assessment of severity of soybean rust improves accuracy of estimates and optimizes resource use. Plant Pathology. 69:495–505 Available at: http://dx.doi.org/10.1111/ppa.13148.\n\n\nGonzález-Domínguez, E., Martins, R. B., Del Ponte, E. M., Michereff, S. J., García-Jiménez, J., and Armengol, J. 2014. Development and validation of a standard area diagram set to aid assessment of severity of loquat scab on fruit. European Journal of Plant Pathology. Available at: http://dx.doi.org/10.1007/s10658-014-0400-2.\n\n\nMoreira, R. R., Silva Silveira Duarte, H. da, and De Mio, L. L. M. 2018. Improving accuracy, precision and reliability of severity estimates of Glomerella leaf spot on apple leaves using a new standard area diagram set. European Journal of Plant Pathology. 153:975–982 Available at: http://dx.doi.org/10.1007/s10658-018-01610-0.\n\n\nPereira, W. E. L., Andrade, S. M. P. de, Del Ponte, E. M., Esteves, M. B., Canale, M. C., Takita, M. A., et al. 2020. Severity assessment in the Nicotiana tabacum-Xylella fastidiosa subsp. pauca pathosystem: design and interlaboratory validation of a standard area diagram set. Tropical Plant Pathology. 45:710–722 Available at: http://dx.doi.org/10.1007/s40858-020-00401-5.\n\n\nYadav, N. V. S., Vos, S. M. de, Bock, C. H., and Wood, B. W. 2012. Development and validation of standard area diagrams to aid assessment of pecan scab symptoms on fruit. Plant Pathology. 62:325–335 Available at: http://dx.doi.org/10.1111/j.1365-3059.2012.02641.x."
  },
  {
    "objectID": "data-training.html#training-sessions",
    "href": "data-training.html#training-sessions",
    "title": "7  Training sessions",
    "section": "7.1 Training sessions",
    "text": "7.1 Training sessions\nSimilar to SADs, when raters are exposed to a fixed number of reference diagrams to correct and improve accuracy of their visual estimates of severity, if raters are exposed several times to diagrams (or actual images) with known severity values, of varying values, they will also get similar benefits."
  },
  {
    "objectID": "data-training.html#software",
    "href": "data-training.html#software",
    "title": "7  Training sessions",
    "section": "7.2 Software",
    "text": "7.2 Software\nTraining sessions have been used in the past and proven to improve rater’s performance. Research on this topic began during the mid-1980s with the arrival of personal computers, which were used to develop computerized images of specific and measured disease severity. Those software, running on DOS or Windows system, included AREAGRAM, DISTRAIN, DISEASE.PRO, ESTIMATE, SEVERITY.PRO and COMBRO (See review by Bock et al. (2021) ). Although training has proven successful, a potential issue with computer training is that the benefits may be short-lived with raters requiring regular re-training.\n\n\n\nFigure 7.1: Selected screenshots from Severity.Pro, the disease assessment training program by Forrest W. Nutter (Madden et al. 2021).\n\n\n\n7.2.1 Online training tools\nIn Brazil, the “Sistema de treinamento de acuidade visual” was initially developed as a web-based system to train raters in assessing citrus canker. The system has evolved over time and now has a current version that is accessible on both iOS and Android platforms. You can find the current version of the system at this link. This platform provides an interactive training experience to enhance the ability of raters in accurately assessing the severity of citrus canker.\nIn Mexico, a specific application called Validar-PER has been developed to train raters in visually assessing the severity of coffee leaf rust. This application utilizes diagrammatic log-based scales as a standardized approach for severity assessment. You can access the Validar-PER application online here. The application aims to improve the proficiency of raters in evaluating the severity of coffee leaf rust using a systematic and standardized methodology.\n\n\n\nFigure 7.2: Screen of Validar-PER, an online training module for assessing coffee leaf rust severity\n\n\n\n\n7.2.2 Training software made with R\n\n7.2.2.1 TraineR\nTraineR, developed by the author of this book, is created using R and Shiny. Its purpose is to train users in assessing disease severity, specifically expressed as the percentage area of an organ (leaf or fruit) affected by lesions.\nTo use the app, users can adjust parameters for organ shape, organ color, as well as lesion shape, lesion color, lesion number, and lesion size. These adjustments will generate a standard area diagram with an ellipsoidal shape.\nTo initiate the training, users should first set the desired number of attempts for the session and click on the “generate new” button. A diagram will then be displayed, and users should input their estimate of the diseased area as a numeric value in percentage. The estimate will be recorded and shown in a table along with the actual value, enabling a comparison between the actual and estimated values.\nUsers can continue generating new diagrams and providing estimates until they reach the defined number of attempts. Once the final attempt is completed, the app will present the accuracy in the form of Lin’s concordance correlation coefficient to the user. Plots depicting the relationship between estimates and actual values, as well as the error of the estimates, will be displayed. Furthermore, comprehensive accuracy statistics are also made available.\nCurrently, the app has certain limitations, including the inability to overlap lesions and a maximum severity representation of approximately 60%. Nonetheless, it remains a valuable educational and demonstration tool.\n\n\n\nFigure 7.3: Screen of TraineR, an online app for training in the assessment of plant disease severity\n\n\n\n\n7.2.2.2 Trainer2\nTrainer2 the second generation of TraineR, takes advantage of actual photographs showcasing disease symptoms. This updated version allows for testing the ability of raters to assess disease severity, particularly by evaluating the percentage area affected based on real symptoms captured in the photographs.\nBy utilizing actual images, Trainer2 offers a more realistic and practical approach to training raters. Raters can now evaluate disease severity by visually inspecting the symptoms depicted in the photographs, enhancing their ability to accurately assess the extent of damage in terms of the affected area.\nThe incorporation of real symptoms in Trainer2 serves as a valuable tool for evaluating and refining the skills of raters in disease severity assessment. It provides a more authentic training experience and helps raters become proficient in identifying and quantifying the extent of disease based on visual cues observed in real-life scenarios.\n\n\n\nFigure 7.4: Screen of traineR2, an online for training in the assessment of plant disease severity based on real symptoms captured in photographs\n\n\n\n\n\n\nBock, C. H., Chiang, K.-S., and Del Ponte, E. M. 2021. Plant disease severity estimated visually: a century of research, best practices, and opportunities for improving methods and practices to maximize accuracy. Tropical Plant Pathology. 47:25–42 Available at: http://dx.doi.org/10.1007/s40858-021-00439-z.\n\n\nMadden, L. V., Esker, P. D., and Pethybridge, S. J. 2021. Forrest W. Nutter, Jr.: a career in phytopathometry. Tropical Plant Pathology. 47:5–13 Available at: http://dx.doi.org/10.1007/s40858-021-00469-7."
  },
  {
    "objectID": "temporal-dpc.html#how-epidemics-occur",
    "href": "temporal-dpc.html#how-epidemics-occur",
    "title": "8  Disease progress curves",
    "section": "8.1 How epidemics occur",
    "text": "8.1 How epidemics occur\nBefore knowing how epidemics develop in time, it is important to understand how an epidemic occur. An epidemic begins when the primary inoculum (a variable number of propagules able to infect the plant) that is surviving somewhere establishes an intimate contact with individuals of the host population - this process is called infection. These inocula are usually surviving externally to the plant host and need to disperse (move), passively or by means of a vector, to reach the plant. It can also be that a growing host encounter a localized (static) source of inoculum.\nOnce the infection is established, the pathogen colonizes the plant tissues and disease symptoms are noticed. When this happens, the incubation period can be measured in time units. A successful colonization will lead to reproduction of the pathogen inside and/or external to the crop, and so the latent period is completed, and can also be measure in time units. Finally, the infectious period takes place and continues until the pathogen is not capable of producing the secondary inoculum on the infected site.\n\n\n\n\n\nflowchart\n  A[Infection] --&gt; B[Colonization]\n  B --&gt; C[Reproduction]\n  C -. New inoculum .-&gt; D[Dispersal]\n  E[Survival] -- Primary inoculum --&gt; D\n  D  --&gt; A\n  D  -.-&gt; A\n  C --&gt; E \n\n\nFigure 8.1: Five main processes of the disease cycle\n\n\n\n\nEpidemiologists are generally interested in determining the length of the incubation, latent, and infectious periods as influenced by factors related to the host, pathogen, or environment. This is relevant because the longer it takes for the completion of the incubation and latent periods, the lower the potential number of repeated cycles. In summary, a single “infection cycle” represents all events that occur from infection to dispersal, and this occurs only once for many diseases, while for others there may be multiple cycles, which are defined as an “infection chain.”\n\n\nCode\nlibrary(tidyverse)\nperiods &lt;- tibble::tribble(\n  ~period, ~length, ~color, ~order,\n  \"Incubation\", 10, 0, 1,\n  \"Latent\" , 15, 0, 2,\n  \"Infectious\", 25, 15, 3\n)\n\np &lt;- periods |&gt; \n  ggplot(aes(reorder(period, order), length, fill = period))+\n  geom_col()+\n  geom_col(aes(period, color), color = \"white\", fill = \"white\")+\n  coord_flip()+\n  theme_void()+\n  theme(legend.position = \"none\")+\n  annotate(geom = \"text\", x = 0.5, y = 15, label = \"----- Time ---&gt;\")+\n  annotate(geom = \"text\", x = 1, y = 5, label = \"Incubation\", color = \"white\")+\n  annotate(geom = \"text\", x = 2, y = 8, label = \"Latent\", color = \"white\")+\n  annotate(geom = \"text\", x = 3, y = 20, label = \"Infectious\", color = \"white\")+\n  annotate(geom = \"text\", x = 1, y = 10.5, label = \"Visible symptoms\", angle = 90, size = 1.7)+\n  annotate(geom = \"text\", x = 2, y = 15.5, label = \"Reproduction starts\", angle = 90, size =1.7)+\n  annotate(geom = \"text\", x = 3, y = 25.5, label = \"Reproduction ends\", angle = 90, size =1.7)+\n  scale_fill_manual(values = c(\"darkgreen\",  \"brown\", \"darkorange\"))+\n  geom_segment(mapping=aes(x=0.6, y=0, xend=0.6, yend=10), arrow=arrow(ends='both'), size=1, color = \"black\")+ \n  geom_segment(mapping=aes(x=1.6, y=0, xend=1.6, yend=15), arrow=arrow(ends='both'), size=1, color = \"black\")  +\n   geom_segment(mapping=aes(x=2.6, y=15, xend=2.6, yend=25), arrow=arrow(ends='both'), size=1, color = \"black\") \n  library(png)\n  library(cowplot)\n  incubation &lt;- readPNG(\"imgs/incubation3.png\", native = TRUE)\n  latent &lt;- readPNG(\"imgs/latent3.png\", native = TRUE)\n  p2 &lt;- p + draw_image(incubation , x = 0.5, y = 13, scale = 5)+\n    draw_image(latent , x = 1.5, y = 20, scale = 5)\n  ggsave(\"imgs/periods.png\", width =6, height =2, bg = \"white\")  \n\n\n\n\n\nFigure 8.2: Three time-related epidemiological periods and their relations with stages of the disease cycle including colonization (symptoms) and reproduction (sporulation in the case of fungi). Drawings of apple scab symptoms and signs adapted from Agrios (2005)"
  },
  {
    "objectID": "temporal-dpc.html#disease-curves",
    "href": "temporal-dpc.html#disease-curves",
    "title": "8  Disease progress curves",
    "section": "8.2 Disease curves",
    "text": "8.2 Disease curves\nA key understanding of the epidemics relates to the knowledge of rates and patterns. Epidemics can be viewed as dynamic systems that change their state as time goes. The first and simplest way to characterize such changes in time is to produce a graphical plot called disease progress curve (DPC). This curve can be obtained as long as the intensity of the disease (y) in the host population is assessed sequentially in time (t).\nA DPC summarizes the interaction of the three main components of the disease triangle occurring during the epidemic. The curves can vary greatly in shape according to variations in each of the components, in particular due to management practices that alter the course of the epidemics and for which the goal is to stop disease increase. We can create a data frame in R for a single DPC and make a plot using ggplot. By convention we use t for time and y for disease intensity, expressed in percentage (0 to 100%).\nFirstly, let’s load the essential R packages and set up the environment.\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_bw(base_size = 16)) # set global theme\n\nThere are several ways to create a data frame in R. I like to use the tribble function as below. The entered data will be assigned to a dataframe called dpc.\n\ndpc &lt;- \n  tribble(\n   ~t,  ~y, \n   0,  8, \n   7,  13, \n  14,  78, \n  21,  92, \n  28,  99, \n  35, 99.5, \n  42, 99.9, \n  )\n\nNow the plot\n\ndpc1 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  geom_line(size = 1)+\n  geom_point(size = 4, shape = 16)+\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")\n\nggsave(\"imgs/dpc1.png\", dpc1)\n\n\n\n\nFigure 8.3: A typical disease progress curve for an epidemic that reaches the maximum value"
  },
  {
    "objectID": "temporal-dpc.html#epidemic-classification",
    "href": "temporal-dpc.html#epidemic-classification",
    "title": "8  Disease progress curves",
    "section": "8.3 Epidemic classification",
    "text": "8.3 Epidemic classification\nVanderplank analysed the shapes of great number of epidemic curves and classified the epidemics into two basic types: monocyclic or polycyclic (Vanderplank 1963). In monocyclic epidemics, inoculum capable of infecting the crop is not produced during the epidemics. These epidemics are initiated and maintained only by the primary inoculum. There is no secondary infection and hence no further spread of newly produced inoculum among the host individuals. Tipically, the progress curves for monocyclic epidemics have a saturation type shape.\nConversely, when the secondary inoculum produced during the epidemics is capable of infecting the host during the same crop cycle, a polycyclic epidemic is established. The number of repeated cycles just depends on how long it takes to complete a single infection cycle. These epidemics most commonly present a sigmoid shape Figure 8.4.\n\n\nCode\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\n\nlibrary(epifitter)\npolyc &lt;- sim_logistic(N = 50, dt = 5, \n                      y0 = 0.01, r = 0.2, \n                      K = 0.8, n = 1, \n                      alpha =0)\n\np &lt;- polyc |&gt; \n  ggplot(aes(time, y))+\n  geom_point(aes(time, y), size =19, shape =1)+\n  geom_line()+\n  ylim(0,1)+\n  labs(x = \"Time\", y = \"Disease intensity\")\n\n\nmonoc &lt;- sim_monomolecular(N = 50, dt = 5, \n                           y0 = 0.01, r = 0.1,\n                           K = 0.8, n = 1, \n                           alpha =0)\nlibrary(ggforce)\nm &lt;- monoc |&gt; \n  ggplot(aes(time, y))+\n  geom_point(aes(x = 25, y = 0.5), size =90, shape = 1)+\n   geom_line()+\n  ylim(0,1)+\n  labs(x = \"Time\", y = \"Disease intensity\")\n\nlibrary(patchwork)\ncycles &lt;- m | p\nggsave(\"imgs/cycles.png\", bg = \"white\", width = 8, height =4)\n\n\n\n\n\nFigure 8.4: Hypothetical curves for monocyclic (left) and polycyclic (right) epidemics. Each circle represents a single infection cycle."
  },
  {
    "objectID": "temporal-dpc.html#curve-descriptors-and-audpc",
    "href": "temporal-dpc.html#curve-descriptors-and-audpc",
    "title": "8  Disease progress curves",
    "section": "8.4 Curve descriptors and AUDPC",
    "text": "8.4 Curve descriptors and AUDPC\nThe depiction and analysis of disease progress curves can provide useful information for gaining understanding of the underlying epidemic process. The curves are extensively used to evaluate how disease control measures affect epidemics. When characterizing DPCs, a researcher may be interested in describing and comparing epidemics that result from different treatments, or simply in their variations as affected by changes in environment, host or pathogen.\nThe precision and complexity of the analysis of progress curve data depends on the objective of the study. In general, the goal is to synthesize similarities and differences among epidemics based on common descriptors of the disease progress curves. For example, the simple appraisal of the disease intensity at any time during the course of the epidemic should be sufficient for certain situations. Furthermore, a few quantitative and qualitative descriptors can be extracted including:\n\nEpidemic duration\nMaximum disease\nCurve shape\nArea under the area under the disease progress curve (AUDPC).\n\nLet’s visualize the AUDPC in the same plot that we produced above.\n\ndpc2 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")+\n    geom_area(fill = \"darkorange\")+\n    geom_line(size = 1)+\n  geom_point(size = 3, shape = 16)+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42))\nggsave(\"imgs/dpc2.png\")\n\n\n\n\nFigure 8.5: Representation of the area under the disease progress curve\n\n\nThe AUDPC summarizes the “total measure of disease stress” and is largely used to compare epidemics (Jeger and Viljanen-Rollinson 2001). The most common approach to calculate AUDPC is the trapezoidal method, which splits the disease progress curves into a series of rectangles, calculating the area of each of them and then summing the areas. Let’s extend the plot code to show those rectangles using the annotate function.\n\n\nCode\ndpc3 &lt;- dpc |&gt;\n  ggplot(aes(t, y)) +\n  labs(x = \"Assessment time (days)\",\n       y = \"Disease intensity (%)\")+\n  annotate(\"rect\", xmin = dpc$t[1], xmax = dpc$t[2], \n           ymin = 0, ymax = (dpc$y[1]+ dpc$y[2])/2, \n           color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[2], xmax = dpc$t[3], \n            ymin = 0, ymax = (dpc$y[2]+ dpc$y[3])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[3], xmax = dpc$t[4], \n            ymin = 0, ymax = (dpc$y[3]+ dpc$y[4])/2,\n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[4], xmax = dpc$t[5], \n            ymin = 0, ymax = (dpc$y[4]+ dpc$y[5])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[5], xmax = dpc$t[6], \n            ymin = 0, ymax = (dpc$y[5]+ dpc$y[6])/2, \n            color = \"darkgreen\",fill = \"darkorange\")+\n   annotate(\"rect\", xmin = dpc$t[6], xmax = dpc$t[7], \n            ymin = 0, ymax = (dpc$y[6]+ dpc$y[7])/2, \n            color = \"darkgreen\", fill = \"darkorange\")+\n  geom_line(size = 1)+\n  geom_point(size = 3, shape = 16)+\n  annotate(geom = \"text\", x = 26.5, y = 50,\n           label = \"AUDPC = 3048.5\", size = 6)+\n  scale_x_continuous(breaks = c(0, 7, 14, 21, 28, 35, 42))\nggsave(\"imgs/dpc3.png\")\n\n\n\n\n\nFigure 8.6: Representation of the area under the disease progress curve calculated using the trapezoidal method\n\n\nIn R, we can obtain the AUDPC for the DPC we created earlier using the AUDPC function offered by the epifitter package. Because we are using the percent data, we need to set the argument y_proportion = FALSE. The function returns the absolute AUDPC. If one is interested in relative AUDPC, the argument type should be set to \"relative\". There is also the alternative to AUDPC, the area under the disease progress stairs (AUDPS) (Simko and Piepho 2012).\n\nlibrary(epifitter)\nAUDPC(dpc$t, dpc$y, \n      y_proportion = FALSE)\n\n[1] 3048.15\n\n# The relative AUDPC \nAUDPC(dpc$t, dpc$y, \n      y_proportion = FALSE, \n      type = \"relative\")\n\n[1] 0.72575\n\n# To calculate AUDPS, the alternative to AUDPC\nAUDPS(dpc$t, dpc$y, \n      y_proportion = FALSE)\n\n[1] 3425.8\n\n\n\n\n\n\nJeger, M. J., and Viljanen-Rollinson, S. L. H. 2001. The use of the area under the disease-progress curve (AUDPC) to assess quantitative disease resistance in crop cultivars. Theoretical and Applied Genetics. 102:32–40 Available at: http://dx.doi.org/10.1007/s001220051615.\n\n\nSimko, I., and Piepho, H.-P. 2012. The Area Under the Disease Progress Stairs: Calculation, Advantage, and Application. Phytopathology®. 102:381–389 Available at: http://dx.doi.org/10.1094/phyto-07-11-0216.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control. Elsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X."
  },
  {
    "objectID": "temporal-models.html#non-flexible-models",
    "href": "temporal-models.html#non-flexible-models",
    "title": "9  Population models",
    "section": "9.1 Non-flexible models",
    "text": "9.1 Non-flexible models\nThese population dynamics models require at least two parameters, hence they are known as non-flexible, as opposed to the flexible ones for which there are at least one additional (third) parameter.\nFollowing the convention proposed by (Madden et al. 2017) in their book “The study of plant disease epidemics”:\n\ntime is represented by \\(t\\)\ndisease intensity by \\(y\\)\nthe rate of change in \\(y\\) between two time units is represented by \\(\\frac{dy}{dt}\\)\n\nNow we can proceed and learn which non-flexible models exist and for which situation they are more appropriate.\n\n9.1.1 Exponential\nThe differential equation for the exponential model is given by\n\\(\\frac{dy}{dt} = r_E.y\\),\nwhere \\(r_E\\) is the apparent infection rate (subscript E for this model) (sensu Vanderplank) and \\(y\\) is the disease intensity. Biologically, this formulation suggests that diseased plants, or \\(y\\), and \\(r_E\\) at each time contribute to disease increase. The value of \\(\\frac{dy}{dt}\\) is minimal when \\(y = 0\\) and increases exponentially with the increase in \\(y\\).\nThe integral for the exponential model is given by\n\\(y = y_0 e^{r_Et}\\),\nwhere \\(y0\\) is and \\(r\\) are obtained via estimation. Let’s simulate two curves by varying \\(r\\) while fixing \\(y0\\) and varying the latter while fixing \\(r_E\\). We produce the two plots in ggplot and add the predicted curve using the `stat_function`. But first, we need to define values for the two model parameters. Further modifications to these values will be handled directly in the simulation (e.g. doubling infection rate, reducing initial inoculum by half, etc.).\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_bw(base_size = 16)) # set global theme\n\n\ny0 &lt;- 0.001 \nr &lt;- 0.06 \ntmax &lt;- 60 # maximum duration t of the epidemics\ndat &lt;- data.frame(t = seq(1:tmax), y = seq(0:1)) # define the axes\n\nIn the plot below, note that the infection rate in one curve was doubled (\\(r\\) = 0.12)\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  labs(x = \"Time\")\n\n\n\n\nFigure 9.1: Exponential curves with two rates of infection (0.06 and 0.12) and the same initial inoculum (0.001)\n\n\n\n\nNow the inoculum was increased five times while using the same doubled rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * 5 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  labs(x = \"Time\")\n\n\n\n\nFigure 9.2: Exponential curves with the same rate of infection (0.12) and single and five times the initial inoculum (0.001)\n\n\n\n\n\n\n9.1.2 Monomolecular\nThe differential of the monomolecular model is given by\n\\(\\frac{dy}{dt} = r_M (1-y)\\)\nwhere now the \\(r_M\\) is the rate parameter of the monomolecular model and \\((1-y)\\) is the proportion of non-infected (healthy) individuals or host tissue. Note that \\(\\frac{dy}{dt}\\) is maximum when \\(y = 0\\) and decreases when \\(y\\) approaches 1. Its decline is due to decrease in the proportion of individuals or healthy sites with the increase in \\(y\\). Any inoculum capable of infecting the host will more likely land on infected individuals or sites.\nThe integral of the monomolecular model is given by\n\\(\\frac{dy}{dt} = 1 - (1-y)e^{-r_Mt}\\)\nThis model commonly describes the temporal patterns of the monocyclic epidemics. In those, the inoculum produced during the course of the epidemics do not contribute new infections. Therefore, different from the exponential model, disease intensity \\(y\\) does not affect the epidemics and so the absolute rate is proportional to \\((1-y)\\).\nLet’s simulate two monomolecular curve with different rate parameters where one is one third of the other.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r * t))) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-(r / 3) * t))) +\n  labs(x = \"Time\") +\n  theme_bw(base_size = 16)+\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"r = 0.06\") +\n  annotate(geom = \"text\", x = 50, y = 0.55, label = \"r = 0.02\")\n\n\n\n\nFigure 9.3: Monomolecular curves with two rates of infection (0.06 and 0.02) and the same initial inoculum (0.001)\n\n\n\n\nNow inoculum was increased 100 times with the reduced rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r / 2 * t))) +\n  stat_function(fun = function(t) 1 - ((1 - (y0 * 100)) * exp(-r / 2 * t))) +\n  theme_bw(base_size = 16)+\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.1\") +\n  annotate(geom = \"text\", x = 45, y = 0.65, label = \"y0 = 0.001\")\n\n\n\n\nFigure 9.4: Monomolecular curves with one rate (0.06) and the initial inoculum increased 100 times\n\n\n\n\n\n\n9.1.3 Logistic\nThe logistic model is a more elaborated version of the two previous models as it incorporates the features of them both. Its differential is given by\n\\(\\frac{dy}{dt} = r_L. y . (1 - y)\\),\nwhere \\(r_L\\) is the infection rate of the logistic model, \\(y\\) is the proportion of diseased individuals or host tissue and \\((1-y)\\) is the proportion of non-affected individuals or host area.\nBiologically, \\(y\\) in its differential equation implies that \\(\\frac{dy}{dt}\\) increases with the increase in \\(y\\) (as in the exponential) because more disease means more inoculum. However, \\((1-y)\\) leads to a decrease in \\(\\frac{dy}{dt}\\) when \\(y\\) approaches the maximum \\(y=1\\), because the proportion of healthy individuals or host area decreases (as in the monomolecular). Therefore, \\(\\frac{dy}{dt}\\) is minimal at the onset of the epidemics, reaches a maximum when \\(y/2\\) and declines until \\(y=1\\).\nThe integral is given by\n\\(y = \\frac{1}{1 + (1-y_0).e^{-r.t}}\\),\nwhere \\(r_L\\) is the apparent infection rate of the logistic model and \\(y0\\) is the disease intensity at \\(t=0\\). This model provides a good fit to polycyclic epidemics.\nLet’s check two curves where in one the infection rate is double while keeping the same initial inoculum.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 2 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 4 * t))) +\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.18\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.024\")\n\n\n\n\nFigure 9.5: Logistic curves with two rates of infection (0.18 and 0.024) and the same initial inoculum (0.001)\n\n\n\n\nNow the inoculum is reduced 10 times for a same infection rate.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - (y0 / 10)) / (y0 / 10)) * exp(-r * 3 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 3 * t))) +\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"y0 = 0.0001\")\n\n\n\n\nFigure 9.6: Logistic curves with a single rate of infection (0.24) and two initial inoculum (0.001 and 0.0001)\n\n\n\n\n\n\n9.1.4 Gompertz\nThe Gompertz model is similar to the logistic and also provides a very good fit to several polycyclic diseases. The differential equation is given by\n\\(\\frac{dy}{dt} = r_G.[ln(1) - ln(y)]\\)\nDifferently from the logistic, the variable representing the non-infected individuals or host area is \\(-ln(y)\\). The integral equation is given by\n\\(y = e^{(ln(y0)).{e^{-r_G.t)}}}\\),\nwhere \\(r_G\\) is the apparent infection rate for the Gompertz models and \\(y_0\\) is the disease intensity at \\(t = 0\\).\nLet’s check curves for two rates.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r/2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0) * exp(-r*2 * t))) +\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.12\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.03\")\n\n\n\n\nFigure 9.7: Gompertz curves with two rates of infection (0.12 and 0.03) and the same initial inoculum (0.001)\n\n\n\n\nAnd those when inoculum was reduced one thousand times.\n\ndat |&gt;\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r*2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0/1000) * exp(-r*2 * t))) +\n  labs(x = \"Time\") +\n  annotate(geom = \"text\", x = 15, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 25, y = 0.10, label = \"y0 = 0.00001\")\n\n\n\n\nFigure 9.8: Gompertz curves with a single rate of infection (0.12) and two levels of initial inoculum (0.001 and 0.00001)"
  },
  {
    "objectID": "temporal-models.html#interactive-application",
    "href": "temporal-models.html#interactive-application",
    "title": "9  Population models",
    "section": "9.2 Interactive application",
    "text": "9.2 Interactive application\nA shiny app was developed to demonstrate these four models interactively. Click on the image below to get access to the app.\n\n\n\nFigure 9.9: Screenshot of the application to visualize the population dynamics models by varying the model’s parameters\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Temporal analysis i: Quantifying and comparing epidemics. In The American Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004."
  },
  {
    "objectID": "temporal-fitting.html#non-replicated-epidemics",
    "href": "temporal-fitting.html#non-replicated-epidemics",
    "title": "10  Model fitting",
    "section": "10.1 Non-replicated epidemics",
    "text": "10.1 Non-replicated epidemics\nWe will compare three DPCs of the incidence of tobacco etch, a virus disease, in peppers. Evaluations of incidence were evaluated at a 7-day interval up to 49 days. The data are available in chapter 4 (page 93) (Madden et al. 2017). Let’s input the data manually and create a data frame. First column is the assessment time and the other columns correspond to the treatments, called groups in the book, from 1 to 3."
  },
  {
    "objectID": "temporal-fitting.html#entering-data",
    "href": "temporal-fitting.html#entering-data",
    "title": "10  Model fitting",
    "section": "10.2 Entering data",
    "text": "10.2 Entering data\n\nlibrary(tidyverse) # essential packages \ntheme_set(theme_bw(base_size = 16)) # set global theme\n\n\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  )"
  },
  {
    "objectID": "temporal-fitting.html#visualize-the-dpcs",
    "href": "temporal-fitting.html#visualize-the-dpcs",
    "title": "10  Model fitting",
    "section": "10.3 Visualize the DPCs",
    "text": "10.3 Visualize the DPCs\nBefore proceeding with model selection and fitting, let’s visualize the three epidemics. The code below reproduces quite exactly the top plot of Fig. 4.15 (Madden et al. (2017) page 94). The appraisal of the curves might give us a hint on which models are the best candidates.\nBecause the data was entered in the wide format (each DPC is in a different column) we need to reshape it to the long format. The pivot_longer() function will do the job of reshaping from wide to long format so we can finally use the ggplot() function to produce the plot.\n\npepper |&gt; \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\") |&gt; \n  ggplot (aes(t, inc, \n              linetype = treat, \n              shape = treat, \n              group = treat))+\n  geom_line(size = 1)+\n  geom_point(size =3, shape = 16)+\n  annotate(geom = \"text\", x = 15, y = 0.84, label = \"1\")+\n  annotate(geom = \"text\", x = 23, y = 0.6, label = \"2\")+\n  annotate(geom = \"text\", x = 32, y = 0.33, label = \"3\")+\n  labs(y = \"Disease incidence (y)\",\n       x = \"Time (days)\")+\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 10.1: Disease progress curves for three tobacco etch epidemics in pepper. Reproduced from Madden et al. (2017) page 94\n\n\n\n\nMost of the three curves show a sigmoid shape with the exception of group 3 that resembles an exponential growth, not reaching the maximum value, and thus suggesting an incomplete epidemic. We can easily eliminate the monomolecular and exponential models and decide on the other two non-flexible models: logistic or Gompertz. To do that, let’s proceed to model fitting and evaluate the statistics for supporting a final decision. There are two modeling approaches for model fitting in epifitter: the linear or nonlinear parameter-estimation methods."
  },
  {
    "objectID": "temporal-fitting.html#fitting-single-epidemics",
    "href": "temporal-fitting.html#fitting-single-epidemics",
    "title": "10  Model fitting",
    "section": "10.4 Fitting: single epidemics",
    "text": "10.4 Fitting: single epidemics\nAmong the several options offered by epifitter we start with the simplest one, which is fit a model to a single epidemics using the linear regression approach. For such, the fit_lin() requires two arguments: time (time) and disease intensity (y) each one as a vector stored or not in a dataframe.\nSince we have three epidemics, fit_lin() will be use three times. The function produces a list object with six elements. Let’s first look at the Stats dataframe of each of the three lists named epi1 to epi3.\n\nlibrary(epifitter)\nepi1 &lt;- fit_lin(time = pepper$t,  \n                y = pepper$`1` )\nepi1$Stats\n\n                 CCC r_squared    RSE\nGompertz      0.9848    0.9700 0.5911\nMonomolecular 0.9838    0.9681 0.5432\nLogistic      0.9782    0.9572 0.8236\nExponential   0.7839    0.6447 0.6705\n\n\n\nepi2 &lt;- fit_lin(time = pepper$t,  \n  y = pepper$`2` )\nepi2$Stats\n\n                 CCC r_squared    RSE\nLogistic      0.9962    0.9924 0.4524\nGompertz      0.9707    0.9431 0.8408\nMonomolecular 0.9248    0.8601 1.0684\nExponential   0.8971    0.8134 1.2016\n\n\n\nepi3 &lt;- fit_lin(time = pepper$t,  \n  y = pepper$`3` )\nepi3$Stats\n\n                 CCC r_squared    RSE\nLogistic      0.9829    0.9665 0.6045\nGompertz      0.9825    0.9656 0.2263\nExponential   0.9636    0.9297 0.7706\nMonomolecular 0.8592    0.7531 0.2534\n\n\nThe statistics of the model fit confirms our initial guess that the predictions by the logistic or the Gompertz are closer to the observations than predictions by the other models. There is no much difference between them based on these statistics. However, to pick one of the models, it is important to inspect the curves with the observed and predicted values to check which model is best for all curves."
  },
  {
    "objectID": "temporal-fitting.html#fitting-multiple-epidemics",
    "href": "temporal-fitting.html#fitting-multiple-epidemics",
    "title": "10  Model fitting",
    "section": "10.5 Fitting: multiple epidemics",
    "text": "10.5 Fitting: multiple epidemics\nBefore looking at the prediction, let’s use another handy function that allows us to simultaneously fit the models to multiple DPC data. Different from fit_lin(), fit_multi() requires the data to be structured in the long format where there is a column specifying each of the epidemics.\nLet’s then create a new data set called pepper2 using the data transposing functions of the tidyr package.\n\npepper2 &lt;- pepper |&gt; \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\")\n\nNow we fit the models to all DPCs. Note that the name of the variable indicating the DPC code needs to be informed in strata_cols argument.\n\nepi_all &lt;- fit_multi(\n  time_col = \"t\",\n  intensity_col = \"inc\",\n  data = pepper2,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nNow let’s select the statistics of model fitting. Again, Epifitter ranks the models based on the CCC (the higher the better) but it is important to check the RSE as well - the lower the better. In fact, the RSE is more important when the goal is prediction.\n\nepi_all$Parameters |&gt; \n  select(treat, model, best_model, RSE, CCC)\n\n   treat         model best_model       RSE       CCC\n1      1      Gompertz          1 0.5911056 0.9847857\n2      1 Monomolecular          2 0.5431977 0.9838044\n3      1      Logistic          3 0.8235798 0.9781534\n4      1   Exponential          4 0.6705085 0.7839381\n5      2      Logistic          1 0.4523616 0.9961683\n6      2      Gompertz          2 0.8407922 0.9707204\n7      2 Monomolecular          3 1.0683633 0.9247793\n8      2   Exponential          4 1.2015809 0.8971003\n9      3      Logistic          1 0.6045243 0.9829434\n10     3      Gompertz          2 0.2262550 0.9824935\n11     3   Exponential          3 0.7705736 0.9635747\n12     3 Monomolecular          4 0.2533763 0.8591837\n\n\nTo be more certain about our decision, let’s advance to the final step which is to produce the plots with the observed and predicted values for each assessment time by calling the Data dataframe of the `epi_all list.\n\nepi_all$Data |&gt;\n filter(model %in% c(\"Gompertz\", \"Logistic\")) |&gt; \n  ggplot(aes(time, predicted, shape = treat)) +\n  geom_point(aes(time, y)) +\n  geom_line() +\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(0, 1)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.2: Observed (dots) and fitted (line) values for three tobacco etch epidemics in pepper\n\n\n\n\nOverall, the logistic model seems a better fit for all the curves. Let’s produce a plot with the prediction error versus time.\n\nepi_all$Data |&gt;\n filter(model %in% c(\"Gompertz\", \"Logistic\")) |&gt; \n  ggplot(aes(time, predicted -y, shape = treat)) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype =2)+\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(-0.4, 0.4)) + # set the max to 0.6\n  labs(\n    y = \"Prediction error\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.3: Prediction error (dotted lines) by two models fitted to the progress curves of three tobacco etch epidemics in pepper\n\n\n\n\nThe plots above confirms the logistic model as good fit overall because the errors for all epidemics combined are more scattered around the non-error line.\n\n  epi_all$Parameters |&gt;\n    filter(model == \"Logistic\") |&gt;\n    select(treat, y0, y0_ci_lwr, y0_ci_upr, r, r_ci_lwr, r_ci_upr \n)\n\n  treat           y0    y0_ci_lwr   y0_ci_upr         r  r_ci_lwr  r_ci_upr\n1     1 0.0935037690 0.0273207272 0.274728744 0.2104047 0.1659824 0.2548270\n2     2 0.0013727579 0.0006723537 0.002800742 0.2784814 0.2540818 0.3028809\n3     3 0.0008132926 0.0003131745 0.002110379 0.1752146 0.1426077 0.2078215\n\n\nWe can produce a plot for visual inference on the differences in the parameters.\n\np1 &lt;- epi_all$Parameters |&gt;\n  filter(model == \"Logistic\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"r\"\n  )\n\np2 &lt;- epi_all$Parameters |&gt;\n  filter(model == \"Logistic\") |&gt;\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"y0\"\n  )\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\nFigure 10.4: Estimated infection rates (left) and initial inoculum (right) by a logistic model fitted to the progress curves of three epidemics of tobacco etch on pepper"
  },
  {
    "objectID": "temporal-fitting.html#designed-experiments",
    "href": "temporal-fitting.html#designed-experiments",
    "title": "10  Model fitting",
    "section": "10.6 Designed experiments",
    "text": "10.6 Designed experiments\nIn this next section, we will work with disease data collected over time in the same plot unit (also called repeated measures) from a designed experiment for evaluating and comparing treatment effects.\nAgain, we will use a dataset of progress curves shown in page 98 (Madden et al. 2017). The curves represent the incidence of soybean plants symptomatic for bud blight caused by tobacco streak virus. Four treatments (different planting dates) were evaluated in randomized complete block design with four replicates. There are four assessment in time for each curve. The data was stored as a csv file and will be loaded using read_csv() function and stored as dataframe called budblight.\n\n10.6.1 Loading data\n\nbudblight &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/bud-blight-soybean.csv\")\n\nLet’s have a look at the first six rows of the dataset and check the data type for each column. There is an additional column representing the replicates, called block.\n\nbudblight\n\n# A tibble: 64 × 4\n   treat  time block     y\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 PD1      30     1  0.1 \n 2 PD1      30     2  0.3 \n 3 PD1      30     3  0.1 \n 4 PD1      30     4  0.1 \n 5 PD1      40     1  0.3 \n 6 PD1      40     2  0.38\n 7 PD1      40     3  0.36\n 8 PD1      40     4  0.37\n 9 PD1      50     1  0.57\n10 PD1      50     2  0.52\n# … with 54 more rows\n\n\n\n\n10.6.2 Visualizing the DPCs\nLet’s have a look at the curves and produce a combo plot figure similar to Fig. 4.17 of the book, but without the line of the predicted values.\n\np3 &lt;- budblight |&gt;\n  ggplot(aes(\n    time, y,\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 1.5) +\n  ylim(0, 0.6) +\n  theme(legend.position = \"none\")+\n  facet_wrap(~treat, ncol =1)+\n  labs(y = \"Disease incidence\",\n       x = \"Time (days after emergence)\")\n\np4 &lt;- budblight |&gt;\n  ggplot(aes(\n    time, log(1 / (1 - y)),\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 2) +\n  facet_wrap(~treat, ncol = 1) +\n  theme(legend.position = \"none\")+\n  labs(y = \"Transformed incidence\", x = \"Time (days after emergence)\")\n\np3 | p4\n\n\n\n\nFigure 10.5: Disease progress curves for the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n10.6.3 Model fitting\nRemember that the first step in model selection is the visual appraisal of the curve data linearized with the model transformation. In the case the curves represent complete epidemics (close to 100%) appraisal of the absolute rate (difference in y between two times) over time is also helpful.\nFor the treatments above, it looks like the curves are typical of a monocyclic disease (the case of soybean bud blight), for which the monomolecular is usually a good fit, but other models are also possible as well. For this exercise, we will use both the linear and the nonlinear estimation method.\n\n10.6.3.1 Linear regression\nFor convenience, we use the fit_multi() to handle multiple epidemics. The function returns a list object where a series of statistics are provided to aid in model selection and parameter estimation. We need to provide the names of columns (arguments): assessment time (time_col), disease incidence (intensity_col), and treatment (strata_cols).\n\nlin1 &lt;- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nLet’s look at how well the four models fitted the data. Epifitter suggests the best fitted model (1 to 4, where 1 is best) for each treatment. Let’s have a look at the statistics of model fitting.\n\nlin1$Parameters |&gt; \nselect(treat, best_model, model, CCC, RSE)\n\n   treat best_model         model       CCC        RSE\n1    PD1          1 Monomolecular 0.9348429 0.09805661\n2    PD1          2      Gompertz 0.9040182 0.22226189\n3    PD1          3      Logistic 0.8711178 0.44751963\n4    PD1          4   Exponential 0.8278055 0.36124036\n5    PD2          1 Monomolecular 0.9547434 0.07003116\n6    PD2          2      Gompertz 0.9307192 0.17938711\n7    PD2          3      Logistic 0.9062012 0.38773023\n8    PD2          4   Exponential 0.8796705 0.32676216\n9    PD3          1 Monomolecular 0.9393356 0.06832499\n10   PD3          2      Gompertz 0.9288436 0.17156394\n11   PD3          3      Logistic 0.9085414 0.39051075\n12   PD3          4   Exponential 0.8896173 0.33884790\n13   PD4          1      Gompertz 0.9234736 0.17474422\n14   PD4          2 Monomolecular 0.8945962 0.06486949\n15   PD4          3      Logistic 0.8911344 0.52412586\n16   PD4          4   Exponential 0.8739618 0.49769642\n\n\nAnd now we extract values for each parameter estimated from the fit of the monomolecular model.\n\nlin1$Parameters |&gt;\nfilter(model == \"Monomolecular\") |&gt;\nselect(treat, y0, r)\n\n  treat         y0          r\n1   PD1 -0.5727700 0.02197351\n2   PD2 -0.5220593 0.01902952\n3   PD3 -0.4491365 0.01590586\n4   PD4 -0.3619898 0.01118047\n\n\nNow we visualize the fit of the monomolecular model (using filter function - see below) to the data together with the observed data and then reproduce the right plots in Fig. 4.17 from the book.\n\nlin1$Data |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(time, predicted)) +\n  geom_point(aes(time, y)) +\n  geom_line(size = 0.5) +\n  facet_wrap(~treat) +\n  coord_cartesian(ylim = c(0, 0.6)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nFigure 10.6: Observed (dot) and fitted values by a monomolecular model (line) to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\nNow we can plot the means and respective 95% confidence interval of the apparent infection rate (\\(r\\)) and initial inoculum (\\(y_0\\)) for visual inference.\n\np5 &lt;- lin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Infection rate (r)\"\n  )\n\np6 &lt;- lin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"Initial inoculum (y0)\"\n  )\np5 | p6\n\n\n\n\nFigure 10.7: Estimates of the infection rate (left) and initial inoculum (right) from the fit of a monomolecular model to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n10.6.3.2 Non-linear regression\nTo estimate the parameters using the non-linear approach, we repeat the same arguments in the fit_multi function, but include an additional argument nlin set to TRUE.\n\nnlin1 &lt;- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = TRUE\n)\n\nLet’s check statistics of model fit.\n\nnlin1$Parameters |&gt;\nselect(treat, model, CCC, RSE, best_model)\n\n   treat         model       CCC        RSE best_model\n1    PD1 Monomolecular 0.9382991 0.06133704          1\n2    PD1      Gompertz 0.9172407 0.06986307          2\n3    PD1      Logistic 0.8957351 0.07700720          3\n4    PD1   Exponential 0.8544194 0.08799512          4\n5    PD2 Monomolecular 0.9667886 0.04209339          1\n6    PD2      Gompertz 0.9348370 0.05726761          2\n7    PD2      Logistic 0.9077857 0.06657793          3\n8    PD2   Exponential 0.8702365 0.07667322          4\n9    PD3 Monomolecular 0.9570853 0.04269129          1\n10   PD3      Gompertz 0.9261609 0.05443852          2\n11   PD3      Logistic 0.8997106 0.06203037          3\n12   PD3   Exponential 0.8703443 0.06891021          4\n13   PD4 Monomolecular 0.9178226 0.04595409          1\n14   PD4      Gompertz 0.9085579 0.04791331          2\n15   PD4      Logistic 0.8940731 0.05083336          3\n16   PD4   Exponential 0.8842437 0.05267415          4\n\n\nAnd now we obtain the two parameters of interest. Note that the values are not the sames as those estimated using linear regression, but they are similar and highly correlated.\n\nnlin1$Parameters |&gt;\nfilter(model == \"Monomolecular\") |&gt;\nselect(treat, y0, r)\n\n  treat         y0          r\n1   PD1 -0.7072562 0.02381573\n2   PD2 -0.6335713 0.02064629\n3   PD3 -0.5048763 0.01674209\n4   PD4 -0.3501234 0.01094368\n\n\n\np7 &lt;- nlin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Infection rate (r)\"\n  )\n\np8 &lt;- nlin1$Parameters |&gt;\n  filter(model == \"Monomolecular\") |&gt;\n  ggplot(aes(treat, y0)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Epidemic\",\n    y = \"Initial inoculum (y0)\"\n  )\n\np7 | p8\n\n\n\n\nFigure 10.8: Estimates of the infection rate (left) and initial inoculum (right) from the fit of a monomolecular model to the data on the incidence of budblight of soybean in Brazil for four planting dates\n\n\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Temporal analysis i: Quantifying and comparing epidemics. In The American Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004."
  },
  {
    "objectID": "spatial-gradients.html#introduction",
    "href": "spatial-gradients.html#introduction",
    "title": "11  Spatial gradients",
    "section": "11.1 Introduction",
    "text": "11.1 Introduction\nThe assessment of disease in space, in terms of changes in the intensity as it spreads over distance, is called disease gradient. In reality, it is the dispersal (migration) of the pathogen by various means (e.g. wind, vectors, rain, movement of infected material or human mediation) that promotes the spread of plant diseases within a field or across continents and generates the disease gradients. There are two kinds of gradients, the inoculum gradient where host availability is not necessarily required and the disease gradient where the three elements of the disease triangle are required. Let’s see examples of actual disease gradients measured in the field with quite distinct patterns.\nIn the first example (Mundt et al. 1999), the objective of the authors was to measure the dispersal potential of the pathogenic bacteria Xanthomonas oryzae pv. oryzae that causes leaf blight on rice using experimental plots in the Philippines, during the wet seasons of 1994 and 1995. The data were made available in this tutorial. We enter the data manually and then produce two plots, one for each year.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\n\nxo &lt;- \ntibble::tribble(\n    ~d,   ~y4,   ~y5,\n     0, 3.083, 7.185,\n  0.22, 0.521,  0.38,\n  0.44, 0.083, 0.157,\n  0.66, 0.021, 0.028\n  )\n\ng1 &lt;- xo |&gt; \n  ggplot(aes(d, y4))+\n  geom_point()+\n  geom_line()+\n  ylim(0,8)+\n  labs(y = \"Numer of new lesions\",\n       x = \"Distance (m)\",\n       title = \"1994 wet season\")\n\ng2 &lt;- xo |&gt; \n  ggplot(aes(d, y5))+\n  geom_point()+\n  geom_line()+\n  ylim(0,8)+\n  labs(y = \"Numer of new lesions\",\n       x = \"Distance (m)\",\n       title = \"1995 wet season\")\n\nlibrary(patchwork)\n(g1 | g2) +  plot_annotation(\n    caption = \"Source: Mundt et al. (1999)\")\n\n\n\n\nFigure 11.1: Primary gradients of bacerial blight of rice in two wet seasons in the Philippines\n\n\n\n\nThe second gradient is of stripe rust, caused by Puccinia striiformis f. sp. tritici, on wheat collected in a field experiment at Hermiston in 2002 (Sackett and Mundt 2005) and whose data was made freely available (Mikaberidze et al. 2015). Let’s enter data manually as a tibble format. There are five columns. The first and second are distances in feet and meters, respectively, from the source of infection. The other three columns are measures of stripe rust severity on replicated plots.\n\nhermiston &lt;- \n  tibble::tribble(\n  ~dist_f, ~dist_m,  ~`1`,  ~`2`,  ~`3`,\n  0,        0,    65,    65,    39,\n  5,      1.5,    35,    44,   7.5,\n  10,       3,  21.5,  14.5,  1.75,\n  20,     6.1,     8,  0.75,   0.2,\n  40,    12.2,     1,  0.08, 0.025,\n  60,    18.3,  0.25, 0.026, 0.015,\n  80,    24.4, 0.035, 0.015, 0.009,\n  100,   30.5,  0.01, 0.003, 0.008,\n  120,   36.6, 0.008, 0.016,  0.01,\n  140,   42.7, 0.003, 0.003,  0.01,\n  160,   48.8, 0.001, 0.006, 0.006,\n  180,   54.9, 0.001, 0.002, 0.002,\n  200,     61, 0.001, 0.003, 0.004,\n  220,   67.1, 0.001, 0.003, 0.002,\n  240,   73.2, 0.001, 0.001,     0,\n  260,   79.2, 0.001, 0.002,     0,\n  280,   85.3, 0.001, 0.001,     0,\n  300,   91.4, 0.001, 0.001, 0.001\n  )\n\n\nlibrary(tidyverse)\nlibrary(ggthemes)\n\nhermiston |&gt; \n  pivot_longer(3:5, names_to = \"replicate\", values_to = \"severity\") |&gt; \n  ggplot(aes(dist_m, severity, color = replicate))+\n  geom_point(size = 2)+\n  geom_line(size = 1)+\n  scale_color_colorblind()+\n  labs(x = \"Distance from the source (m)\",\n       y = \"Stripe rust severity (%)\",\n       color = \"Replicate\",\n       caption = \"source: Sackett et al. (2005)\")\n\n\n\n\nFigure 11.2: Primary gradients of stripe rust of wheat on a replicated experiment\n\n\n\n\nAs it is clear in the above examples, in disease gradients, assuming that there is only a single source of inoculum, the intensity of the disease decreases more steeply within short distances of the source, and less steeply at greater distances until they reach zero or a low background level of occasional diseased plants. The shapes of the gradients are defined by mechanisms associated with the dispersal of the inoculum which depends on the biology of the pathogen but strongly to environmental factors that affect pathogen dispersal.\nThe resulting gradients can be classified in two types: primary or secondary. The primary gradient originates only from the initial focus, while the secondary gradient originates from the movement of inoculum produced at previously infected (due to primary gradients) plants to other plants at increasing distances from the source. It is expected that a mix of both kinds of gradients exists as the disease increases over time.\nAs an example of primary and secondary gradients, let’s visualize the gradients of Septoria leaf spot, caused by Septoria lycopersici, on tomato (Parker et al. 1997). The gradients were measured during two times, thus enabling a comparison of primary and secondary dispersal/disease gradients. More details of the study and experimental approach were provided in this tutorial. The data is entered below as a tribble and the plot produced using ggplot2.\n\nseptoria &lt;- \ntibble::tribble(\n ~d, ~date1, ~date4,\n 60,     75,    87,\n 120,    40,    78,\n 180,    30,    68,\n 240,    20,    62,\n 300,    15,    50,\n 360,    12,    27,\n 420,    10,    32,\n 480,    12,    12,\n 540,     8,    13,\n 600,     5,     5,\n 660,     4,     4\n                )\n\nseptoria |&gt; \n  pivot_longer(2:3, names_to = \"date\", \n               values_to = \"defoliation\") |&gt; \n  ggplot(aes(d, defoliation, color = date))+\n  geom_point()+\n  geom_line()+\n  scale_color_colorblind()+\n  annotate(geom = \"text\", x = 200, y = 12, \n           label = \"Primary gradient\", hjust = \"left\")+\n  annotate(geom = \"text\", x = 200, y = 72, \n           label = \"Secondary gradient\", hjust = \"left\")+\n  labs(x = \"Distance from focus (m)\",\n       y = \"Percent defoliation\",\n       color = \"Date\",\n       caption = \"Parker et al. (1997)\")\n\n\n\n\nFigure 11.3: Primary and secondary gradients of defoliation due to Septoria leaf spot on tomato\n\n\n\n\nWhen studying disease gradients, researchers need to make sure that there is a well-defined single source of inoculum. In gradients, this is called a focus (where foci are deemed the plural), from where the inoculum originates. Three types of foci can be defined: point, line or area sources. While the point source can be a plant or group of plants at any position in the plot or field (center or corner), line and area sources are usually defined as one or more rows of diseased plants at one side of the plot or field.\n\n\nCode\nlibrary(ggplot2)\n\nline &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 9.7, ymax = 10, color = \"black\", fill = \"orange\")+\n  annotate(\"segment\", size = 2, x = 1, xend = 1, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 3, xend = 3, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 7, xend = 7, y = 9.5, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 9, xend = 9, y = 9.5, yend = 2, arrow = arrow())+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"      Side line\")\n\narea &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 8.2, ymax = 10, color = \"black\", fill = \"orange\")+\n  annotate(\"segment\", size = 2, x = 1, xend = 1, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 3, xend = 3, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 7, xend = 7, y = 8, yend = 2, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 9, xend = 9, y = 8, yend = 2, arrow = arrow())+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"      Side area\")\n\npoint_central &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 5, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 10, y = 5, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 5, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 0, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 5, yend = 10, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 5, xend = 5, y = 5, yend = 0, arrow = arrow())+\n   annotate(\"rect\", xmin = 5.5, xmax = 4.5, ymin = 4.5, ymax = 5.5, color = \"black\", fill = \"orange\" )+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"    Central point/area\")\n\npoint_corner &lt;- ggplot(data.frame(c(1:10),c(1:10)))+\n  annotate(\"rect\", xmin = 0, xmax = 10, ymin = 0, ymax = 10, fill = \"gray92\")+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 6.6, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 3.3, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 0, y = 10, yend = 0, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 3.3, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 6.6, arrow = arrow())+\n  annotate(\"segment\", size = 2, x = 0, xend = 10, y = 10, yend = 10, arrow = arrow())+\n  annotate(\"rect\", xmin = 0, xmax = 1, ymin = 9, ymax = 10, color = \"black\", fill = \"orange\")+\n  ylim(0,10)+\n  xlim(0,10)+\n  coord_fixed()+\n  theme_void()+\n  labs(title = \"    Corner point/area\")\n\nlibrary(patchwork)\np_gradients &lt;- (line | area)/\n(point_central | point_corner)\n\nggsave(\"imgs/gradients.png\", width =9, height =9, bg = \"white\")\n\n\n\n\n\nFigure 11.4: Example of location and size of inoculum sources for the study of disease gradients\n\n\n\n\n\n\nMikaberidze, A., Mundt, C. C., and Bonhoeffer, S. 2015. Data from: Invasiveness of plant pathogens depends on the spatial scale of host distribution. Available at: http://datadryad.org/stash/dataset/doi:10.5061/dryad.f2j8s.\n\n\nMundt, C. C., Ahmed, H. U., Finckh, M. R., Nieva, L. P., and Alfonso, R. F. 1999. Primary Disease Gradients of Bacterial Blight of Rice. Phytopathology®. 89:64–67 Available at: http://dx.doi.org/10.1094/phyto.1999.89.1.64.\n\n\nParker, S. K., Nutter, F. W., and Gleason, M. L. 1997. Directional Spread of Septoria Leaf Spot in Tomato Rows. Plant Disease. 81:272–276 Available at: http://dx.doi.org/10.1094/pdis.1997.81.3.272.\n\n\nSackett, K. E., and Mundt, C. C. 2005. Primary Disease Gradients of Wheat Stripe Rust in Large Field Plots. Phytopathology®. 95:983–991 Available at: http://dx.doi.org/10.1094/PHYTO-95-0983."
  },
  {
    "objectID": "spatial-models.html#exponential-model",
    "href": "spatial-models.html#exponential-model",
    "title": "12  Gradient models",
    "section": "12.1 Exponential model",
    "text": "12.1 Exponential model\nThe exponential model is also known as Kiyosawa & Shiyomi model. The differential of the exponential model is given by\n\\(\\frac{dy}{dx}\\) = \\(-b_{E}.y\\) ,\nwhere \\(b_{E}\\) is the exponential form of the rate of decline and \\(y\\) is the disease intensity. This model suggests that \\(y\\) (any disease intensity) is greater close to the source of inoculum, or at the distance zero. The integral form of the model is given by\n\\(y = a . e^{-b.x}\\) ,\nwhere \\(a\\) is the disease intensity at the distance zero and \\(b\\) is the rate of decline, in this case negative because disease intensity decreases with the increase of the distance from inoculum source. Let’s make a plot for two disease gradients of varying parameters for this model.\nFirst we need to load essential packages for programming, customizing the outputs and defining a global ggplot theme.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16)) # set global theme\n\nSet the parameters for the exponential model with two rates and the same inoculum level at the source:\n\na1 &lt;- 0.2 # y at distance zero for gradient 1\na2 &lt;- 0.2 # y at distance zero for gradient 2\nb1 &lt;- 0.1 # decline rate for gradient 1\nb2 &lt;- 0.05 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\nThe following code allows to visualize the model predictions.\n\ndat |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * exp(-b1 * x), linetype = 1) +\n  stat_function(fun = function(x) a2 * exp(-b2 * x), linetype = 2) +\n  ylim(0, a1) +\n  annotate(\"text\", x = 20, y = 0.04, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.10, label = \"b = 0.05\") +\n  labs(x = \"Distance (m)\", y = \"Disease incidence (proportion)\"\n  )\n\n\n\n\nFigure 12.1: Exponential curves describing plant disease gradients"
  },
  {
    "objectID": "spatial-models.html#power-law-model",
    "href": "spatial-models.html#power-law-model",
    "title": "12  Gradient models",
    "section": "12.2 Power law model",
    "text": "12.2 Power law model\nAlso known as the modified Gregory’s model (Gregory was a pioneer in the use this model to describe plant disease gradients). In the power law model, \\(Y\\) is proportional to the power of the distance, and is given by:\n\\(Y = a_{P}.x - b_{P}\\)\nwhere \\(a_{P}\\) and \\(b_{P}\\) are the two parameters of the power law model. They differ from the exponential because as closer to \\(x\\) is to zero, \\(Y\\) is indefinitely large (not meaningful biologically). However, the model can still be useful because it produces realistic values at any distance \\(x\\) away from the source. The values of the \\(a_{P}\\) parameter should be interpreted in accord to the scale of \\(x\\), whether in centimeters or meters. If the distance between the source and the first measure away from the source is 0.5m, it is so more appropriate to record the distance in cm than in m or km.\nOnce \\(y\\) at the distance zero from the source is undefined when using the power law model, this is usually modified by the addition of a positive constant \\(C\\) in \\(x\\):\n\\(Y = a_{P}.(x + C) - b_{P}\\)\nFor this reason, the model is named as the modified power law. Here, the constant \\(C\\) is of the same unit of \\(x\\). At the distance zero, the positive constant is a term that express the size of the inoculum source. In other words, the \\(a\\) parameter is a theoretical value of \\(Y\\) at the distance \\(1-C\\) from the center of the inoculum source.\nLet’s plot two gradients with two rate parameters for the modified power law model:\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * ((x + C)^-b1), linetype = 1) +\n  stat_function(fun = function(x) a2 * ((x + C)^-b2), linetype = 2) +\n  ylim(0, a1 - 0.02) +\n  annotate(\"text\", x = 20, y = 0.03, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.06, label = \"b = 0.05\") +\n  labs(x = \"Distance (m)\", y = \"Disease incidence\")\n\n\n\n\nFigure 12.2: Power law (modified) curves describing plant disease gradients\n\n\n\n\nThe differential equation of the power law model is given by:\n\\(\\frac{dy}{dx}\\) = \\(\\frac{-b_{P}.Y}{x - C}\\)\nSimilar to the exponential model, \\(\\frac{dy}{dx}\\) is proportional to \\(Y\\), meaning that the gradient is steeper (more negative) at the highest disease intensity value, usually closer to the source."
  },
  {
    "objectID": "spatial-models.html#linearization-of-the-models",
    "href": "spatial-models.html#linearization-of-the-models",
    "title": "12  Gradient models",
    "section": "12.3 Linearization of the models",
    "text": "12.3 Linearization of the models\n\n12.3.1 Transformations of y\nThe gradient models, again similar to the temporal disease models, are non linear in their parameters. The model is intrinsically linear if transformations are applied (according to the model) in both sides of the equations. The linear model in its generic state is given by\n\\(y* = a* + bx\\) ,\nwhere the asterisk in \\(a\\) indicated that one of the transformations was applied in \\(y\\) that produced the linear model. Note that \\(a*\\) is the transformed version of the initial disease intensity, which needs to be returned to the original scale according to the respective back-transformation. Follows the linearized form of the two most common gradient models.\n\\(ln(y) = ln(a_{E}) - b_{E}. x\\)\n\\(ln(y) = ln(a_{P}) - b_{E}. ln(x+C)\\)\n\n\n12.3.2 Plot for the linearized form of models\nLet’s visualize the linearization of the exponential model with two different slopes (gradient 1 and 2). Note that the transformation used was \\(ln(y)\\).\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- 80 # maximum distance for gradient 1\nmax2 &lt;- 80 # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * x), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * x), linetype = 2) +\n  labs(x = \"log of distance (m)\", y = \"log of disease incidence\"\n  )\n\n\n\n\nFigure 12.3: Linearization of the exponential model describing plant disease gradients\n\n\n\n\nFollows the linearization of the modified power law model. Note that the transformation used was \\(ln(y)\\) and \\(ln(x+C)\\) .\n\nC &lt;- 0.5\na1 &lt;- 0.2 # y at zero distance for gradient 1\na2 &lt;- 0.2 # y at zero distance for gradient 2\nb1 &lt;- 0.5 # decline rate for gradient 1\nb2 &lt;- 0.7 # decline rate for gradient 2\nmax1 &lt;- log(80) # maximum distance for gradient 1\nmax2 &lt;- log(80) # maximum distance for gradient 2\ndat2 &lt;- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 |&gt;\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * log(x + C)), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * log(x + C)), linetype = 2) +\n  labs(\n    title = \"Modified Power Law\",\n    subtitle = \"\",\n    x = \"log of distance (m)\",\n    y = \"log of disease incidence\"\n  )\n\n\n\n\nFigure 12.4: Linearization of the modified power law curves describing plant disease gradients"
  },
  {
    "objectID": "spatial-fitting.html#dataset",
    "href": "spatial-fitting.html#dataset",
    "title": "13  Fitting gradient models",
    "section": "13.1 Dataset",
    "text": "13.1 Dataset\nThe hypothetical data below shows a gradient for the number of lesions counted at varying distances in meters from the source. Let’s create two vectors, one for the distances \\(x\\) and the other for the lesion count \\(Y\\), and then a data frame by combining the two vectors.\n\n# create the two vectors\nx &lt;- c(0.8, 1.6, 2.4, 3.2, 4, 7.2, 12, 15.2, 21.6, 28.8)\nY &lt;- c(184.9, 113.3, 113.3, 64.1, 25, 8, 4.3, 2.5, 1, 0.8)\ngrad1 &lt;- data.frame(x, Y) # create the dataframe\ngrad1 # show the gradient\n\n      x     Y\n1   0.8 184.9\n2   1.6 113.3\n3   2.4 113.3\n4   3.2  64.1\n5   4.0  25.0\n6   7.2   8.0\n7  12.0   4.3\n8  15.2   2.5\n9  21.6   1.0\n10 28.8   0.8"
  },
  {
    "objectID": "spatial-fitting.html#visualize-the-gradient",
    "href": "spatial-fitting.html#visualize-the-gradient",
    "title": "13  Fitting gradient models",
    "section": "13.2 Visualize the gradient",
    "text": "13.2 Visualize the gradient\n\ngrad1 |&gt; \n  ggplot(aes(x, Y))+\n  geom_point()+\n  geom_line()+\n  labs(y = \"Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\nFigure 13.1: Hypothetical gradient of lesion count over distances from the inoculum source"
  },
  {
    "objectID": "spatial-fitting.html#linear-regression",
    "href": "spatial-fitting.html#linear-regression",
    "title": "13  Fitting gradient models",
    "section": "13.3 Linear regression",
    "text": "13.3 Linear regression\nA linear regression model is fitted to the transformed variables according to the model. The higher the coefficient of determination, the better is the fit of the model to the data.\n\n13.3.1 Exponential model\n\nreg_exp &lt;- lm(log(Y) ~ x, data = grad1)\nsummary(reg_exp)$r.squared\n\n[1] 0.8776612\n\n\n\ngrad1 |&gt; \n  ggplot(aes(x, log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_exp)[[2]], intercept = coef(reg_exp)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\nFigure 13.2: Fit of the exponential model to the log of lesion count over distances from the inoculum source\n\n\n\n\n\n\n13.3.2 Power law model\n\nreg_p &lt;- lm(log(Y) ~ log(x), data = grad1)\nsummary(reg_p)$r.squared\n\n[1] 0.962132\n\n\n\ngrad1 |&gt; \n  ggplot(aes(log(x), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_p)[[2]], intercept = coef(reg_p)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance\")\n\n\n\n\nFigure 13.3: Fit of the power law model to the log of lesion count over log of the distance from the inoculum source\n\n\n\n\n\n\n13.3.3 Modified power law model\n\nreg_pm &lt;- lm(log(Y) ~ log(x + 0.4), data = grad1)\nsummary(reg_pm)$r.squared\n\n[1] 0.9742072\n\n\n\ngrad1 |&gt; \n  ggplot(aes(log(x+0.4), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_pm)[[2]], intercept = coef(reg_pm)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance + 0.4 (m)\")\n\n\n\n\nFigure 13.4: Fit of the modified power law model to the log of lesion count over log + 0.4 of the distances from the inoculum source\n\n\n\n\nBased on the (highest) coefficient of determination, the modified power law provided the best fit. The graphs for the fitted models confirm this conclusion."
  },
  {
    "objectID": "spatial-patterns.html#definitions",
    "href": "spatial-patterns.html#definitions",
    "title": "14  Spatial patterns",
    "section": "14.1 Definitions",
    "text": "14.1 Definitions\nA spatial disease pattern can be defined as the arrangement of diseased entities relative to each other and to the architecture of the host crop (Madden et al. 2017). Such arrangement is the realization of the underlying dispersal of the pathogen, from one or several sources within and/or outside the area of interest, under the influence of physical, biological and environmental factors.\nThe study of spatial patterns is conducted at a specific time or multiple times during the epidemic. When assessed multiple times, both spatial and temporal processes can be characterized. Because epidemics change over time, it is expected that spatial patterns are not constant but change over time as well. Usually, plant pathologists are interested in determining spatial patterns at one or various spatial scales, depending on the objective of the study. The scale of interest may be a leaf or root, plant, field, municipality, state, country or even intercontinental area. The diseased units observed may vary from lesions on a single leaf to diseased fields in a large production region.\nThe patterns can be classified into two main types that occur naturally: random or aggregated. The random pattern originates because the chances for the units (leaf, plant, crop) to be infected are equal and low, and are largely independent from each other. In aggregated spatial patterns, such chances are unequal and there is dependency among the units. For example, a healthy unit close to a diseased unit is at higher risk than more distant units.\nLet’s simulate in R two vectors (x,y) for the positions of diseased units that follow a random or an aggregated pattern. For the random pattern, we use runif, a function which generates random deviates from the uniform distribution.\n\nset.seed(123)          # for reproducibility\nx &lt;- runif(50, 0, 30)  # x vector\ny &lt;- runif(50, 0, 30)  # y vector\ndat &lt;- data.frame(x,y) # dataframe for plotting\n\nNow, the plot to visualize the random pattern.\n\nlibrary(tidyverse) \nlibrary(ggthemes)\ntheme_set(theme_few())\n\npr &lt;- dat |&gt; # R base pipe operator\n  ggplot(aes(x, y))+\n  geom_point(size =3, \n             color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Random\")\npr\n\n\n\n\nFigure 14.1: Random pattern of a plant disease epidemic\n\n\n\n\nNow, we can generate new x and y vectors using rnbinom function which allows generating values for the negative binomial distribution (which should give rise to aggregated patterns) with parameters size and prob. Let’s simulate 50 values with mean 12 and size 20 as dispersal parameter.\n\nx &lt;- rnbinom(n = 50, mu = 12, size = 20)\ny &lt;- rnbinom(n = 50, mu = 5, size = 20)\ndat2 &lt;- data.frame(x, y)\n\nThis should give us an aggregated pattern.\n\npag &lt;- dat2 |&gt;\n  ggplot(aes(x, y))+\n  geom_point(size = 3, color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Aggregated\")\npag\n\n\n\n\nFigure 14.2: Aggregated pattern of a plant disease epidemic\n\n\n\n\nA rare pattern found in nature is the regular pattern, but it may be generated artificially by the man when conducting experimentation. Follows a code to produce the regular pattern.\n\nx &lt;- rep(c(0,5,10,15,20, 25, 30, 35, 40, 45), 5) \ny &lt;- rep(c(0, 5, 10, 15, 20, 25, 30, 35, 40, 45), each = 10)\ndat3 &lt;- data.frame(x, y)\n\npreg &lt;- dat3 |&gt;\n  ggplot(aes(x, y))+\n  geom_point(size = 3, color = \"darkred\")+\n  ylim(0,30)+\n  xlim(0,30)+\n  coord_fixed()+\n  labs(x = \"Distance x\", y = \"Distance y\", \n       title = \"Regular\")\npreg\n\nWarning: Removed 51 rows containing missing values (geom_point).\n\n\n\n\n\nFigure 14.3: Regular pattern of a plant disease epidemic\n\n\n\n\n\nlibrary(patchwork)\npreg + pr + pag\n\n\n\nggsave(\"imgs/spatial.png\", width = 10, height = 4)"
  },
  {
    "objectID": "spatial-patterns.html#spatiotemporal",
    "href": "spatial-patterns.html#spatiotemporal",
    "title": "14  Spatial patterns",
    "section": "14.2 Spatiotemporal",
    "text": "14.2 Spatiotemporal\nThe location of diseased plants can be assessed over time and so we can appraise both the progress and pattern of the epidemics. Let’s visualize spatial data collected from actual epidemics monitored (plant is diseased or not diseased) during six times during the epidemics. The data is available in the epiphy R package. Let’s use only one variety and one irrigation type.\n\nlibrary(epiphy)\ntswv_1928 &lt;- tomato_tswv$field_1928\n\ntswv_1928 |&gt;\n  filter(variety == \"Burwood-Prize\"&\n         irrigation == \"trenches\") |&gt; \n  ggplot(aes(x, y, color = factor(i)))+\n  geom_point(aes(group = seq_along(factor(t))), size =2)+\n  coord_fixed()+\n  scale_color_manual(values = c(\"grey70\", \"darkred\"))+\n  labs(color = \"Status\", title = \"\")+\n  theme_void()+\n  theme(legend.position = \"bottom\")+\n  facet_wrap(~ t, nrow =1)\n\n\n\n\nFigure 14.4: Spatial patterns of tomato spotted wilt virus at six assessment times"
  },
  {
    "objectID": "spatial-tests.html#intensively-mapped",
    "href": "spatial-tests.html#intensively-mapped",
    "title": "15  Tests for patterns",
    "section": "15.1 Intensively mapped",
    "text": "15.1 Intensively mapped\n\n15.1.1 Binary data\nIn this situation the individual plants are mapped, meaning that their relative positions to one another are known. It is the case when a census is used to map presence/absence data. The status of each unit (usually a plant) is noted as a binary variable. The plant is either diseased (D or 1) or non-diseased or healthy (H or 0). Several statistical tests can be used to detect a deviation from randomness. The most commonly used tests are runs, doublets and join count.\n\n15.1.1.1 Runs test\nA run is defined as a succession of one or more diseased (D) or healthy (H) plants, which are followed and preceded by a plant of the other disease status or no plant at all. In the example below, we can count 13 runs.\n\n\n\nFigure 15.2: Example for the computation of the number of ordinary runs in a sequence of binary data\n\n\nThere would be few runs if there is an aggregation of diseased or healthy plants and a large number of runs for a random mixing of diseased and healthy plants.\nLet’s create a vector of binary (0 = non-diseased; 1 = diseased) data representing a crop row with 20 plants and assign it to y. For plotting purposes, we make a dataframe for more complete information.\n\nlibrary(tidyverse) \ntheme_set(theme_bw(base_size = 16))\n\n\ny1 &lt;- c(1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1,1)\nx1 &lt;- c(1:20) # position of each plant\nz1 &lt;- 1\nrow1 &lt;- data.frame(x1, y1, z1) # create a dataframe\n\nWe can then visualize the series using ggplot and count the number of runs as 7, aided by the color used to identify a run.\n\nrow1 |&gt;\n  ggplot(aes(x1, z1, label = x1, color = factor(y1))) +\n  geom_point(shape = 15, size = 7) +\n  theme_void() +\n  scale_x_continuous(breaks = max(z1)) +\n  scale_color_manual(values = c(\"gray70\", \"darkred\")) +\n  geom_text(vjust = 0, nudge_y = 0.5) +\n  coord_fixed() +\n  ylim(0, 2.5) +\n  theme(legend.position = \"top\") +\n  labs(color = \"Status\")\n\n\n\n\nFigure 15.3: Sequence of diseased (1) or non-diseased (0) units (plants). The numbers represent the position of the unit\n\n\n\n\nWe can obtain the number of runs and related statistics using the oruns.test() function of the r4pde package.\n\nlibrary(r4pde)\noruns.test(row1$y1)\n\n$U\n[1] 7\n\n$EU\n[1] 10.6\n\n$pvalue\n[1] 0.08416615\n\n$result\n[1] \"clustering\"\n\n\n\n\n15.1.1.2 Doublets\nDoublet analysis is used to compare the observed number or adjacent diseased plants, a doublet (DD or 11), to the number expected if the disease were randomly distributed in the field. If the observed number is greater than the expected number, contagion within the field is suspected.\n\n\n\nFigure 15.4: Example for the computation of the number of doublets (DD) in a sequence of binary data\n\n\nThe doublets.test() function of the r4pde package calculates the doublets and associated statistics.\n\ndoublets.test(row1$y1)\n\n$Db\n[1] 4\n\n$EDb\n[1] 2.8\n\n$pvalue\n[1] 0.4496918\n\n$result\n[1] \"randomness\"\n\n\n\n\n15.1.1.3 Foci analysis\nThe Analysis of Foci Structure and Dynamics (AFSD), introduced by (Nelson 1996) and further expanded by (Laranjeira et al. 1998), was used in several studies on citrus diseases in Brazil. In this analysis, the data come from incidence maps where both the diseased and no-diseased trees are mapped in the 2D plane (Jesus Junior and Bassanezi 2004; Laranjeira et al. 2004).\nHere is an example of an incidence map with four foci (adapted from (Laranjeira et al. 1998)). The data is organized in the wide format where the first column x is the index for the row and each column is the position of the plant within the row. The 0 and 1 represent the non-diseased and diseased plant, respectively.\n\nfoci &lt;- tibble::tribble(\n           ~x, ~`1`, ~`2`, ~`3`, ~`4`, ~`5`, ~`6`, ~`7`, ~`8`, ~`9`,\n           1,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           2,   1,   1,   1,   0,   0,   0,   0,   1,   0,\n           3,   1,   1,   1,   0,   0,   0,   1,   1,   1,\n           4,   0,   1,   1,   0,   0,   0,   0,   1,   0,\n           5,   0,   1,   1,   0,   0,   0,   0,   0,   0,\n           6,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n           7,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           8,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           9,   0,   0,   0,   0,   0,   1,   0,   1,   0,\n          10,   0,   0,   0,   0,   0,   0,   1,   0,   0,\n          11,   0,   1,   0,   0,   0,   1,   0,   1,   0,\n          12,   0,   0,   0,   0,   0,   0,   0,   0,   0\n          )\n\nSince the data frame is in the wide format, we need to reshape it to the long format using pivot_longer function of the tidyr package before plotting using ggplot2 package.\n\nlibrary(tidyr)\n\nfoci2 &lt;- foci |&gt; \n  pivot_longer(2:10, names_to = \"y\", values_to = \"i\")\nfoci2\n\n# A tibble: 108 × 3\n       x y         i\n   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n 1     1 1         0\n 2     1 2         0\n 3     1 3         0\n 4     1 4         0\n 5     1 5         0\n 6     1 6         0\n 7     1 7         0\n 8     1 8         0\n 9     1 9         0\n10     2 1         1\n# ℹ 98 more rows\n\n\nNow we can make the plot.\n\nlibrary(ggplot2)\nfoci2 |&gt; \n  ggplot(aes(x, y, fill = factor(i)))+\n  geom_tile(color = \"black\")+\n  scale_fill_manual(values = c(\"grey96\", \"grey20\"))+\n  theme_void()+\n  coord_fixed()+\n  theme(legend.position = \"none\")\n\n\n\n\nFigure 15.5: Examples of foci of plant diseases - see text for description\n\n\n\n\nIn the above plot, the upper left focus is composed of four diseased plants with a pattern of vertical and horizontal proximity to the central unit (or the Rook’s case). The upper right focus, also with four diseased plants denotes a pattern of longitudinal proximity to the central unit (or the Bishop’s case). The lower left focus is composed of 11 diseased plants with 4 rows and 6 columns occupied by the focus; the shape index of the focus (SIF) is 1.25 and the compactness index of the focus (CIF) is 0.55. The lower right is a single-unit focus.\nIn this analysis, several statistics can be summarized, both at the single focus and averaging across all foci in the area, including:\n\nNumber of foci (NF) and number of single focus (NSF)\nTo compare maps with different number of plants, NF and NSF can be normalized to 1000 plants as NF1000 and NSF1000\nNumber of plants in each focus i (NPFi)\nMaximum number of rows of the focus i (rfi) and maximum number of columns of the focus i (cfi)\nMean shape index of foci (meanSIF = [∑(fri / cfi)]/NF), where SIF values equal to 1.0 indicate isodiametrical foci; values greater than 1.0 indicate foci with greater length in the direction between the planting rows and values less than 1 indicate foci with greater length in the direction of the planting row.\nMean compactness index of foci (meanCIF = [∑(NPFi/rfi*cfi)]/NF), where CIF values close to 1.0 indicate a more compact foci, that is, greater aggregation and proximity among all the plants belonging to the focus\n\nWe can obtain the above-mentioned foci statistics using the AFSD function of the r4pde package. Let’s calculate for the foci2 dataset already loaded, but first we need to check whether all variables are numeric or integer.\n\nstr(foci2) # y was not numeric\n\ntibble [108 × 3] (S3: tbl_df/tbl/data.frame)\n $ x: num [1:108] 1 1 1 1 1 1 1 1 1 2 ...\n $ y: chr [1:108] \"1\" \"2\" \"3\" \"4\" ...\n $ i: num [1:108] 0 0 0 0 0 0 0 0 0 1 ...\n\nfoci2$y &lt;- as.integer(foci2$y) # transform to numeric\n\nlibrary(r4pde)\nresult_foci &lt;- AFSD(foci2)\n\nThe AFSD function returns a list of three data frames. The first is a summary statistics of this analysis, together with the disease incidence (DIS_INC), for the data frame in analysis.\n\nknitr::kable(result_foci[[1]])\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n4.0000000\n\n\nNF1000\n37.0370370\n\n\nNSF\n1.0000000\n\n\nNSF1000\n9.2592593\n\n\nDIS_INC\n0.2037037\n\n\nmean_SIF\n1.0625000\n\n\nmean_CIF\n0.6652778\n\n\n\n\n\nThe second object in the list is a data frame with statistics at the focus level, including the number of rows and columns occupied by each focus as well as the two indices for each focus: shape and compactness.\n\nknitr::kable(result_foci[[2]])\n\n\n\n\nfocus_id\nsize\nrows\ncols\nSIF\nCIF\n\n\n\n\n1\n11\n4\n5\n0.8\n0.5500000\n\n\n2\n5\n3\n3\n1.0\n0.5555556\n\n\n3\n5\n3\n3\n1.0\n0.5555556\n\n\n4\n1\n1\n1\n1.0\n1.0000000\n\n\n\n\n\nThe third object is the original data frame amended with the id for each focus which can be plotted and labelled (the focus ID) using the plot_AFSD() function.\n\nfoci_data &lt;- result_foci[[3]]\nDT::datatable(foci_data)\n\n\n\n\n\n\nThe plot shows the ID for each focus.\n\nplot_AFSD(foci_data)+\n  theme_bw()\n\n\n\n\nWe will now analyse an actual data set from the epiphy package. The data describe the incidence of tomato spotted wilt virus (TSWV) disease in field trials. There are two years in the dataset. We will work with the data from 1928 when 6 assessments were made in time. We will first work with time 1 by using filter() function of the dplyr package.\n\nlibrary(epiphy)\ntswv_1928 &lt;- tomato_tswv$field_1928\ndf1 &lt;- tswv_1928 |&gt;\n  filter(t == 1) |&gt; # filter time 1\n  select(x, y, i) # select only three variables\n\nFollows the incidence map of the area at time 1.\n\ndf1 |&gt; \n  ggplot(aes(x, y, fill = factor(i)))+\n  geom_tile(color = \"black\")+\n  theme_void()+\n  scale_fill_grey(start = 0.8, end = 0.2)+\n  coord_fixed()+\n  theme(legend.position = \"none\")\n\n\n\n\nNow we can run the AFSD function and obtain the statistics.\n\nresult_df1 &lt;- AFSD(df1)\n\nknitr::kable(result_df1[[1]])\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n33.0000000\n\n\nNF1000\n17.8571429\n\n\nNSF\n8.0000000\n\n\nNSF1000\n4.3290043\n\n\nDIS_INC\n0.0784632\n\n\nmean_SIF\n1.1482323\n\n\nmean_CIF\n0.7977633\n\n\n\n\n\nThis analysis is usually applied to multiple maps and the statistics are visually related to the incidence in the area in a scatter plot. Let’s calculate the statistics for all five times of the data frame where we will keep now the time variable in the dataframe and split it by time before applying the function. We can do it using the map function of the purrr package.\n\nlibrary(purrr)\n\ndf_all &lt;- tomato_tswv$field_1928\n\n# Split the dataframe by 'time'\ndf_split &lt;- split(df_all, df_all$t)\n\n# Apply the AFSD function to each split dataframe\nresults &lt;- map(df_split, AFSD)\n\nWe can check the summary results for time 2 and time 3.\n\ntime2 &lt;- data.frame(results[[2]][1])\nknitr::kable(time2)\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n2.0000000\n\n\nNF1000\n1.0822511\n\n\nNSF\n0.0000000\n\n\nNSF1000\n0.0000000\n\n\nDIS_INC\n0.2364719\n\n\nmean_SIF\n1.7121212\n\n\nmean_CIF\n1.1352814\n\n\n\n\ntime3 &lt;- data.frame(results[[3]][1])\nknitr::kable(time3)\n\n\n\n\nstats\nvalue\n\n\n\n\nNF\n1.0000000\n\n\nNF1000\n0.5411255\n\n\nNSF\n0.0000000\n\n\nNSF1000\n0.0000000\n\n\nDIS_INC\n0.4085498\n\n\nmean_SIF\n0.4242424\n\n\nmean_CIF\n1.6341991\n\n\n\n\n# Plot the results to see the two foci in time 1\nplot_AFSD(results[[1]][[3]])+\n  theme_void()+\n  coord_fixed()\n\n\n\n# Plot time 2\nplot_AFSD(results[[2]][[3]])+\n  theme_void()+\n  coord_fixed()\n\n\n\n\n\n\n15.1.1.4 Join count\nIn this analysis, two adjacent plants may be classified by the type of join that links them: D-D, H-H or H-D. The orientation(s) of interest (along rows, across rows, diagonally, or a a combination o these) should be specified in the test. The number of joins of the specified type in the orientation(s) of interest is then counted. The question is whether the observed join-count is large (or small) relative to that expected for a random pattern. The join-count statistics provides a basic measure of spatial autocorrelation.\nIn R, we can use the join.count() function of the spdep package to perform a joint count test. First, we need to create the series of binary data from top to bottom and left to right. The data are shown in Fig. 9.13 in page 260 of the book chapter on spatial analysis (Madden et al. 2017a). In the example, there are 5 rows and 5 columns. This will be informed later to run the test.\n\nS2 &lt;- c(1,0,1,1,0,\n       1,1,0,0,0,\n       1,0,1,0,0,\n       1,0,0,1,0,\n       0,1,0,1,1)\n\nVisualize the two-dimensional array:\n\n# Convert to raster \nmapS2 &lt;- terra::rast(matrix(S2, 5 , 5))\n# Convert to data frame\nmapS3 &lt;- terra::as.data.frame(mapS2, xy = TRUE)\nmapS3 |&gt;\n  ggplot(aes(x, y, label = lyr.1, fill = factor(lyr.1))) +\n  geom_tile(color = \"white\", size = 0.5) +\n  theme_void() +\n  labs(fill = \"Status\") +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\"))+\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.6: Visualization of a matrix of presence or absence data representing a disease spatial pattern\n\n\n\n\nAfter loading the library, we need to generate a list of neighbors (nb) for a grid of cells. This is performed with the cell2nb() function by informing the number of rows and columns. The argument rook means shared edge, but it could be the queen, for shared edge or vertex. We can use the default.\n\nlibrary(spdep)\nnb &lt;- cell2nb(nrow = 5,\n              ncol = 5,\n              type = \"rook\")\n\nThe joincount.test() function runs the BB join count test for spatial autocorrelation. The method uses a spatial weights matrix in weights list form for testing whether same-status joins occur more frequently than would be expected if the zones were labelled in a spatially random way. We need to inform the sequence as factor and the nb object we created previously.\n\njoincount.test(factor(S2), \n                nb2listw(nb))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 0 = -0.58266, p-value = 0.7199\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.9583333             3.2500000             0.2505797 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 1 = -0.66841, p-value = 0.7481\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.4166667             2.7500000             0.2486957 \n\n\nThe function returns a list with a class for each of the status (in this case 0 and 1) with several components. We should look at the P-value. The alternative hypothesis (greater) is that the same status joins occur more frequently than expected if they were labelled in a spatial random way. In this case, we do not reject the null hypothesis of randomness.\nWe can run the ordinary runs and doublets tests, which only considers the adjacent neighbor, for the same series and compare the results.\n\noruns.test(S2)\n\n$U\n[1] 17\n\n$EU\n[1] 13.48\n\n$pvalue\n[1] 0.1496727\n\n$result\n[1] \"clustering\"\n\ndoublets.test(S2)\n\n$Db\n[1] 3\n\n$EDb\n[1] 5.28\n\n$pvalue\n[1] 0.3009097\n\n$result\n[1] \"randomness\"\n\n\nLet’s repeat the procedure using the second array of data shown in the book chapter, for which the result is different. In this case, there is evidence to reject the null hypothesis, indicating aggregation of plants.\n\nS3 &lt;- c(1,1,1,0,0,\n       1,1,1,0,0,\n       1,1,1,0,0,\n       1,1,1,0,0,\n       0,0,0,0,0)\n\njoincount.test(factor(S3), \n                nb2listw(nb))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb) \n\nStd. deviate for 0 = 4.2451, p-value = 1.093e-05\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            5.3750000             3.2500000             0.2505797 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb) \n\nStd. deviate for 1 = 4.5953, p-value = 2.16e-06\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            5.0416667             2.7500000             0.2486957 \n\noruns.test(S3)\n\n$U\n[1] 8\n\n$EU\n[1] 13.48\n\n$pvalue\n[1] 0.02490392\n\n$result\n[1] \"clustering\"\n\n\nWe can apply these tests for a real example epidemic data provided by the epiphy R package (Gigot 2018). Let’s work with part of the intensively mapped data on the incidence of tomato spotted wilt virus (TSWV) disease in field trials reported by Cochran (1936) and Bald (1937). First, we need to load the library and then assign one dataframe (the dataset has two dataframes) of the dataset tomato_tswv to a new dataframe called tswv_1929.\n\nlibrary(epiphy)\ntswv_1929 &lt;- tomato_tswv$field_1929\ntswv_1929 |&gt;  head(10) \n\n   x  y t i n\n1  1  1 1 0 1\n2  1  2 1 1 1\n3  1  3 1 0 1\n4  1  4 1 1 1\n5  1  5 1 0 1\n6  1  6 1 0 1\n7  1  7 1 0 1\n8  1  8 1 0 1\n9  1  9 1 1 1\n10 1 10 1 0 1\n\n\nThe inspection of the first 10 rows of the dataframe shows five variables where x and y are spatial grid coordinates, t is assessment time, i is the status of the plant (0 = healthy, 1 = diseased) and n is the sampling unit size (here all one). Let’s visualize these data for each sampling time.\n\ntswv_1929 |&gt;\n  ggplot(aes(x, y, fill = factor(i))) +\n  geom_tile() +\n  coord_fixed() +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\")) +\n  facet_wrap( ~ t) +\n  labs(fill = \"Status\")+\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.7: Incidence maps for for tomato spotted wilt virus (TSWV) disease in field trials reported by Cochran (1936) and Bald (1937)\n\n\n\n\nCheck the number of rows (y) and columns (x) for further preparing the neighbor object for the join count statistics.\n\ntswv_1929 |&gt; \n  dplyr::select(x, y) |&gt; \n  summary()\n\n       x               y        \n Min.   : 1.00   Min.   : 1.00  \n 1st Qu.: 6.75   1st Qu.:15.75  \n Median :12.50   Median :30.50  \n Mean   :12.50   Mean   :30.50  \n 3rd Qu.:18.25   3rd Qu.:45.25  \n Max.   :24.00   Max.   :60.00  \n\n\nThere are 60 rows and 24 columns.\n\n# Neighbor grid\nnb1 &lt;- cell2nb(nrow = 60,\n               ncol = 24,\n               type = \"rook\")\n\n# Pull the binary sequence of time 1\nS1 &lt;- tswv_1929 |&gt;\n  filter(t == \"1\") |&gt;\n  pull(i)\n\njoincount.test(factor(S1),\n               nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S1) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = -0.28351, p-value = 0.6116\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n           482.000000            482.578874              4.169132 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S1) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = -0.059497, p-value = 0.5237\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            23.458333             23.578874              4.104614 \n\n\nWe can apply the join count test for time 2 and time 3. Results show that the pattern changes from random to aggregate over time.\n\n# Pull the binary sequence of time 1\nS2 &lt;- tswv_1929 |&gt;\n  filter(t == \"2\") |&gt;\n  pull(i)\n\njoincount.test(factor(S2),\n               nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = 0.35872, p-value = 0.3599\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n           317.000000            315.900625              9.392312 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = 0.34604, p-value = 0.3647\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            82.958333             81.900625              9.342754 \n\n# Pull the binary sequence of time 1\nS3 &lt;- tswv_1929 |&gt;\n  filter(t == \"3\") |&gt;\n  pull(i)\n\njoincount.test(factor(S3), \n                nb2listw(nb1))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb1) \n\nStd. deviate for 0 = 1.8541, p-value = 0.03186\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            136.12500             129.92773              11.17243 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S3) \nweights: nb2listw(nb1) \n\nStd. deviate for 1 = 1.7275, p-value = 0.04204\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            243.70833             237.92773              11.19743 \n\n\n\n\n\n15.1.2 Point pattern analysis\nPoint pattern analysis is the study of the spatial arrangements of points in a 2-D space. The easiest way to visualize a 2-D point pattern is to produce a map of the locations, which is simply a scatterplot but with the provision that the axes are equally scaled.\nLet’s work with a real epidemic data where the presence of banana plants displaying the symptoms of Fusarium wilt was determined in fields across several regions in Brazil (Heck et al. 2021). On each field, the location of each symptomatic plant was geolocated using a GPS together with the coordinates of the four corners of the field. Let’s load the data from the web and assign them to a data frame called fw (Fusarium wilt).\n\nfw &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/fusarium_banana.csv\")\n\nBecause we using a coordinate system, we need to convert the data to meters.\n\n#|warning: false\n\n# Convert to meters \nlibrary(sp)\ncoordinates(fw) &lt;- c(\"lon\", \"lat\")\nproj4string(fw) &lt;- CRS(\"+proj=longlat +datum=WGS84\")\nfw &lt;- spTransform(fw, CRS(\"+proj=utm +zone=22 ellps=WGS84\"))\nfw &lt;- data.frame(fw)\n\nAs shown above, the fw dataframe has five variables. The marker indicates weather the point is a plant or one of the four limits of the polygon. The field variable is the number of the field. Let’s produce 2-D map.\n\nfw %&gt;% \n  ggplot(aes(lat, lon, color = marker))+\n  geom_polygon(data = fw, aes(lat, lon, group = marker), fill = \"white\",  color=\"grey\")+\n  geom_point()+\n  scale_color_manual(values = c(\"black\", NA))+\n  coord_map()+\n  coord_flip()+\n  theme_void()+\n  theme(legend.position = \"none\")+\n  labs (title = \"Fusarium wilt incidence map\", \n        subtitle = \"Field 11\", \n        x = \"Latitude\",\n        y = \"Longitude\",\n        caption = \"Source: Heck et al. (2021)\")\n\n\n\n\n\n15.1.2.1 Quadrat based\nQuadrat count analysis\n\nlibrary(spatstat)\n### Create window \nwindow_fw &lt;- ripras(fw$lon, fw$lat)\n\n# create the point pattern object\nppp_fw &lt;- ppp(fw$lon, fw$lat, window_fw)\nplot(ppp_fw)\n\n\n\n## Quadrat count 10 x 10\nqq &lt;- quadratcount(ppp_fw,8,8, keepempty=TRUE) \n\n# plot the quadrat count\nplot(qq)\n\n\n\n# Quadrat test\nqt &lt;- quadrat.test(qq, alternative=\"clustered\", method=\"M\")\nqt\n\n\n    Conditional Monte Carlo test of CSR using quadrat counts\n    Test statistic: Pearson X2 statistic\n\ndata:  \nX2 = 132.76, p-value = 0.001\nalternative hypothesis: clustered\n\nQuadrats: 60 tiles (irregular windows)\n\n\n\n\n15.1.2.2 Spatial KS test\nPerforms a test of goodness-of-fit test of the uniform Poisson point process (Complete Spatial Randomness, CSR) for the data set.The test is performed by comparing the observed distribution of the values of a spatial covariate at the data points, and the predicted distribution of the same covariate under the model, using a classical goodness-of-fit test Baddeley et al. (2005). Thus, we must nominate a spatial covariate for this test. In the case below we nominate x, y or x and y as covariate.\n\n# y as covariate\nks_y &lt;- cdf.test(ppp_fw, test=\"ks\", \"y\", jitter=FALSE)\nks_y\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'y' evaluated at points of 'ppp_fw' \n     and transformed to uniform distribution under CSR\nD = 0.056002, p-value = 0.6862\nalternative hypothesis: two-sided\n\nplot(ks_y)\n\n\n\n# x as covariate\nks_x &lt;- cdf.test(ppp_fw, test=\"ks\", \"x\", jitter=FALSE)\nks_x\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'x' evaluated at points of 'ppp_fw' \n     and transformed to uniform distribution under CSR\nD = 0.10115, p-value = 0.07118\nalternative hypothesis: two-sided\n\nplot(ks_x)\n\n\n\n# x and y as covariates\nfun &lt;- function(x,y){2* x + y}\nks_xy &lt;- cdf.test(ppp_fw, test=\"ks\", fun, jitter=FALSE)\nks_xy\n\n\n    Spatial Kolmogorov-Smirnov test of CSR in two dimensions\n\ndata:  covariate 'fun' evaluated at points of 'ppp_fw' \n     and transformed to uniform distribution under CSR\nD = 0.093067, p-value = 0.1188\nalternative hypothesis: two-sided\n\nplot(ks_xy)\n\n\n\n\nAs shown above, we do not have sufficient evidence to reject the null hypothesis of complete spatial randomness.\n\n\n15.1.2.3 Distance based\nA spatial point process is a set of irregularly distributed locations within a defined region which are assumed to have been generated by some form of stochastic mechanism.\nThe K function, a.k.a. Ripley’s K-function, is a statistical measure used in spatial analysis to examine the spatial distribution of a single type of point in a given area. Named after its developer, the British statistician B.D. Ripley, the K-function measures the expected number of points within a given distance of an arbitrary point, assuming homogeneous intensity (a constant probability of a point occurring in a particular place).\nTo describe it simply: imagine you have a map of diseased trees in a forest, and you select a tree at random. The K-function helps you answer the question: “How many other diseased trees do I expect to find within a certain distance from the diseased tree I’ve chosen?”\nThe K-function is often used to identify and analyze patterns within spatial data, such as clustering, randomness, or regularity (dispersion). It is particularly useful because it looks at the distribution at all scales (distances) simultaneously. To interpret the results of Ripley’s K-function:\n\nRandom distribution: If the points (like trees in our example) are randomly distributed, the plot of the K-function will be a straight line at a 45-degree angle.\nClustered distribution: If the points are clustered (grouped closer together than you’d expect by chance), the plot will be above the 45-degree line of the random expectation.\nRegular or dispersed distribution: If the points are regularly spaced or dispersed (further apart than you’d expect by chance), the plot will be below the 45-degree line.\n\nRipley’s K checks the density of diseased units in each area by the variance as a function of radial distances (r) from the diseased unit, hence K(r). If the spatial localization of a diseased unit is independent, the process is random in space.\nLet’s use the Kest function of the spatstat package to obtain K(r).\n\nk &lt;- Kest(ppp_fw)\nplot(k)\n\n\n\n\nThe envelope function performs simulations and computes envelopes of a summary statistic based on the simulations. The envelope can be used to assess the goodness-of-fit of a point process model to point pattern data (Baddeley et al. 2014). Let’s simulate the envelope and plot the values using ggplot. Because observed K(r) (solid line) lied outside the simulation envelope, aggregation was detected.\n\nke &lt;- envelope(ppp_fw, fun = Kest)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\ndata.frame(ke) |&gt; \n  ggplot(aes(r, theo))+\n  geom_line(linetype =2)+\n  geom_line(aes(r, obs))+\n  geom_ribbon(aes(ymin = lo, ymax = hi),\n              fill = \"steelblue\", alpha = 0.5)+\n  labs(y = \"K(r)\", x = \"r\")+\n  theme_bw(base_size = 16)\n\n\n\n\nmad.test performs the ‘global’ or ‘Maximum Absolute Deviation’ test described by Ripley (1977, 1981). See (Baddeley et al. 2014). This performs hypothesis tests for goodness-of-fit of a point pattern data set to a point process model, based on Monte Carlo simulation from the model.\n\n# Maximum absolute deviation test\nmad.test(ppp_fw, Kest)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\n    Maximum absolute deviation test of CSR\n    Monte Carlo test based on 99 simulations\n    Summary function: K(r)\n    Reference function: theoretical\n    Alternative: two.sided\n    Interval of distance values: [0, 41.7189302890329]\n    Test statistic: Maximum absolute deviation\n    Deviation = observed minus theoretical\n\ndata:  ppp_fw\nmad = 433.73, rank = 2, p-value = 0.02\n\n\nAnother statistics that can be used is the O-ring statitics which are used in spatial analysis to quantify and test the degree of interaction between two types of spatial points (Wiegand and A. Moloney 2004). The name derives from the method of placing a series of concentric circles (O-rings) around each point of type 1 and counting how many points of type 2 fall within each ring. The plot generated by O-ring statistics is called an O-ring plot or an O-function plot. It plots the radius of the rings on the x-axis and the estimated intensity of points of type 2 around points of type 1 on the y-axis.\nInterpreting the plot is as follows:\n\nRandom pattern: If points of type 2 are randomly distributed around points of type 1, the O-ring plot will be a flat line. This means that the intensity of points of type 2 does not change with the distance to points of type 1.\nAggregation or clustering: If points of type 2 are aggregated around points of type 1, the O-ring plot will be an upward-sloping curve. This indicates that the intensity of points of type 2 increases with proximity to points of type 1.\nDispersion: If points of type 2 are dispersed away from points of type 1, the O-ring plot will be a downward-sloping curve. This shows that the intensity of points of type 2 decreases as you get closer to points of type 1.\n\nThe O-ring plot often includes a confidence envelope. If the O-ring statistic falls within this envelope, it suggests that the observed pattern could be the result of random spatial processes. If it falls outside the envelope, it suggests that the pattern is not random. Therefore, to decide whether a pattern is aggregated or random using O-ring statistics:\n\nLook at the shape of the O-ring plot.\nCompare the O-ring statistic to the confidence envelope.\n\nAn aggregated pattern will show an increasing curve that lies outside the confidence envelope, indicating that the density of type 2 points is higher close to type 1 points. On the other hand, a random pattern will show a flat line that lies within the confidence envelope, indicating no significant difference in the density of type 2 points around type 1 points at varying distances.\nIn R, we can use the estimate_o_ring() function of the onpoint package. We will use the point pattern object ppp_fw used in the previous examples\n\nlibrary(onpoint)\nplot(estimate_o_ring(ppp_fw))\n\n\n\n\nThe function can be used in combination with spatstat's envelope() function.\n\noring_envelope &lt;- envelope(ppp_fw, fun = estimate_o_ring, nsim = 199, verbose = FALSE)\nplot(oring_envelope)\n\n\n\n\nTo plot simulation envelopes using quantum plots (Esser et al. 2014), just pass an envelope object as input to plot_quantums().\n\nplot_quantums(oring_envelope, ylab = \"O-ring\")\n\n\n\n\nFinally, the ‘Maximum Absolute Deviation’ test can be used in combination with the function.\n\nmad.test(ppp_fw, fun = estimate_o_ring)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\nWarning in envelopeTest(X, ..., exponent = Inf, alternative = alternative, :\nSome function values were infinite, NA or NaN at distance r = 0; lower limit of\nr interval was reset to 0.0814822857207673 units\n\n\n\n    Maximum absolute deviation test of CSR\n    Monte Carlo test based on 99 simulations\n    Summary function: g(r) * lambda\n    Reference function: theoretical\n    Alternative: two.sided\n    Interval of distance values: [0.0814822857207673, 41.7189302890329]\n    Test statistic: Maximum absolute deviation\n    Deviation = observed minus theoretical\n\ndata:  ppp_fw\nmad = 0.12315, rank = 1, p-value = 0.01\n\n\n\n\n\n15.1.3 Grouped data\nIf the data are intensively mapped, meaning that the spatial locations of the sampling units are known, we are not limited to analyse presence/absence (incidence) only data at the unit level. The sampling units may be quadrats where the total number of plants and the number of disease plants (or number of pathogen propagules) are known. Alternatively, it could be a continuous measure of severity. The question here, similar to the previous section, is whether a plant being diseased makes it more (or less) likely that neighboring plants will be diseased. If that is the case, diseased plants are exhibiting spatial autocorrelation. The most common methods are autocorrelation (known as Moran’s I), semivariance and SADIE (an alternative approach to autocorrelation.)\n\n15.1.3.1 Autocorrelation\nSpatial autocorrelation analysis provides a quantitative assessment of whether a large value of disease intensity in a sampling unit makes it more (positive autocorrelation) or less (negative auto- correlation) likely that neighboring sampling units tend to have a large value of disease intensity (Madden et al. 2017a).\nWe will illustrate the method by reproducing the example provided in page 264 of the chapter on spatial analysis (Madden et al. 2017a), which was extracted from table 11.3 of Campbell and Madden. L. (1990). The data represent a single transect with the number of Macrophomia phaseolina propagules per 10 g air-dry soil recorded in 16 contiguous quadrats across a field.\n\nmp &lt;- data.frame(\n  i = c(1:16),\n  y = c(41, 60, 81, 22, 8, 20, 28, 2, 0, 2, 2, 8, 0, 43, 61, 50)\n)\nmp\n\n    i  y\n1   1 41\n2   2 60\n3   3 81\n4   4 22\n5   5  8\n6   6 20\n7   7 28\n8   8  2\n9   9  0\n10 10  2\n11 11  2\n12 12  8\n13 13  0\n14 14 43\n15 15 61\n16 16 50\n\n\nWe can produce a plot to visualize the number of propagules across the transect.\n\nmp |&gt;\n  ggplot(aes(i, y)) +\n  geom_col(fill = \"darkred\") +\n  labs(\n    x = \"Relative position within a transect\",\n    y = \"Number of propagules\",\n    caption = \"Source: Campbell and Madden (1990)\"\n  )\n\n\n\n\nFigure 15.8: Number of propagules of Macrophomina phaseolina in the soil at various positions within a transect\n\n\n\n\nTo calculate the autocorrelation coefficient in R, we can use the ac() function of the tseries package.\n\nlibrary(tseries)\nac_mp &lt;- acf(mp$y, lag = 5, pl = FALSE)\nac_mp\n\n\nAutocorrelations of series 'mp$y', by lag\n\n     0      1      2      3      4      5 \n 1.000  0.586  0.126 -0.033 -0.017 -0.181 \n\n\nLet’s store the results in a data frame to facilitate visualization.\n\nac_mp_dat &lt;- data.frame(index = ac_mp$lag, ac_mp$acf)\nac_mp_dat\n\n  index   ac_mp.acf\n1     0  1.00000000\n2     1  0.58579374\n3     2  0.12636306\n4     3 -0.03307249\n5     4 -0.01701392\n6     5 -0.18092810\n\n\nAnd now the plot known as autocorrelogram.\n\nac_mp_dat |&gt;\n  ggplot(aes(index, ac_mp.acf, label = round(ac_mp.acf, 3))) +\n  geom_col(fill = \"darkred\") +\n  geom_text(vjust = 0, nudge_y = 0.05) +\n  scale_x_continuous(n.breaks = 6) +\n  geom_hline(yintercept = 0) +\n  labs(x = \"Distance lag\", y = \"Autocorrelation coefficient\")\n\n\n\n\nFigure 15.9: Autocorrelogram for the spatial distribution of Macrophomina phaseolina in soil\n\n\n\n\nThe values we obtained here are not the same but quite close to the values reported in Madden et al. (2017b). For the transect data, the calculated coefficients in the book example for lags 1, 2 and 3 are 0.625, 0.144, and - 0.041. The conclusion is the same, the smaller the distance between sampling units, the stronger is the correlation between the count values.\nThe method above is usually referred to Moran’s I (Moran 1950). Let’s use another example dataset from the book to calculate the Moran’s I in R. The data is shown in page 269 of the book. The data represent the number of diseased plants per quadrat (out of a total of 100 plants in each) in 144 quadrats. It was based on an epidemic generated using the stochastic simulator of Xu and Madden (2004). The data is stored in a CSV file.\n\nepi &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/epidemiology-R/main/data/xu-madden-simulated.csv\")\nepi1 &lt;- epi |&gt;\n  pivot_longer(2:13,\n               names_to = \"y\",\n               values_to = \"n\") |&gt;\n  pull(n)\n\nUsing moran() function of the spdep R package.\n\nset.seed(100)\nlibrary(spdep)\n\nThe cell2nb() function creates the neighbor list with 12 rows and 12 columns, which is how the 144 quadrats are arranged.\n\nnb &lt;- cell2nb(12, 12, type = \"queen\", torus = FALSE)\n\nThe nb2listw() function supplements a neighbors list with spatial weights for the chosen coding scheme. We use the default W, which is the row standardized (sums over all links to n). We then create the col.W neighbor list.\n\ncol.W &lt;- nb2listw(nb, style = \"W\")\n\nThe Moran’s I statistic is given by the moran() function\n\nmoran(x = epi1, # numeric vector\n      listw = col.W, # the nb list\n      n = 12, # number of zones\n      S0 = Szero(col.W)) # global sum of weights\n\n$I\n[1] 0.05818595\n\n$K\n[1] 2.878088\n\n\nThe Moran’s test for spatial autocorrelation uses spatial weights matrix in weights list form.\n\nmoran.test(x = epi1, \n           listw = col.W)\n\n\n    Moran I test under randomisation\n\ndata:  epi1  \nweights: col.W    \n\nMoran I statistic standard deviate = 15.919, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.698231416      -0.006993007       0.001962596 \n\n\n\ncorrel_I &lt;- sp.correlogram(nb, epi1, \n                           order = 10,\n                           method = \"I\",  \n                           zero.policy = TRUE)\n\nWe can generate a correlogram using the output of the sp.correlogram() function. Note that the figure below is very similar to the one shown in Figure 91.5 in page 269 of the book chapter (Madden et al. 2017a). Let’s store the results in a dataframe.\n\ndf_correl &lt;- data.frame(correl_I$res) |&gt; \n  mutate(lag = c(1:10))\n\n# Show the spatial autocorrelation for 10 distance lags\nround(df_correl$X1,3)\n\n [1]  0.698  0.340  0.086 -0.002 -0.009 -0.024 -0.090 -0.180 -0.217 -0.124\n\n\nThen, we can generate the plot using ggplot.\n\ndf_correl |&gt;\n  ggplot(aes(lag, X1)) +\n  geom_col(fill = \"darkred\") +\n  scale_x_continuous(n.breaks = 10) +\n  labs(x = \"Distance lag\", y = \"Spatial autocorrelation\")\n\n\n\n\nFigure 15.10: Autocorrelogram for the spatial distribution of simulated epidemics\n\n\n\n\n\n\n15.1.3.2 Semivariance\nSemi-variance is a key quantity in geostatistics. This differs from spatial autocorrelation because distances are usually measured in discrete spatial lags. The semi-variance can be defined as half the variance of the differences between all possible points spaced a constant distance apart.\nThe semi-variance at a distance d = 0 will be zero, because there are no differences between points that are compared to themselves. However, as points are compared to increasingly distant points, the semi-variance increases. At some distance, called the Range, the semi-variance will become approximately equal to the variance of the whole surface itself. This is the greatest distance over which the value at a point on the surface is related to the value at another point. In fact, when the distance between two sampling units is small, the sampling units are close together and, usually, variability is low. As the distance increases, so (usually) does the variability.\nResults of semi-variance analysis are normally presented as a graphical plot of semi-variance against distance, which is referred to as a semi-variogram. The main characteristics of the semi-variogram of interest are the nugget, the range and the sill, and their estimations are usually based on an appropriate (non-linear) model fitted to the data points representing the semi-variogram.\nFor the semi-variance, we will use the variog() function of the geoR package. We need the data in the long format (x, y and z). Let’s reshape the data to the long format and store it in epi2 dataframe.\n\nepi2 &lt;- epi |&gt;\n  pivot_longer(2:13,\n               names_to = \"y\",\n               values_to = \"n\") |&gt;\n  mutate(y = as.numeric(y))\n\nhead(epi2)\n\n# A tibble: 6 × 3\n      x     y     n\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     2\n2     1     2     2\n3     1     3     3\n4     1     4    33\n5     1     5     4\n6     1     6     0\n\n\n\nlibrary(geoR)\n# the coordinates are x and y and the data is the n\nv1 &lt;- variog(coords = epi2[,1:2], data = epi2[,3])\n\nvariog: computing omnidirectional variogram\n\n\n\nv2 &lt;- variofit(v1, ini.cov.pars = c(1200, 12), \n               cov.model = \"exponential\", \n               fix.nugget = F)\n\nvariofit: covariance model used is exponential \nvariofit: weights used: npairs \nvariofit: minimisation function used: optim \n\n# Plotting \nplot(v1, xlim = c(0,15))\nlines(v2, lty = 1, lwd = 2)\n\n\n\n\nFigure 15.11: Semivariance plot for the spatial distribution simulated epidemic\n\n\n\n\n\n\n15.1.3.3 SADIE\nSADIE (spatial analysis by distance indices) is an alternative to autocorrelation and semi-variance methods described previously, which has found use in plant pathology (Madden et al. 2017a; Xu and Madden 2004; Li et al. 2011). Similar to those methods, the spatial coordinates for the disease intensity (count of diseased individuals) or pathogen propagules values should be provided.\nSADIE quantifies spatial pattern by calculating the minimum total distance to regularity. That is, the distance that individuals must be moved from the starting point defined by the observed counts to the end point at which there is the same number of individuals in each sampling unit. Therefore, if the data are highly aggregated, the distance to regularity will be large, but if the data are close to regular to start with, the distance to regularity will be smaller.\nThe null hypothesis to test is that the observed pattern is random. SADIE calculates an index of aggregation (Ia). When this is equal to 1, the pattern is random. If this is greater than 1, the pattern is aggregated. Hypothesis testing is based on the randomization procedure. The null hypothesis of randomness, with an alternative hypothesis of aggregation.\nAn extension was made to quantify the contribution of each sampling unit count to the observed pattern. Regions with large counts are defined as patches and regions with small counts are defined as gaps. For each sampling unit, a clustering index is calculated and can be mapped.\nIn R, we can use the sadie() function of the epiphy package (Gigot 2018). The function computes the different indices and probabilities based on the distance to regularity for the observed spatial pattern and a specified number of random permutations of this pattern. To run the analysis, the dataframe should have only three columns: the first two must be the x and y coordinates and the third one the observations. Let’s continue working with the simulated epidemic dataset named epi2. We can map the original data as follows:\n\nepi2 |&gt;\n  ggplot(aes(x, y, label = n, fill = n)) +\n  geom_tile() +\n  geom_text(size = 5, color = \"white\") +\n  theme_void() +\n  coord_fixed() +\n  scale_fill_gradient(low = \"gray70\", high = \"darkred\")\n\n\n\n\nFigure 15.12: Spatial map for the number of diseased plants per quadrat (n = 144) in simulated epidemic\n\n\n\n\n\nlibrary(epiphy)\nsadie_epi2 &lt;- sadie(epi2)\n\nComputation of Perry's indices:\n\nsadie_epi2\n\nSpatial Analysis by Distance IndicEs (sadie)\n\nCall:\nsadie.data.frame(data = epi2)\n\nIa: 2.4622 (Pa = &lt; 2.22e-16)\n\n\nThe simple output shows the Ia value and associated P-value. As suggested by the low value of the P-value, the pattern is highly aggregated. The summary() function provides a more complete information such as the overall inflow and outflow measures. A dataframe with the clustering index for each sampling unit is also provided using the summary() function.\n\nsummary(sadie_epi2)\n\n\nCall:\nsadie.data.frame(data = epi2)\n\nFirst 6 rows of clustering indices:\n  x y  i cost_flows      idx_P idx_LMX prob\n1 1 1  2 -11.382725 -7.2242617      NA   NA\n2 1 2  2  -9.461212 -6.2258877      NA   NA\n3 1 3  3  -7.299482 -5.3390880      NA   NA\n4 1 4 33   1.000000  0.8708407      NA   NA\n5 1 5  4  -5.830952 -3.6534511      NA   NA\n6 1 6  0  -5.301329 -2.9627172      NA   NA\n\nSummary indices:\n                      overall    inflow  outflow\nPerry's index        2.495346 -2.811023 2.393399\nLi-Madden-Xu's index       NA        NA       NA\n\nMain outputs:\nIa: 2.4622 (Pa = &lt; 2.22e-16)\n\n'Total cost': 201.6062\nNumber of permutations: 100\n\n\nThe plot() function allows to map the clustering indices and so to identify regions of patches (red, outflow) and gaps (blue, inflow).\n\nplot(sadie_epi2)\n\n\n\n\nFigure 15.13: Map of the SADIE clustering indices where red identifiy patches (outflow) and blue identify gaps (inflow)\n\n\n\n\nA isocline plot can be obtained by setting the isocline argument as TRUE.\n\nplot(sadie_epi2, isoclines = TRUE)\n\n\n\n\nFigure 15.14: Map of the SADIE clustering indices"
  },
  {
    "objectID": "spatial-tests.html#sparsely-sampled-data",
    "href": "spatial-tests.html#sparsely-sampled-data",
    "title": "15  Tests for patterns",
    "section": "15.2 Sparsely sampled data",
    "text": "15.2 Sparsely sampled data\nDifferent from intensively mapped data, sparsely sampled data do not contain information about the spatial location of the units, and so it is not taken into account in the analysis. The analysis of sparsely sampled data usually involves characterizing the extent of variability in the mean level of disease intensity per sampling unit (Madden et al. 2017a). There are two types of approaches to analyse these data in the context of spatial patterns of plant disease epidemics: 1) testing the goodness of fit to statistical probability distributions and 2) calculating indices of aggregation. These will be discussed further separated depending on the nature of the data, whether count or incidence (proportion), for which specific distributions are assumed to describe the data.\n\n15.2.1 Count data\n\n15.2.1.1 Fit to distributions\nTwo statistical distributions can be adopted as reference for the description of random or aggregated patterns of disease data in the form of counts of infection within sampling units. Take the count of lesions on a leaf, or the count of diseased plants on a quadrat, as an example. If the presence of a lesion/diseased plant does not increase or decrease the chance that other lesions/diseased plants will occur, the Poisson distribution describes the distribution of lesions on the leaf. Otherwise, the negative binomial provides a better description.\nLet’s work with the previous simulation data of 144 quadrats with a variable count of diseased plants per quadrat (in a maximum of 100). Notice that we won’t consider the location of each quadrat as in the previous analyses of intensively mapped data. We only need the vector with the number of infected units per sampling unit.\nThe epiphy package provides a function called fit_two_distr(), which allows fitting these two distribution for count data. In this case, either randomness assumption (Poisson distributions) or aggregation assumption (negative binomial) are made, and then, a goodness-of-fit comparison of both distributions is performed using a log-likelihood ratio test. The function requires a dataframe created using the count() function where the number of infection units is designated as i. It won’t work with a single vector of numbers. We create the dataframe using:\n\ndata_count &lt;- epi2 |&gt; \n  mutate(i = n) |&gt;  # create i vector\n  epiphy::count()   # create the map object of count class\n\nWe can now run the function that will look fo the the vector i. The function returns a list of four components including the outputs of the fitting process for both distribution and the result of the log-likelihood ratio test, the llr.\n\nfit_data_count &lt;- fit_two_distr(data_count)\nsummary(fit_data_count)\n\nFitting of two distributions by maximum likelihood\nfor 'count' data.\nParameter estimates:\n\n(1) Poisson (random):\n       Estimate  Std.Err Z value    Pr(&gt;z)    \nlambda 27.85417  0.43981  63.333 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(2) Negative binomial (aggregated):\n       Estimate    Std.Err Z value    Pr(&gt;z)    \nk     0.6327452  0.0707846  8.9390 &lt; 2.2e-16 ***\nmu   27.8541667  2.9510198  9.4388 &lt; 2.2e-16 ***\nprob  0.0222118  0.0033463  6.6378 3.184e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nfit_data_count$llr\n\nLikelihood ratio test\n\n               LogLik Df  Chisq Pr(&gt;Chisq)    \nrandom :     -2654.71                         \naggregated :  -616.51  1 4076.4  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe very low value of the P-value of the LLR test suggest that the negative binomial provides a better fit to the data. The plot() function allows for visualizing the expected random and aggregated frequencies together with the observed frequencies. The number of breaks can be adjusted as indicated.\n\nplot(fit_data_count, breaks = 5) \n\n\n\n\nFigure 15.15: Frequencies of the observed and expected aggregated and random distributions\n\n\n\n\nSee below another way to plot by extracting the frequency data (and pivoting from wide to long format) from the generated list and using ggplot. Clearly, the negative binomial is a better description for the observed count data.\n\ndf &lt;- fit_data_count$freq |&gt;\n  pivot_longer(2:4, \"pattern\", \"value\")\n\ndf |&gt;\n  ggplot(aes(category, value, fill = pattern)) +\n  geom_col(position = \"dodge\", width = 2) +\n  scale_fill_manual(values = c(\"gray70\", \"darkred\", \"steelblue\")) +\n  theme(legend.position = \"top\")\n\n\n\n\nFigure 15.16: Frequencies of the observed and expected aggregated and random distributions\n\n\n\n\n\n\n15.2.1.2 Aggregation indices\n\nidx &lt;- agg_index(data_count, method = \"fisher\")\nidx\n\nFisher's index of dispersion:\n(Version for count data)\n34.25\n\nchisq.test(idx)\n\n\n    Chi-squared test for (N - 1)*index following a chi-squared\n    distribution (df = N - 1)\n\ndata:  idx\nX-squared = 4897.2, df = 143, p-value &lt; 2.2e-16\n\nz.test(idx)\n\n\n    One-sample z-test\n\ndata:  idx\nz = 82.085, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n# Lloyd index\n\nidx_lloyd &lt;- agg_index(data_count, method = \"lloyd\")\nidx_lloyd\n\nLloyd's index of patchiness:\n2.194\n\nidx_mori &lt;- agg_index(data_count, method = \"morisita\")\nidx_mori\n\nMorisita's coefficient of dispersion:\n(Version for count data)\n2.186\n\n# Using the vegan package\nlibrary(vegan)\nz &lt;- data_count$data$i\nmor &lt;- dispindmorisita(z)\nmor\n\n      imor     mclu      muni      imst pchisq\n1 2.185591 1.008728 0.9922162 0.5041152      0\n\n\n\n\n15.2.1.3 Power law\nWhen we have a collection of count data sets at the sampling unit scale the Taylor’s power law (TPL) can be used to assess the overall degree of heterogeneity.\n\n\n\n15.2.2 Incidence data\n\n15.2.2.1 Fit to distributions\n\ntas &lt;-\n  read.csv(\n    \"https://www.apsnet.org/edcenter/disimpactmngmnt/topc/EcologyAndEpidemiologyInR/SpatialAnalysis/Documents/tasmania_test_1.txt\",\n    sep = \"\"\n  )\nhead(tas,10)\n\n   quad group_size count\n1     1          6     4\n2     2          6     6\n3     3          6     6\n4     4          6     6\n5     5          6     6\n6     6          6     6\n7     7          6     6\n8     8          6     6\n9     9          6     4\n10   10          6     6\n\n# Create incidence object for epiphy\ndat_tas &lt;- tas |&gt;\n  mutate(n = group_size, i = count) |&gt;\n  epiphy::incidence()\n\n## Fit to two distributions\nfit_tas &lt;- fit_two_distr(dat_tas)\nsummary(fit_tas)\n\nFitting of two distributions by maximum likelihood\nfor 'incidence' data.\nParameter estimates:\n\n(1) Binomial (random):\n     Estimate Std.Err Z value    Pr(&gt;z)    \nprob  0.90860 0.01494  60.819 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(2) Beta-binomial (aggregated):\n      Estimate  Std.Err Z value    Pr(&gt;z)    \nalpha 1.923479 0.869621  2.2119  0.026976 *  \nbeta  0.181337 0.075641  2.3973  0.016514 *  \nprob  0.913847 0.023139 39.4943 &lt; 2.2e-16 ***\nrho   0.322080 0.096414  3.3406  0.000836 ***\ntheta 0.475101 0.209789  2.2647  0.023534 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfit_tas$llr\n\nLikelihood ratio test\n\n              LogLik Df  Chisq Pr(&gt;Chisq)    \nrandom :     -75.061                         \naggregated : -57.430  1 35.263   2.88e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(fit_tas)\n\n\n\n\n\n\n15.2.2.2 Aggregation indices\nglm model\n\nbinom.tas = glm(cbind(count, group_size - count) ~ 1,\n                family = binomial,\n                data = tas)\nsummary(binom.tas)\n\n\nCall:\nglm(formula = cbind(count, group_size - count) ~ 1, family = binomial, \n    data = tas)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-3.447   1.073   1.073   1.073   1.073  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.2967     0.1799   12.77   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 117.76  on 61  degrees of freedom\nResidual deviance: 117.76  on 61  degrees of freedom\nAIC: 152.12\n\nNumber of Fisher Scoring iterations: 5\n\nlibrary(performance)\ncheck_overdispersion(binom.tas)\n\n# Overdispersion test\n\n       dispersion ratio =   2.348\n  Pearson's Chi-Squared = 143.206\n                p-value = &lt; 0.001\n\n\nepiphy(c-alpha test)\n\nlibrary(epiphy)\ntas2 &lt;- tas |&gt;\n  mutate(i = count,\n         n = group_size) |&gt;  # create i vector\n  epiphy::incidence()\n\nt &lt;- agg_index(tas2, flavor = \"incidence\")\nt\n\nFisher's index of dispersion:\n(Version for incidence data)\n2.348\n\n\n\ncalpha.test(t)\n\n\n    C(alpha) test\n\ndata:  t\nz = 7.9886, p-value = 1.365e-15\n\n\n\n\n15.2.2.3 Binary power law\nWhen we have a collection of incidence data sets at the sampling unit scale the binary form of the power law can be used to assess the overall degree of heterogeneity. This spatial analysis method describes the relationship between the observed variance of diseased individuals within a data set and the corresponding variance under the assumption that the data have a random distribution distribution (i.e., Binomial for proportion data).\n\n\n\n\nBaddeley, A., Diggle, P. J., Hardegen, A., Lawrence, T., Milne, R. K., and Nair, G. 2014. On tests of spatial pattern based on simulation envelopes. Ecological Monographs. 84:477–489 Available at: http://dx.doi.org/10.1890/13-2042.1.\n\n\nBaddeley, A., Turner, R., Moller, J., and Hazelton, M. 2005. Residual analysis for spatial point processes (with discussion). Journal of the Royal Statistical Society: Series B (Statistical Methodology). 67:617–666 Available at: http://dx.doi.org/10.1111/j.1467-9868.2005.00519.x.\n\n\nCampbell, C. L., and Madden. L., V. 1990. Introduction to plant disease epidemiology. Wiley.\n\n\nEsser, D. S., Leveau, J. H. J., Meyer, K. M., and Wiegand, K. 2014. Spatial scales of interactions among bacteria and between bacteria and the leaf surface. FEMS Microbiology Ecology. 91 Available at: http://dx.doi.org/10.1093/femsec/fiu034.\n\n\nGigot, C. 2018. Epiphy: Analysis of plant disease epidemics.\n\n\nHeck, D. W., Dita, M., Del Ponte, E. M., and Mizubuti, E. S. G. 2021. Incidence, spatial pattern and temporal progress of fusarium wilt of bananas. Journal of Fungi. 7 Available at: https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112784905&doi=10.3390%2fjof7080646&partnerID=40&md5=4169ec6f1d53e1a8c536522522e77ffa.\n\n\nJesus Junior, W. C. de, and Bassanezi, R. B. 2004. Análise da dinâmica e estrutura de focos da morte súbita dos citros. Fitopatologia Brasileira. 29:399–405 Available at: http://dx.doi.org/10.1590/S0100-41582004000400007.\n\n\nLaranjeira, F. F., Bergamin Filho, A. R., and Amorim, L. I. 1998. Dinâmica e estrutura de focos da clorose variegada dos citros (CVC). Fitopatologia Brasileira. 23:36–41.\n\n\nLaranjeira, F. F., Bergamin Filho, A., Amorim, L., and Gottwald, T. R. 2004. Dinâmica espacial da clorose variegada dos citros em três regiões do estado de são paulo. Fitopatologia Brasileira. 29:56–65 Available at: http://dx.doi.org/10.1590/S0100-41582004000100009.\n\n\nLi, B., Madden, L. V., and Xu, X. 2011. Spatial analysis by distance indices: an alternative local clustering index for studying spatial patterns. Methods in Ecology and Evolution. 3:368–377 Available at: http://dx.doi.org/10.1111/j.2041-210x.2011.00165.x.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017a. Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017b. The study of plant disease epidemics. The American Phytopathological Society. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMoran, P. A. P. 1950. Notes on continuous stochastic phenomena. Biometrika. 37:17.\n\n\nNelson, S. C. 1996. A simple analysis of disease foci. Phytopathology. 86:432–439.\n\n\nWiegand, T., and A. Moloney, K. 2004. Rings, circles, and null-models for point pattern analysis in ecology. Oikos. 104:209–229 Available at: http://dx.doi.org/10.1111/j.0030-1299.2004.12497.x.\n\n\nXu, X.-M., and Madden, L. V. 2004. Use of SADIE statistics to study spatial dynamics of plant disease epidemics. Plant Pathology. 53:38–49 Available at: http://dx.doi.org/10.1111/j.1365-3059.2004.00949.x."
  },
  {
    "objectID": "yieldloss-concepts.html#introduction",
    "href": "yieldloss-concepts.html#introduction",
    "title": "16  Definitions and concepts",
    "section": "16.1 Introduction",
    "text": "16.1 Introduction\nPlant disease epidemics can also be studied in regard to their potential to reduce crop yield (the measurable produce such as seed, fruit, leaves, roots or tubers) and quality (e.g. blemishes on fruit and toxins in grain) of the agricultural production. The yield of some crops that host the pathogen for long time may be reduced because its physiology is negatively affected in a dynamic way as the crop grows (biomass increase) and develops (advances the phenological stages). For some diseases that primarily infect the product (e.g. grains), yield is directly as affected with the reduction in size and weight of the affected plant part. There are cases of diseases causing visual damages on the product (e.g. fruit, tuber) that do no result in yield reduction, but the presence of the symptoms may reduce sales. Another example is the presence of toxins that downgrade product value.\nLosses can be classified as direct (on the farm) or indirect (on the society) (Figure 16.1). Costs on farm that are due to reduction in quantity an quality of yield and control costs are classified as primary. Other consequences of the epidemics such as the build-up of inoculum in soil and the reduced efficacy of control due to surge of resistance to chemicals in the pathogen population over the years are examples of secondary losses on farm.\n\n\n\nFigure 16.1: Tipology of losses caused by plant diseases\n\n\nThe famous epidemics in the ancient history, such as the late blight of potatoes, serve us as a remind of worst-case scenarios of major impact of epidemics causing both direct and indirect losses. However, crop losses due to diseases occur regularly and at levels that depend on the intensity of epidemics (Madden et al. 2017). Expert opinion estimates have indicated that around 20% (on average) of the yield of major crops like wheat, rice, maize, potato and soybean is lost due to the pests and pathogens globally (Savary et al. 2019)."
  },
  {
    "objectID": "yieldloss-concepts.html#crop-loss-assessment",
    "href": "yieldloss-concepts.html#crop-loss-assessment",
    "title": "16  Definitions and concepts",
    "section": "16.2 Crop loss assessment",
    "text": "16.2 Crop loss assessment\nAccording to Madden et al. (2017), knowledge about the disease:yield relationship falls within crop loss assessment, a general branch of epidemiology that study the relationship between the attack by harmful organisms and the resulting yield (or yield loss) of crops. In fact, the study (analysis and modeling) of crop losses is considered central to plant pathology as no plant protection scientific reasoning could be possible without a measure of crop loss (Savary et al. 2006).\nThe concept of yield levels is important to recognize as a framework to study crop losses. There are three levels (from higher to lower) of yield: theoretical, attainable and actual.\n\nTheoretical (also known as potential) yield is determined mainly by defining factors such as the genotype of the crop grown under ideal conditions. It can be obtained in experimental plots managed with high input of fertilizers and pesticides.\nAttainable yield is obtained in commercial crops managed with a full range of modern technology to maximize yield. It considers the presence of limiting factors such as water and fertilizers.\nActual yield is generally less than or equal to attainable yield, and is obtained under the effect of reducing factors such as those caused by pest (disease, insects, weeds) injuries - defined as measurable symptom caused by a harmful organism. It is the crop yield actually harvested in a farmer’s field.\n\nYield loss (expressed in absolute or relative terms) is the difference between the attainable and the actual yield. Yield loss studies are only possible when reliable field data are collected in sufficient number to allow the development of statistical (empirical) models as well as the validation of mechanistic simulation yield loss models.\n\n\nCode\nlibrary(tidyverse)\nyl &lt;- tibble::tribble(\n  ~yield, ~value, ~class,\n  \"Theoretical\", 25,1,\n  \"Attainable\", 20,2,\n  \"Actual\", 15,3,\n  \"\", 0, 4\n)\nyl |&gt; \n  ggplot(aes(reorder(yield,-value), value, fill = class))+\n  geom_col(width = 0.5)+\n  theme_minimal(base_size = 16)+\n  ggthemes::scale_fill_gradient_tableau()+\n  geom_hline(yintercept = 25, linetype = 2, color = \"gray60\")+\n  geom_hline(yintercept = 20, linetype = 2, color = \"gray60\")+\n  geom_hline(yintercept = 15, linetype = 2, color = \"gray60\")+\n  theme(legend.position = \"none\", \n        axis.text.y=element_blank(),\n        axis.ticks.x = element_blank())+\n  annotate(geom = \"text\", x = 1.8, y = 22, label =\"Defining factors \n           (genotype and environment)\")+\n  annotate(geom = \"text\", x = 2.8, y = 17.5, label =\"Limiting factors\n        (fertilizers, water)\")+\n  annotate(geom = \"text\", x = 3.8, y = 12, label =\"Reducing factors\n           (pest, weeds, diseases)\")+\n  annotate(\"segment\", x = 4, y = 20, xend = 4, yend = 15,\n         arrow = arrow(type = \"closed\", length = unit(0.02, \"npc\")))+\n  annotate(geom = \"text\", x = 4.3, y = 17, label =\"Yield loss\")+\n  labs(x = \"\", y = \"\")\n\n\n\n\n\nFigure 16.2: Yield levels"
  },
  {
    "objectID": "yieldloss-concepts.html#diseaseyield-data-and-graphs",
    "href": "yieldloss-concepts.html#diseaseyield-data-and-graphs",
    "title": "16  Definitions and concepts",
    "section": "16.3 Disease:yield data and graphs",
    "text": "16.3 Disease:yield data and graphs\nThe datasets used to characterize a disease:yield relationship should ideally have a wide range of values of yield and disease. Two different approaches have been used to obtain such data: 1) experimentation conducted in the field or greenhouse; or 2) from surveys in naturally infected commercial fields.\nIn experiments, the researcher rely on different treatments that will result in different epidemics - assuming that the disease affects yield. These treatments include mainly the use of inoculations of varying inoculum levels (when disease is expected to be low) and application of fungicides at varying rate, number or timing (when disease is expected to be high) Alternatively, one can use different host genotypes (preferably isolines or near isolines) with varying susceptibility or manipulate the environment (e.g. irrigation).\nWhatever the case, the relationship between a measure of yield (in absolute or relative terms) and disease variable can be appraised using scatter plots that depict a “damage curve” (Madden et al. 2017). The disease variable most commonly represent the assessment of disease at a single time (critical point). Sometimes, the data obtained from multiple assessments during the epidemics is used to calculate the area under the disease progress curve that is used to represent disease variable.\nLet’s work with actual data on the incidence of white mold disease and yield of soybean determined across different locations and years in Brazil (Lehner et al. 2016). The variation in disease and yield was obtained by applying different fungicides that varied in efficacy, thus resulting in variable final disease incidence. The data was made freely available in this repository.\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nwm &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-white-mold-meta-analysis/gh-pages/dat-white-mold-br.csv\")\nglimpse(wm)\n\nRows: 382\nColumns: 17\n$ study           &lt;dbl&gt; 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 18, 18, 18, 18, 18…\n$ treat           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5, …\n$ season          &lt;chr&gt; \"2009/2010\", \"2009/2010\", \"2009/2010\", \"2009/2010\", \"2…\n$ harvest_year    &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, …\n$ location        &lt;chr&gt; \"Agua Fria\", \"Agua Fria\", \"Agua Fria\", \"Agua Fria\", \"A…\n$ state           &lt;chr&gt; \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", \"GO\", …\n$ country         &lt;chr&gt; \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\", \"Bra…\n$ elevation       &lt;dbl&gt; 891, 891, 891, 891, 891, 891, 891, 891, 891, 891, 891,…\n$ region          &lt;chr&gt; \"Northern\", \"Northern\", \"Northern\", \"Northern\", \"North…\n$ elevation_class &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ inc_check       &lt;dbl&gt; 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, 37.7, …\n$ inc_class       &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\"…\n$ yld_check       &lt;dbl&gt; 3729, 3729, 3729, 3729, 3729, 3729, 3729, 3729, 3729, …\n$ yld_class       &lt;chr&gt; \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\"…\n$ inc             &lt;dbl&gt; 37.7, 11.6, 33.5, 1.0, 5.6, 1.0, 3.7, 0.0, 1.1, 0.0, 3…\n$ scl             &lt;dbl&gt; 5092, 6154, 200, 180, 1123, 641, 1203, 521, 20, 0, 847…\n$ yld             &lt;dbl&gt; 3729, 3739, 3863, 3904, 4471, 4313, 4177, 4001, 4090, …\n\n\nAs seen above using glimpse() function, the full data set has 17 variables. Let’s reduce the data set to a few variables (study, inc and yld) and the trials number 1 and 2.\n\nwm2 &lt;- wm |&gt; \n  select(study, inc, yld) |&gt; \n  filter(study %in% c(1,2)) \nwm2\n\n# A tibble: 26 × 3\n   study   inc   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1    76  2265\n 2     1    53  2618\n 3     1    42  2554\n 4     1    37  2632\n 5     1    29  2820\n 6     1    42  2799\n 7     1    55  2503\n 8     1    40  2967\n 9     1    26  2965\n10     1    18  3088\n# … with 16 more rows\n\n\nWe can now produce the damage curves for each study. As it can be seen, the relationship can be adequately described by a straight line.\n\nwm2 |&gt; \n  ggplot(aes(inc, yld, \n             group = study, \n             color = factor(study)))+\n  geom_point(size = 2)+\n  ggthemes::scale_color_colorblind()+\n  geom_smooth(method = \"lm\", se = F, color = \"black\", fullrange = T)+\n  ylim(1800, 3500)+\n  facet_wrap(~study)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\",\n       color = \"Study\")\n\n\n\n\nFigure 16.3: Relationship between soybean yield and incidence of white mold in two experiments\n\n\n\n\nWe can plot the relationships for all studies combined, which will resemble a “spaghetti” plot after adding the individual regression lines.\n\np1 &lt;- wm |&gt; \n  ggplot(aes(inc, yld, group = study))+\n  geom_point(size = 2, alpha = 0.5)+\n  ylim(0, 5000)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\")\n\np2 &lt;- wm |&gt; \n  ggplot(aes(inc, yld, group = study))+\n  geom_smooth(method = \"lm\", se = F, fullrange = T, color = \"black\")+\n  ylim(0, 5000)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\")\n\nlibrary(patchwork)\np1 | p2\n\n\n\n\nFigure 16.4: Relationship between soybean yield and incidence of white mold across trials. Observed (left) and fitted regression lines (right)\n\n\n\n\n\n\n\n\nLehner, M. S., Pethybridge, S. J., Meyer, M. C., and Del Ponte, E. M. 2016. Meta-analytic modelling of the incidenceyield and incidencesclerotial production relationships in soybean white mould epidemics. Plant Pathology. 66:460–468 Available at: http://dx.doi.org/10.1111/ppa.12590.\n\n\nMadden, L. V., Hughes, G., and Bosch, F. van den, eds. 2017. CHAPTER 12: Epidemics and crop yield. In The American Phytopathological Society, p. 353–388. Available at: http://dx.doi.org/10.1094/9780890545058.012.\n\n\nSavary, S., Teng, P. S., Willocquet, L., and Nutter, F. W. 2006. Quantification and Modeling of Crop Losses: A Review of Purposes. Annual Review of Phytopathology. 44:89–112 Available at: http://dx.doi.org/10.1146/annurev.phyto.44.070505.143342.\n\n\nSavary, S., Willocquet, L., Pethybridge, S. J., Esker, P., McRoberts, N., and Nelson, A. 2019. The global burden of pathogens and pests on major food crops. Nature Ecology & Evolution. 3:430–439 Available at: http://dx.doi.org/10.1038/s41559-018-0793-y."
  },
  {
    "objectID": "yieldloss-regression-models.html",
    "href": "yieldloss-regression-models.html",
    "title": "17  Statistical models",
    "section": "",
    "text": "This is a work in progress that is currently undergoing heavy technical editing and copy-editing\n\n\n\n\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nwm &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-white-mold-meta-analysis/gh-pages/dat-white-mold-br.csv\")\n\n\nwm1 &lt;- wm |&gt; \n  select(study, inc, yld) |&gt; \n  filter(study %in% c(1)) \nwm1\n\n# A tibble: 13 × 3\n   study   inc   yld\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1    76  2265\n 2     1    53  2618\n 3     1    42  2554\n 4     1    37  2632\n 5     1    29  2820\n 6     1    42  2799\n 7     1    55  2503\n 8     1    40  2967\n 9     1    26  2965\n10     1    18  3088\n11     1    27  3044\n12     1    28  2925\n13     1    36  2867\n\n\n\nwm1 |&gt; \n  ggplot(aes(inc, yld))+\n  geom_point(size = 2)+\n  geom_smooth(method = \"lm\", se = F, color = \"black\", fullrange = T)+\n  ylim(1800, 3500)+\n  labs(x = \"White mold incidence (%)\",\n       y = \"Soybean yield (kg/ha)\",\n       color = \"Study\")\n\n\n\n\nFitting a linear regression model\n\nlm1 &lt;-  lm(yld ~ inc, data = wm1) \nsummary(lm1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wm1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-178.41  -44.70   14.60   49.34  206.18 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3329.142     86.844  38.335 4.60e-13 ***\ninc          -14.208      2.076  -6.845 2.78e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 110.4 on 11 degrees of freedom\nMultiple R-squared:  0.8099,    Adjusted R-squared:  0.7926 \nF-statistic: 46.86 on 1 and 11 DF,  p-value: 2.782e-05\n\n\nThe damage curves can be expressed in relative terms. For this, we divide the slope by the intercept and multiply by 100.\n\nslope &lt;- -14.2/3329.14*100\nx = seq(0,1,0.1)\ny = seq(0,1,0.1)\ndat &lt;- data.frame(x,y)\ndat |&gt; \n  ggplot(aes(x,y))+\n  geom_point(color = \"white\")+  \n  geom_abline(aes(intercept = 1, slope = slope))"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agrios, G. N. 2005a. INTRODUCTION. In Elsevier, p. 3–75. Available at:\nhttp://dx.doi.org/10.1016/b978-0-08-047378-9.50007-5.\n\n\nAgrios, G. N. 2005b. Plant disease epidemiology. In Elsevier, p.\n265–291. Available at: http://dx.doi.org/10.1016/b978-0-08-047378-9.50014-2.\n\n\nAlves, K. S., Guimarães, M., Ascari, J. P., Queiroz, M. F., Alfenas, R.\nF., Mizubuti, E. S. G., et al. 2021. RGB-based phenotyping of foliar\ndisease severity under controlled conditions. Tropical Plant Pathology.\n47:105–117 Available at: http://dx.doi.org/10.1007/S40858-021-00448-Y.\n\n\nBaddeley, A., Diggle, P. J., Hardegen, A., Lawrence, T., Milne, R. K.,\nand Nair, G. 2014. On tests of spatial pattern based on simulation\nenvelopes. Ecological Monographs. 84:477–489 Available at: http://dx.doi.org/10.1890/13-2042.1.\n\n\nBaddeley, A., Turner, R., Moller, J., and Hazelton, M. 2005. Residual\nanalysis for spatial point processes (with discussion). Journal of the\nRoyal Statistical Society: Series B (Statistical Methodology).\n67:617–666 Available at: http://dx.doi.org/10.1111/j.1467-9868.2005.00519.x.\n\n\nBarnhart, H. X., Haber, M., and Song, J. 2002. Overall Concordance\nCorrelation Coefficient for Evaluating Agreement Among Multiple\nObservers. Biometrics. 58:1020–1027 Available at: http://dx.doi.org/10.1111/j.0006-341x.2002.01020.x.\n\n\nBock, C. H., Chiang, K.-S., and Del Ponte, E. M. 2021a. Plant disease\nseverity estimated visually: a century of research, best practices, and\nopportunities for improving methods and practices to maximize accuracy.\nTropical Plant Pathology. 47:25–42 Available at: http://dx.doi.org/10.1007/s40858-021-00439-z.\n\n\nBock, C. H., Pethybridge, S. J., Barbedo, J. G. A., Esker, P. D.,\nMahlein, A.-K., and Del Ponte, E. M. 2021b. A phytopathometry glossary\nfor the twenty-first century: towards consistency and precision in\nintra- and inter-disciplinary dialogues. Tropical Plant Pathology.\n47:14–24 Available at: http://dx.doi.org/10.1007/s40858-021-00454-0.\n\n\nBrown, V. A. 2021. An Introduction to Linear Mixed-Effects Modeling in\nR. Advances in Methods and Practices in Psychological Science.\n4:251524592096035 Available at: http://dx.doi.org/10.1177/2515245920960351.\n\n\nCampbell, C. L., and Madden. L., V. 1990. Introduction to plant\ndisease epidemiology. Wiley.\n\n\nChester, K. S. 1950. Plant disease losses : Their appraisal and\ninterpretation /. Available at: http://dx.doi.org/10.5962/bhl.title.86198.\n\n\nChiang, K.-S., and Bock, C. H. 2021. Understanding the ramifications of\nquantitative ordinal scales on accuracy of estimates of disease severity\nand data analysis in plant pathology. Tropical Plant Pathology. 47:58–73\nAvailable at: http://dx.doi.org/10.1007/s40858-021-00446-0.\n\n\nChiang, K.-S., Liu, S.-C., Bock, C. H., and Gottwald, T. R. 2014. What\nInterval Characteristics Make a Good Categorical Disease Assessment\nScale? Phytopathology®. 104:575–585 Available at: http://dx.doi.org/10.1094/phyto-10-13-0279-r.\n\n\nCruz, C. D., and Valent, B. 2017. Wheat blast disease: danger on the\nmove. Tropical Plant Pathology. 42:210–222 Available at: http://dx.doi.org/10.1007/s40858-017-0159-z.\n\n\nDel Ponte, E. M., Cazón, L. I., Alves, K. S., Pethybridge, S. J., and\nBock, C. H. 2022. How much do standard area diagrams improve accuracy of\nvisual estimates of the percentage area diseased? A systematic review\nand meta-analysis. Tropical Plant Pathology. 47:43–57 Available at: http://dx.doi.org/10.1007/s40858-021-00479-5.\n\n\nDel Ponte, E. M., Pethybridge, S. J., Bock, C. H., Michereff, S. J.,\nMachado, F. J., and Spolti, P. 2017. Standard Area Diagrams for Aiding\nSeverity Estimation: Scientometrics, Pathosystems, and Methodological\nTrends in the Last 25 Years. Phytopathology®. 107:1161–1174 Available\nat: http://dx.doi.org/10.1094/PHYTO-02-17-0069-FI.\n\n\nDuffeck, M. R., Santos Alves, K. dos, Machado, F. J., Esker, P. D., and\nDel Ponte, E. M. 2020. Modeling Yield Losses and Fungicide Profitability\nfor Managing Fusarium Head Blight in Brazilian Spring Wheat.\nPhytopathology®. 110:370–378 Available at: http://dx.doi.org/10.1094/PHYTO-04-19-0122-R.\n\n\nFranceschi, V. T., Alves, K. S., Mazaro, S. M., Godoy, C. V., Duarte, H.\nS. S., and Del Ponte, E. M. 2020. A new standard area diagram set for\nassessment of severity of soybean rust improves accuracy of estimates\nand optimizes resource use. Plant Pathology. 69:495–505 Available at: http://dx.doi.org/10.1111/ppa.13148.\n\n\nFrancl, L. J. 2001. The..disease triangle: A plant pathological paradigm\nrevisited. The Plant Health Instructor. Available at: http://dx.doi.org/10.1094/PHI-T-2001-0517-01.\n\n\nGigot, C. 2018. Epiphy: Analysis of plant disease epidemics.\n\n\nGodoy, C. V., Seixas, C. D. S., Soares, R. M., Marcelino-Guimarães, F.\nC., Meyer, M. C., and Costamilan, L. M. 2016. Asian soybean rust in\nbrazil: Past, present, and future. Pesquisa Agropecuária Brasileira.\n51:407–421 Available at: http://dx.doi.org/10.1590/S0100-204X2016000500002.\n\n\nGonzález-Domínguez, E., Martins, R. B., Del Ponte, E. M., Michereff, S.\nJ., García-Jiménez, J., and Armengol, J. 2014. Development and\nvalidation of a standard area diagram set to aid assessment of severity\nof loquat scab on fruit. European Journal of Plant Pathology. Available\nat: http://dx.doi.org/10.1007/s10658-014-0400-2.\n\n\nHebert, T. T. 1982. The rationale for the horsfall-barratt plant disease\nassessment scale. Phytopathology. 72:1269 Available at: http://dx.doi.org/10.1094/phyto-72-1269.\n\n\nHeck, D. W., Dita, M., Del Ponte, E. M., and Mizubuti, E. S. G. 2021.\nIncidence, spatial pattern and temporal progress of fusarium wilt of\nbananas. Journal of Fungi. 7 Available at: https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112784905&doi=10.3390%2fjof7080646&partnerID=40&md5=4169ec6f1d53e1a8c536522522e77ffa.\n\n\nIslam, M. T., Kim, K.-H., and Choi, J. 2019. Wheat Blast in Bangladesh:\nThe Current Situation and Future Impacts. The Plant Pathology Journal.\n35:1–10 Available at: http://dx.doi.org/10.5423/ppj.rw.08.2018.0168.\n\n\nJeger, M. J., and Viljanen-Rollinson, S. L. H. 2001. The use of the area\nunder the disease-progress curve (AUDPC) to assess quantitative disease\nresistance in crop cultivars. Theoretical and Applied Genetics.\n102:32–40 Available at: http://dx.doi.org/10.1007/s001220051615.\n\n\nLehner, M. S., Pethybridge, S. J., Meyer, M. C., and Del Ponte, E. M.\n2016. Meta-analytic modelling of the\nincidenceyield and incidencesclerotial\nproduction relationships in soybean white mould epidemics. Plant\nPathology. 66:460–468 Available at: http://dx.doi.org/10.1111/ppa.12590.\n\n\nLi, B., Madden, L. V., and Xu, X. 2011. Spatial analysis by distance\nindices: an alternative local clustering index for studying spatial\npatterns. Methods in Ecology and Evolution. 3:368–377 Available at: http://dx.doi.org/10.1111/j.2041-210x.2011.00165.x.\n\n\nLi, F., Upadhyaya, N. M., Sperschneider, J., Matny, O., Nguyen-Phuc, H.,\nMago, R., et al. 2019. Emergence of the Ug99 lineage of the wheat stem\nrust pathogen through somatic hybridisation. Nature Communications. 10\nAvailable at: http://dx.doi.org/10.1038/s41467-019-12927-7.\n\n\nLin, L. I.-K. 1989. A concordance correlation coefficient to evaluate\nreproducibility. Biometrics. 45:255 Available at: http://dx.doi.org/10.2307/2532051.\n\n\nLiu, H. I., Tsai, J. R., Chung, W. H., Bock, C. H., and Chiang, K. S.\n2019. Effects of Quantitative Ordinal Scale Design on the Accuracy of\nEstimates of Mean Disease Severity. Agronomy. 9:565 Available at: http://dx.doi.org/10.3390/agronomy9090565.\n\n\nMadden, L. V., Esker, P. D., and Pethybridge, S. J. 2021. Forrest W.\nNutter, Jr.: a career in phytopathometry. Tropical Plant Pathology.\n47:5–13 Available at: http://dx.doi.org/10.1007/s40858-021-00469-7.\n\n\nMadden, L. V., Hughes, G., and Bosch, F. van den, eds. 2017a. CHAPTER\n12: Epidemics and crop yield. In The American Phytopathological Society,\np. 353–388. Available at: http://dx.doi.org/10.1094/9780890545058.012.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017b. Spatial aspects\nof epidemicsIII: Patterns of plant disease. In The American\nPhytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017c. Temporal\nanalysis i: Quantifying and comparing epidemics. In The American\nPhytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017d. The study of\nplant disease epidemics. The American Phytopathological Society.\nAvailable at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMalaker, P. K., Barma, N. C. D., Tiwari, T. P., Collis, W. J.,\nDuveiller, E., Singh, P. K., et al. 2016. First Report of Wheat Blast\nCaused by Magnaporthe oryzae Pathotype\ntriticum in Bangladesh. Plant Disease.\n100:2330–2330 Available at: http://dx.doi.org/10.1094/pdis-05-16-0666-pdn.\n\n\nMikaberidze, A., Mundt, C. C., and Bonhoeffer, S. 2015. Data from:\nInvasiveness of plant pathogens depends on the spatial scale of host\ndistribution. Available at: http://datadryad.org/stash/dataset/doi:10.5061/dryad.f2j8s.\n\n\nMoran, P. A. P. 1950. Notes on\ncontinuous stochastic phenomena. Biometrika. 37:17.\n\n\nMoreira, R. R., Silva Silveira Duarte, H. da, and De Mio, L. L. M. 2018.\nImproving accuracy, precision and reliability of severity estimates of\nGlomerella leaf spot on apple leaves using a new standard area diagram\nset. European Journal of Plant Pathology. 153:975–982 Available at: http://dx.doi.org/10.1007/s10658-018-01610-0.\n\n\nMundt, C. C., Ahmed, H. U., Finckh, M. R., Nieva, L. P., and Alfonso, R.\nF. 1999. Primary Disease Gradients of Bacterial Blight of Rice.\nPhytopathology®. 89:64–67 Available at: http://dx.doi.org/10.1094/phyto.1999.89.1.64.\n\n\nNutter, F. W., and Esker, P. D. 2006. The Role of Psychophysics in\nPhytopathology: The WeberFechner Law Revisited. European\nJournal of Plant Pathology. 114:199–213 Available at: http://dx.doi.org/10.1007/s10658-005-4732-9.\n\n\nNutter, F. W., Esker, P. D., and Netto, R. A. C. 2006. Disease\nAssessment Concepts and the Advancements Made in Improving the Accuracy\nand Precision of Plant Disease Data. European Journal of Plant\nPathology. 115:95–103 Available at: http://dx.doi.org/10.1007/s10658-005-1230-z.\n\n\nOlivoto, T. 2022. Lights, camera, pliman! An R package for plant image\nanalysis. Methods in Ecology and Evolution. 13:789–798 Available at: http://dx.doi.org/10.1111/2041-210X.13803.\n\n\nOlivoto, T., Andrade, S. M. P., and M. Del Ponte, E. 2022. Measuring\nplant disease severity in R: introducing and evaluating the pliman\npackage. Tropical Plant Pathology. 47:95–104 Available at: http://dx.doi.org/10.1007/s40858-021-00487-5.\n\n\nParker, S. K., Nutter, F. W., and Gleason, M. L. 1997. Directional\nSpread of Septoria Leaf Spot in Tomato Rows. Plant Disease. 81:272–276\nAvailable at: http://dx.doi.org/10.1094/pdis.1997.81.3.272.\n\n\nPereira, W. E. L., Andrade, S. M. P. de, Del Ponte, E. M., Esteves, M.\nB., Canale, M. C., Takita, M. A., et al. 2020. Severity assessment in\nthe Nicotiana tabacum-Xylella fastidiosa subsp. pauca pathosystem:\ndesign and interlaboratory validation of a standard area diagram set.\nTropical Plant Pathology. 45:710–722 Available at: http://dx.doi.org/10.1007/s40858-020-00401-5.\n\n\nSackett, K. E., and Mundt, C. C. 2005. Primary Disease Gradients of\nWheat Stripe Rust in Large Field Plots. Phytopathology®. 95:983–991\nAvailable at: http://dx.doi.org/10.1094/PHYTO-95-0983.\n\n\nSavary, S., Teng, P. S., Willocquet, L., and Nutter, F. W. 2006.\nQuantification and Modeling of Crop Losses: A Review of Purposes. Annual\nReview of Phytopathology. 44:89–112 Available at: http://dx.doi.org/10.1146/annurev.phyto.44.070505.143342.\n\n\nSavary, S., Willocquet, L., Pethybridge, S. J., Esker, P., McRoberts,\nN., and Nelson, A. 2019. The global burden of pathogens and pests on\nmajor food crops. Nature Ecology & Evolution. 3:430–439 Available\nat: http://dx.doi.org/10.1038/s41559-018-0793-y.\n\n\nScott, P. R., and Hollins, T. W. 1974. Effects of eyespot on the yield\nof winter wheat. Annals of Applied Biology. 78:269–279 Available at: http://dx.doi.org/10.1111/j.1744-7348.1974.tb01506.x.\n\n\nShrout, P. E., and Fleiss, J. L. 1979. Intraclass correlations: Uses in\nassessing rater reliability. Psychological Bulletin. 86:420–428\nAvailable at: http://dx.doi.org/10.1037/0033-2909.86.2.420.\n\n\nSimko, I., and Piepho, H.-P. 2012. The Area Under the Disease Progress\nStairs: Calculation, Advantage, and Application. Phytopathology®.\n102:381–389 Available at: http://dx.doi.org/10.1094/phyto-07-11-0216.\n\n\nTembo, B., Mulenga, R. M., Sichilima, S., M’siska, K. K., Mwale, M.,\nChikoti, P. C., et al. 2020. Detection and characterization of fungus\n(Magnaporthe oryzae pathotype Triticum) causing wheat blast disease on\nrain-fed grown wheat (Triticum aestivum L.) in Zambia ed. Zonghua Wang.\nPLOS ONE. 15:e0238724 Available at: http://dx.doi.org/10.1371/journal.pone.0238724.\n\n\nThresh, J. M. 1998. In memory of James Edward Vanderplank\n19091997. Plant Pathology. 47:114–115 Available at: http://dx.doi.org/10.1046/j.1365-3059.2998.00220.x.\n\n\nVanderplank, J. 1963. Plant disease epidemics and control.\nElsevier. Available at: http://dx.doi.org/10.1016/C2013-0-11642-X.\n\n\nXu, X.-M., and Madden, L. V. 2004. Use of SADIE statistics\nto study spatial dynamics of plant disease epidemics. Plant Pathology.\n53:38–49 Available at: http://dx.doi.org/10.1111/j.1365-3059.2004.00949.x.\n\n\nYadav, N. V. S., Vos, S. M. de, Bock, C. H., and Wood, B. W. 2012.\nDevelopment and validation of standard area diagrams to aid assessment\nof pecan scab symptoms on fruit. Plant Pathology. 62:325–335 Available\nat: http://dx.doi.org/10.1111/j.1365-3059.2012.02641.x.\n\n\nYorinori, J. T., Paiva, W. M., Frederick, R. D., Costamilan, L. M.,\nBertagnolli, P. F., Hartman, G. E., et al. 2005. Epidemics of Soybean\nRust (Phakopsora pachyrhizi) in Brazil and\nParaguay from 2001 to 2003. Plant Disease. 89:675–677 Available at: http://dx.doi.org/10.1094/PD-89-0675.\n\n\nZadoks, J. C., and Schein, R. D. 1988. James Edward Vanderplank:\nMaverick* and Innovator. Annual Review of Phytopathology. 26:31–37\nAvailable at: http://dx.doi.org/10.1146/annurev.py.26.090188.000335."
  },
  {
    "objectID": "spatial-patterns.html#simulating-spatial-patterns",
    "href": "spatial-patterns.html#simulating-spatial-patterns",
    "title": "14  Spatial patterns",
    "section": "14.3 Simulating spatial patterns",
    "text": "14.3 Simulating spatial patterns\nTwo Shiny apps have been developed to allow simulating various spatial disease patterns. The first generates a disease- or pathogen-only data where the units are located in a scatter plot where the user can define the number of cells of the grid as well as the number of points to be plotted and the realized pattern: random or aggregated.\n\n\n\nFigure 14.5: Screenshot of a Shiny app to simulate disease-only data in a grid\n\n\nThe second app generates an artificial plantation with presence-absence data in a 2D map. The user can define the number of rows and number of plants per row and the realized pattern: random or aggregated. The latter pattern can start from the center or border of the plantation. The app calculates the number of foci and the final incidence (proportion of diseased plants).\n\n\n\nFigure 14.6: Screenshot of a Shiny app to simulate a presence-absence data in a 2D map\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F. 2017. Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  },
  {
    "objectID": "intro.html#introduction-to-epidemics",
    "href": "intro.html#introduction-to-epidemics",
    "title": "1  Introduction to epidemics",
    "section": "1.1 Introduction to epidemics",
    "text": "1.1 Introduction to epidemics\nDisease in plants can be defined as any malfunctioning of host cells and tissues that results from continuous irritation by a pathogenic agent or environmental factor and leads to development of symptoms (Agrios 2005a). When caused by pathogenic agent, the disease results from the combination of three elements: susceptible host plant, a virulent pathogen, and favorable environmental conditions - the famous disease triangle. When a pathogen population establishes and causes disease in a host population, the phenomenon is called an epidemic, or the disease in populations. Among several definitions of epidemic, a comprehensive one is the change in disease intensity in a host population over time and space (Madden et al. 2017).\nDifferent versions of the disease triangle, by the inclusion of other elements (e.g. man and time), as points and/or dimensions, have been proposed to illustrate an epidemic (Agrios 2005b). One we prefer is the disease prism where a series of triangles sequentially stacked illustrates the development of plant disease through time (Francl 2001).\n\n\n\nFigure 1.1: The plant disease prism as a model of plant disease epidemics"
  },
  {
    "objectID": "intro.html#defining-plant-disease",
    "href": "intro.html#defining-plant-disease",
    "title": "1  Introduction",
    "section": "1.1 Defining plant disease",
    "text": "1.1 Defining plant disease\nDisease in plants can be defined as any malfunctioning of host cells and tissues that results from continuous irritation by a pathogenic agent or environmental factor and leads to development of symptoms (Agrios 2005a). When caused by pathogenic agent, the disease results from the combination of three elements: susceptible host plant, a virulent pathogen, and favorable environmental conditions - the famous disease triangle. When a pathogen population establishes and causes disease in a host population, the phenomenon is called an epidemic, or the disease in populations. Among several definitions of epidemic, a comprehensive one is the change in disease intensity in a host population over time and space (Madden et al. 2017).\nThere exist numerous iterations of the disease triangle, incorporating additional elements (e.g., human intervention and time) as points and/or dimensions to provide a more comprehensive representation of an epidemic (Agrios 2005b). We find the disease prism particularly illustrative, where a sequence of stacked triangles represent the evolution of a plant disease through time (Francl 2001).\n\n\n\nFigure 1.1: The plant disease prism as a model of plant disease epidemics"
  }
]